"use strict";(globalThis.webpackChunkt_ruby_docs=globalThis.webpackChunkt_ruby_docs||[]).push([[7474],{7474(n,e,t){t.d(e,{TRuby:()=>l});var r=class{files=new Map;addFile(n,e){this.files.set(n,e)}addFiles(n){for(const e of n)this.addFile(e.path,e.content)}getFile(n){return this.files.get(n)}hasFile(n){return this.files.has(n)}removeFile(n){return this.files.delete(n)}getAllFiles(){return new Map(this.files)}clear(){this.files.clear()}get size(){return this.files.size}};function i(n){return`"${n.replace(/\\/g,"\\\\").replace(/"/g,'\\"').replace(/#\{/g,"\\#{").replace(/\n/g,"\\n").replace(/\r/g,"\\r").replace(/\t/g,"\\t")}"`}var s={"lib/t_ruby/ast_type_inferrer.rb":'# frozen_string_literal: true\n\nmodule TRuby\n  # ASTTypeInferrer - TypeScript \uc2a4\ud0c0\uc77c \uc815\uc801 \ud0c0\uc785 \ucd94\ub860 \uc5d4\uc9c4\n  # IR \ub178\ub4dc\ub97c \uc21c\ud68c\ud558\uba74\uc11c \ud0c0\uc785\uc744 \ucd94\ub860\ud558\uace0 \uce90\uc2f1\n  class ASTTypeInferrer\n    # \ub9ac\ud130\ub7f4 \ud0c0\uc785 \ub9e4\ud551\n    LITERAL_TYPE_MAP = {\n      string: "String",\n      integer: "Integer",\n      float: "Float",\n      boolean: "bool",\n      symbol: "Symbol",\n      nil: "nil",\n      array: "Array[untyped]",\n      hash: "Hash[untyped, untyped]",\n    }.freeze\n\n    # \uc0b0\uc220 \uc5f0\uc0b0\uc790 \uaddc\uce59 (\ud53c\uc5f0\uc0b0\uc790 \ud0c0\uc785 \u2192 \uacb0\uacfc \ud0c0\uc785)\n    ARITHMETIC_OPS = %w[+ - * / % **].freeze\n    COMPARISON_OPS = %w[== != < > <= >= <=>].freeze\n    LOGICAL_OPS = %w[&& ||].freeze\n\n    # \ub0b4\uc7a5 \uba54\uc11c\ub4dc \ubc18\ud658 \ud0c0\uc785\n    BUILTIN_METHODS = {\n      # String \uba54\uc11c\ub4dc\n      %w[String upcase] => "String",\n      %w[String downcase] => "String",\n      %w[String capitalize] => "String",\n      %w[String reverse] => "String",\n      %w[String strip] => "String",\n      %w[String chomp] => "String",\n      %w[String chop] => "String",\n      %w[String gsub] => "String",\n      %w[String sub] => "String",\n      %w[String tr] => "String",\n      %w[String to_s] => "String",\n      %w[String to_str] => "String",\n      %w[String to_sym] => "Symbol",\n      %w[String to_i] => "Integer",\n      %w[String to_f] => "Float",\n      %w[String length] => "Integer",\n      %w[String size] => "Integer",\n      %w[String bytesize] => "Integer",\n      %w[String empty?] => "bool",\n      %w[String include?] => "bool",\n      %w[String start_with?] => "bool",\n      %w[String end_with?] => "bool",\n      %w[String match?] => "bool",\n      %w[String split] => "Array[String]",\n      %w[String chars] => "Array[String]",\n      %w[String bytes] => "Array[Integer]",\n      %w[String lines] => "Array[String]",\n\n      # Integer \uba54\uc11c\ub4dc\n      %w[Integer to_s] => "String",\n      %w[Integer to_i] => "Integer",\n      %w[Integer to_f] => "Float",\n      %w[Integer abs] => "Integer",\n      %w[Integer even?] => "bool",\n      %w[Integer odd?] => "bool",\n      %w[Integer zero?] => "bool",\n      %w[Integer positive?] => "bool",\n      %w[Integer negative?] => "bool",\n      %w[Integer times] => "Integer",\n      %w[Integer upto] => "Enumerator[Integer]",\n      %w[Integer downto] => "Enumerator[Integer]",\n\n      # Float \uba54\uc11c\ub4dc\n      %w[Float to_s] => "String",\n      %w[Float to_i] => "Integer",\n      %w[Float to_f] => "Float",\n      %w[Float abs] => "Float",\n      %w[Float ceil] => "Integer",\n      %w[Float floor] => "Integer",\n      %w[Float round] => "Integer",\n      %w[Float truncate] => "Integer",\n      %w[Float nan?] => "bool",\n      %w[Float infinite?] => "Integer?",\n      %w[Float finite?] => "bool",\n      %w[Float zero?] => "bool",\n      %w[Float positive?] => "bool",\n      %w[Float negative?] => "bool",\n\n      # Array \uba54\uc11c\ub4dc\n      %w[Array length] => "Integer",\n      %w[Array size] => "Integer",\n      %w[Array count] => "Integer",\n      %w[Array empty?] => "bool",\n      %w[Array any?] => "bool",\n      %w[Array all?] => "bool",\n      %w[Array none?] => "bool",\n      %w[Array include?] => "bool",\n      %w[Array reverse] => "Array[untyped]",\n      %w[Array sort] => "Array[untyped]",\n      %w[Array uniq] => "Array[untyped]",\n      %w[Array compact] => "Array[untyped]",\n      %w[Array flatten] => "Array[untyped]",\n      %w[Array join] => "String",\n      %w[Array to_s] => "String",\n      %w[Array to_a] => "Array[untyped]",\n\n      # Hash \uba54\uc11c\ub4dc\n      %w[Hash length] => "Integer",\n      %w[Hash size] => "Integer",\n      %w[Hash empty?] => "bool",\n      %w[Hash key?] => "bool",\n      %w[Hash has_key?] => "bool",\n      %w[Hash value?] => "bool",\n      %w[Hash has_value?] => "bool",\n      %w[Hash include?] => "bool",\n      %w[Hash keys] => "Array[untyped]",\n      %w[Hash values] => "Array[untyped]",\n      %w[Hash to_s] => "String",\n      %w[Hash to_a] => "Array[untyped]",\n      %w[Hash to_h] => "Hash[untyped, untyped]",\n\n      # Object \uba54\uc11c\ub4dc (\ubaa8\ub4e0 \ud0c0\uc785\uc5d0 \uc801\uc6a9)\n      %w[Object to_s] => "String",\n      %w[Object inspect] => "String",\n      %w[Object class] => "Class",\n      %w[Object is_a?] => "bool",\n      %w[Object kind_of?] => "bool",\n      %w[Object instance_of?] => "bool",\n      %w[Object respond_to?] => "bool",\n      %w[Object nil?] => "bool",\n      %w[Object frozen?] => "bool",\n      %w[Object dup] => "untyped",\n      %w[Object clone] => "untyped",\n      %w[Object freeze] => "self",\n      %w[Object tap] => "self",\n      %w[Object then] => "untyped",\n      %w[Object yield_self] => "untyped",\n\n      # Symbol \uba54\uc11c\ub4dc\n      %w[Symbol to_s] => "String",\n      %w[Symbol to_sym] => "Symbol",\n      %w[Symbol length] => "Integer",\n      %w[Symbol size] => "Integer",\n      %w[Symbol empty?] => "bool",\n    }.freeze\n\n    attr_reader :type_cache\n\n    def initialize\n      @type_cache = {} # \ub178\ub4dc \u2192 \ud0c0\uc785 \uce90\uc2dc (TypeScript\uc758 \uc9c0\uc5f0 \ud3c9\uac00)\n    end\n\n    # \ud45c\ud604\uc2dd \ud0c0\uc785 \ucd94\ub860\n    # @param node [IR::Node] IR \ub178\ub4dc\n    # @param env [TypeEnv] \ud0c0\uc785 \ud658\uacbd\n    # @return [String, IR::TypeNode, nil] \ucd94\ub860\ub41c \ud0c0\uc785\n    def infer_expression(node, env)\n      # \uce90\uc2dc \ud655\uc778 (\uc9c0\uc5f0 \ud3c9\uac00)\n      cache_key = node.object_id\n      return @type_cache[cache_key] if @type_cache.key?(cache_key)\n\n      type = case node\n             when IR::Literal\n               infer_literal(node)\n             when IR::InterpolatedString\n               "String" # Interpolated strings always produce String\n             when IR::VariableRef\n               infer_variable_ref(node, env)\n             when IR::BinaryOp\n               infer_binary_op(node, env)\n             when IR::UnaryOp\n               infer_unary_op(node, env)\n             when IR::MethodCall\n               infer_method_call(node, env)\n             when IR::ArrayLiteral\n               infer_array_literal(node, env)\n             when IR::HashLiteral\n               infer_hash_literal(node, env)\n             when IR::Assignment\n               infer_assignment(node, env)\n             when IR::Conditional\n               infer_conditional(node, env)\n             when IR::Block\n               infer_block(node, env)\n             when IR::Return\n               infer_return(node, env)\n             when IR::RawCode\n               "untyped"\n             else\n               "untyped"\n             end\n\n      @type_cache[cache_key] = type\n      type\n    end\n\n    # \uba54\uc11c\ub4dc \ubc18\ud658 \ud0c0\uc785 \ucd94\ub860\n    # @param method_node [IR::MethodDef] \uba54\uc11c\ub4dc \uc815\uc758 IR\n    # @param class_env [TypeEnv, nil] \ud074\ub798\uc2a4 \ud0c0\uc785 \ud658\uacbd\n    # @return [String, IR::TypeNode, nil] \ucd94\ub860\ub41c \ubc18\ud658 \ud0c0\uc785\n    def infer_method_return_type(method_node, class_env = nil)\n      return nil unless method_node.body\n\n      # \uba54\uc11c\ub4dc \uc2a4\ucf54\ud504 \uc0dd\uc131\n      env = TypeEnv.new(class_env)\n\n      # \ud30c\ub77c\ubbf8\ud130 \ud0c0\uc785 \ub4f1\ub85d\n      method_node.params.each do |param|\n        param_type = param.type_annotation&.to_rbs || "untyped"\n        env.define(param.name, param_type)\n      end\n\n      # \ubcf8\ubb38\uc5d0\uc11c \ubc18\ud658 \ud0c0\uc785 \uc218\uc9d1\n      return_types, terminated = collect_return_types(method_node.body, env)\n\n      # \uc554\ubb35\uc801 \ubc18\ud658\uac12 \ucd94\ub860 (\ub9c8\uc9c0\ub9c9 \ud45c\ud604\uc2dd) - \uc885\ub8cc\ub418\uc9c0 \uc54a\uc740 \uacbd\uc6b0\ub9cc\n      unless terminated\n        implicit_return = infer_implicit_return(method_node.body, env)\n        return_types << implicit_return if implicit_return\n      end\n\n      # \ud0c0\uc785 \ud1b5\ud569\n      unify_types(return_types)\n    end\n\n    private\n\n    # \ub9ac\ud130\ub7f4 \ud0c0\uc785 \ucd94\ub860\n    def infer_literal(node)\n      LITERAL_TYPE_MAP[node.literal_type] || "untyped"\n    end\n\n    # \ubcc0\uc218 \ucc38\uc870 \ud0c0\uc785 \ucd94\ub860\n    def infer_variable_ref(node, env)\n      # \uc0c1\uc218(\ud074\ub798\uc2a4\uba85)\ub294 \uadf8 \uc790\uccb4\uac00 \ud0c0\uc785 (\uc608: MyClass.new \ud638\ucd9c \uc2dc)\n      if node.scope == :constant || node.name.match?(/^[A-Z]/)\n        return node.name\n      end\n\n      env.lookup(node.name) || "untyped"\n    end\n\n    # \uc774\ud56d \uc5f0\uc0b0\uc790 \ud0c0\uc785 \ucd94\ub860\n    def infer_binary_op(node, env)\n      left_type = infer_expression(node.left, env)\n      right_type = infer_expression(node.right, env)\n      op = node.operator\n\n      # \ube44\uad50 \uc5f0\uc0b0\uc790\ub294 \ud56d\uc0c1 bool\n      return "bool" if COMPARISON_OPS.include?(op)\n\n      # \ub17c\ub9ac \uc5f0\uc0b0\uc790\n      if op == "&&"\n        # && \ub294 falsy\uba74 \uc67c\ucabd, truthy\uba74 \uc624\ub978\ucabd \ubc18\ud658\n        return right_type # \ub2e8\uc21c\ud654: \uc624\ub978\ucabd \ud0c0\uc785 \ubc18\ud658\n      end\n\n      if op == "||"\n        # || \ub294 truthy\uba74 \uc67c\ucabd, falsy\uba74 \uc624\ub978\ucabd \ubc18\ud658\n        return union_type(left_type, right_type)\n      end\n\n      # \uc0b0\uc220 \uc5f0\uc0b0\uc790\n      if ARITHMETIC_OPS.include?(op)\n        return infer_arithmetic_result(left_type, right_type, op)\n      end\n\n      "untyped"\n    end\n\n    # \uc0b0\uc220 \uc5f0\uc0b0 \uacb0\uacfc \ud0c0\uc785 \ucd94\ub860\n    def infer_arithmetic_result(left_type, right_type, op)\n      left_base = base_type(left_type)\n      right_base = base_type(right_type)\n\n      # \ubb38\uc790\uc5f4 \uc5f0\uacb0\n      if op == "+" && (left_base == "String" || right_base == "String")\n        return "String"\n      end\n\n      # \uc22b\uc790 \uc5f0\uc0b0\n      if numeric_type?(left_base) && numeric_type?(right_base)\n        # Float\uac00 \ud558\ub098\ub77c\ub3c4 \uc788\uc73c\uba74 Float\n        return "Float" if left_base == "Float" || right_base == "Float"\n\n        return "Integer"\n      end\n\n      # \ubc30\uc5f4 \uc5f0\uacb0\n      if op == "+" && left_base.start_with?("Array")\n        return left_type\n      end\n\n      "untyped"\n    end\n\n    # \ub2e8\ud56d \uc5f0\uc0b0\uc790 \ud0c0\uc785 \ucd94\ub860\n    def infer_unary_op(node, env)\n      operand_type = infer_expression(node.operand, env)\n\n      case node.operator\n      when "!"\n        "bool"\n      when "-"\n        operand_type\n      else\n        "untyped"\n      end\n    end\n\n    # \uba54\uc11c\ub4dc \ud638\ucd9c \ud0c0\uc785 \ucd94\ub860\n    def infer_method_call(node, env)\n      # receiver \ud0c0\uc785 \ucd94\ub860\n      receiver_type = if node.receiver\n                        infer_expression(node.receiver, env)\n                      else\n                        "Object"\n                      end\n\n      receiver_base = base_type(receiver_type)\n\n      # \ub0b4\uc7a5 \uba54\uc11c\ub4dc \uc870\ud68c\n      method_key = [receiver_base, node.method_name]\n      if BUILTIN_METHODS.key?(method_key)\n        result = BUILTIN_METHODS[method_key]\n\n        # self \ubc18\ud658\uc778 \uacbd\uc6b0 receiver \ud0c0\uc785 \ubc18\ud658\n        return receiver_type if result == "self"\n\n        return result\n      end\n\n      # Object \uba54\uc11c\ub4dc fallback\n      object_key = ["Object", node.method_name]\n      if BUILTIN_METHODS.key?(object_key)\n        result = BUILTIN_METHODS[object_key]\n        return receiver_type if result == "self"\n\n        return result\n      end\n\n      # new \uba54\uc11c\ub4dc\ub294 \ud074\ub798\uc2a4 \uc778\uc2a4\ud134\uc2a4 \ubc18\ud658\n      if node.method_name == "new" && receiver_base.match?(/^[A-Z]/)\n        return receiver_base\n      end\n\n      "untyped"\n    end\n\n    # \ubc30\uc5f4 \ub9ac\ud130\ub7f4 \ud0c0\uc785 \ucd94\ub860\n    def infer_array_literal(node, env)\n      return "Array[untyped]" if node.elements.empty?\n\n      element_types = node.elements.map { |e| infer_expression(e, env) }\n      unified = unify_types(element_types)\n\n      "Array[#{unified}]"\n    end\n\n    # \ud574\uc2dc \ub9ac\ud130\ub7f4 \ud0c0\uc785 \ucd94\ub860\n    def infer_hash_literal(node, env)\n      return "Hash[untyped, untyped]" if node.pairs.empty?\n\n      key_types = node.pairs.map { |p| infer_expression(p.key, env) }\n      value_types = node.pairs.map { |p| infer_expression(p.value, env) }\n\n      key_type = unify_types(key_types)\n      value_type = unify_types(value_types)\n\n      "Hash[#{key_type}, #{value_type}]"\n    end\n\n    # \ub300\uc785 \ud0c0\uc785 \ucd94\ub860 (\ubcc0\uc218 \ud0c0\uc785 \uc5c5\ub370\uc774\ud2b8 \ubc0f \uc6b0\ubcc0 \ud0c0\uc785 \ubc18\ud658)\n    def infer_assignment(node, env)\n      value_type = infer_expression(node.value, env)\n\n      # \ubcc0\uc218 \ud0c0\uc785 \ub4f1\ub85d\n      target = node.target\n      if target.start_with?("@") && !target.start_with?("@@")\n        env.define_instance_var(target, value_type)\n      elsif target.start_with?("@@")\n        env.define_class_var(target, value_type)\n      else\n        env.define(target, value_type)\n      end\n\n      value_type\n    end\n\n    # \uc870\uac74\ubb38 \ud0c0\uc785 \ucd94\ub860 (then/else \ube0c\ub79c\uce58 \ud1b5\ud569)\n    def infer_conditional(node, env)\n      then_type = infer_expression(node.then_branch, env) if node.then_branch\n      else_type = infer_expression(node.else_branch, env) if node.else_branch\n\n      types = [then_type, else_type].compact\n      return "nil" if types.empty?\n\n      unify_types(types)\n    end\n\n    # \ube14\ub85d \ud0c0\uc785 \ucd94\ub860 (\ub9c8\uc9c0\ub9c9 \ubb38\uc7a5\uc758 \ud0c0\uc785)\n    def infer_block(node, env)\n      return "nil" if node.statements.empty?\n\n      # \ub9c8\uc9c0\ub9c9 \ubb38\uc7a5 \ud0c0\uc785 \ubc18\ud658 (Ruby\uc758 \uc554\ubb35\uc801 \ubc18\ud658)\n      last_stmt = node.statements.last\n      infer_expression(last_stmt, env)\n    end\n\n    # return \ubb38 \ud0c0\uc785 \ucd94\ub860\n    def infer_return(node, env)\n      return "nil" unless node.value\n\n      infer_expression(node.value, env)\n    end\n\n    # \ubcf8\ubb38\uc5d0\uc11c \ubaa8\ub4e0 return \ud0c0\uc785 \uc218\uc9d1\n    # @return [Array<(Array<String>, Boolean)>] [\uc218\uc9d1\ub41c \ud0c0\uc785\ub4e4, \uc885\ub8cc \uc5ec\ubd80]\n    def collect_return_types(body, env)\n      types = []\n\n      terminated = collect_returns_recursive(body, env, types)\n\n      [types, terminated]\n    end\n\n    # @return [Boolean] true if this node terminates (contains unconditional return)\n    def collect_returns_recursive(node, env, types)\n      case node\n      when IR::Return\n        type = node.value ? infer_expression(node.value, env) : "nil"\n        types << type\n        true # return\uc740 \ud56d\uc0c1 \uc2e4\ud589 \ud750\ub984 \uc885\ub8cc\n      when IR::Block\n        node.statements.each do |stmt|\n          terminated = collect_returns_recursive(stmt, env, types)\n          return true if terminated # return \uc774\ud6c4 \ucf54\ub4dc\ub294 unreachable\n        end\n        false\n      when IR::Conditional\n        then_terminated = node.then_branch ? collect_returns_recursive(node.then_branch, env, types) : false\n        else_terminated = node.else_branch ? collect_returns_recursive(node.else_branch, env, types) : false\n        # \ubaa8\ub4e0 \ubd84\uae30\uac00 \uc885\ub8cc\ub418\uc5b4\uc57c \uc870\uac74\ubb38 \uc804\uccb4\uac00 \uc885\ub8cc\ub428\n        then_terminated && else_terminated\n      else\n        false\n      end\n    end\n\n    # \uc554\ubb35\uc801 \ubc18\ud658\uac12 \ucd94\ub860 (\ub9c8\uc9c0\ub9c9 \ud45c\ud604\uc2dd)\n    def infer_implicit_return(body, env)\n      case body\n      when IR::Block\n        return nil if body.statements.empty?\n\n        last_stmt = body.statements.last\n\n        # return \ubb38\uc774\uba74 \uc774\ubbf8 \uc218\uc9d1\ub428\n        return nil if last_stmt.is_a?(IR::Return)\n\n        infer_expression(last_stmt, env)\n      else\n        infer_expression(body, env)\n      end\n    end\n\n    # \ud0c0\uc785 \ud1b5\ud569 (\uc5ec\ub7ec \ud0c0\uc785\uc744 \ud558\ub098\ub85c)\n    def unify_types(types)\n      types = types.compact.uniq\n\n      return "nil" if types.empty?\n      return types.first if types.length == 1\n\n      # nil\uacfc \ub2e4\ub978 \ud0c0\uc785\uc774 \uc788\uc73c\uba74 nullable\n      if types.include?("nil") && types.length == 2\n        other = types.find { |t| t != "nil" }\n        return "#{other}?" if other\n      end\n\n      # \ub3d9\uc77c \uae30\ubcf8 \ud0c0\uc785\uc740 \ud1b5\ud569\n      base_types = types.map { |t| base_type(t) }.uniq\n      return types.first if base_types.length == 1\n\n      # Union \ud0c0\uc785 \uc0dd\uc131\n      types.join(" | ")\n    end\n\n    # Union \ud0c0\uc785 \uc0dd\uc131\n    def union_type(type1, type2)\n      return type2 if type1 == type2\n      return type2 if type1 == "nil"\n      return type1 if type2 == "nil"\n\n      "#{type1} | #{type2}"\n    end\n\n    # \uae30\ubcf8 \ud0c0\uc785 \ucd94\ucd9c (Generic\uc5d0\uc11c)\n    def base_type(type)\n      return "untyped" if type.nil?\n\n      type_str = type.is_a?(String) ? type : type.to_rbs\n\n      # Array[X] \u2192 Array\n      return ::Regexp.last_match(1) if type_str =~ /^(\\w+)\\[/\n\n      # Nullable X? \u2192 X\n      return type_str[0..-2] if type_str.end_with?("?")\n\n      type_str\n    end\n\n    # \uc22b\uc790 \ud0c0\uc785\uc778\uc9c0 \ud655\uc778\n    def numeric_type?(type)\n      %w[Integer Float Numeric].include?(type)\n    end\n  end\nend\n',"lib/t_ruby/benchmark.rb":'# frozen_string_literal: true\n\nrequire "benchmark"\nrequire "json"\nrequire "fileutils"\nrequire "time"\n\nmodule TRuby\n  # Benchmark suite for T-Ruby performance measurement\n  class BenchmarkSuite\n    attr_reader :results, :config\n\n    BENCHMARK_CATEGORIES = %i[\n      parsing\n      type_checking\n      compilation\n      incremental\n      parallel\n      memory\n    ].freeze\n\n    def initialize(config = nil)\n      @config = config || Config.new\n      @results = {}\n      @compiler = nil\n      @type_checker = nil\n    end\n\n    # Run all benchmarks\n    def run_all(iterations: 5, warmup: 2)\n      puts "T-Ruby Benchmark Suite"\n      puts "=" * 60\n      puts "Iterations: #{iterations}, Warmup: #{warmup}"\n      puts\n\n      BENCHMARK_CATEGORIES.each do |category|\n        run_category(category, iterations: iterations, warmup: warmup)\n      end\n\n      print_summary\n      @results\n    end\n\n    # Run specific category\n    def run_category(category, iterations: 5, warmup: 2)\n      puts "Running #{category} benchmarks..."\n      puts "-" * 40\n\n      @results[category] = case category\n                           when :parsing then benchmark_parsing(iterations, warmup)\n                           when :type_checking then benchmark_type_checking(iterations, warmup)\n                           when :compilation then benchmark_compilation(iterations, warmup)\n                           when :incremental then benchmark_incremental(iterations, warmup)\n                           when :parallel then benchmark_parallel(iterations, warmup)\n                           when :memory then benchmark_memory\n                           end\n\n      puts\n    end\n\n    # Export results to JSON\n    def export_json(path = "benchmark_results.json")\n      File.write(path, JSON.pretty_generate({\n                                              timestamp: Time.now.iso8601,\n                                              ruby_version: RUBY_VERSION,\n                                              platform: RUBY_PLATFORM,\n                                              results: @results,\n                                            }))\n    end\n\n    # Export results to Markdown\n    def export_markdown(path = "benchmark_results.md")\n      md = []\n      md << "# T-Ruby Benchmark Results"\n      md << ""\n      md << "**Generated:** #{Time.now}"\n      md << "**Ruby Version:** #{RUBY_VERSION}"\n      md << "**Platform:** #{RUBY_PLATFORM}"\n      md << ""\n\n      @results.each do |category, benchmarks|\n        md << "## #{category.to_s.capitalize}"\n        md << ""\n        md << "| Benchmark | Time (ms) | Memory (KB) | Iterations/sec |"\n        md << "|-----------|-----------|-------------|----------------|"\n\n        benchmarks.each do |name, data|\n          time_ms = (data[:avg_time] * 1000).round(2)\n          memory_kb = (data[:memory] || 0).round(2)\n          ips = data[:avg_time].positive? ? (1.0 / data[:avg_time]).round(2) : 0\n          md << "| #{name} | #{time_ms} | #{memory_kb} | #{ips} |"\n        end\n        md << ""\n      end\n\n      File.write(path, md.join("\\n"))\n    end\n\n    # Compare with previous results\n    def compare(previous_path)\n      return nil unless File.exist?(previous_path)\n\n      previous = JSON.parse(File.read(previous_path), symbolize_names: true)\n      comparison = {}\n\n      @results.each do |category, benchmarks|\n        prev_cat = previous[:results][category]\n        next unless prev_cat\n\n        comparison[category] = {}\n        benchmarks.each do |name, data|\n          prev_data = prev_cat[name]\n          next unless prev_data\n\n          diff = ((data[:avg_time] - prev_data[:avg_time]) / prev_data[:avg_time] * 100).round(2)\n          comparison[category][name] = {\n            current: data[:avg_time],\n            previous: prev_data[:avg_time],\n            diff_percent: diff,\n            improved: diff.negative?,\n          }\n        end\n      end\n\n      comparison\n    end\n\n    private\n\n    def compiler\n      @compiler ||= Compiler.new(@config)\n    end\n\n    def type_checker\n      @type_checker ||= TypeChecker.new\n    end\n\n    # Parsing benchmarks\n    def benchmark_parsing(iterations, warmup)\n      test_files = generate_test_files(:parsing)\n      results = {}\n\n      test_files.each do |name, content|\n        times = []\n\n        # Warmup\n        warmup.times { Parser.new(content).parse }\n\n        # Actual benchmark\n        iterations.times do\n          time = Benchmark.realtime { Parser.new(content).parse }\n          times << time\n        end\n\n        results[name] = calculate_stats(times)\n        print_result(name, results[name])\n      end\n\n      results\n    end\n\n    # Type checking benchmarks\n    def benchmark_type_checking(iterations, warmup)\n      test_cases = generate_test_files(:type_checking)\n      results = {}\n\n      test_cases.each do |name, content|\n        times = []\n        ast = Parser.new(content).parse\n\n        # Warmup\n        warmup.times { TypeChecker.new.check(ast) }\n\n        # Actual benchmark\n        iterations.times do\n          checker = TypeChecker.new\n          time = Benchmark.realtime { checker.check(ast) }\n          times << time\n        end\n\n        results[name] = calculate_stats(times)\n        print_result(name, results[name])\n      end\n\n      results\n    end\n\n    # Compilation benchmarks\n    def benchmark_compilation(iterations, warmup)\n      test_cases = generate_test_files(:compilation)\n      results = {}\n\n      Dir.mktmpdir("trb_bench") do |tmpdir|\n        test_cases.each do |name, content|\n          input_path = File.join(tmpdir, "#{name}.trb")\n          File.write(input_path, content)\n\n          times = []\n\n          # Warmup\n          warmup.times { compiler.compile(input_path) }\n\n          # Actual benchmark\n          iterations.times do\n            time = Benchmark.realtime { compiler.compile(input_path) }\n            times << time\n          end\n\n          results[name] = calculate_stats(times)\n          print_result(name, results[name])\n        end\n      end\n\n      results\n    end\n\n    # Incremental compilation benchmarks\n    def benchmark_incremental(iterations, warmup)\n      results = {}\n\n      Dir.mktmpdir("trb_incr_bench") do |tmpdir|\n        # Create test files\n        files = 10.times.map do |i|\n          path = File.join(tmpdir, "file_#{i}.trb")\n          File.write(path, generate_test_content(i))\n          path\n        end\n\n        # Full compilation\n        full_times = []\n        warmup.times { IncrementalCompiler.new(compiler).compile_all(files) }\n        iterations.times do\n          ic = IncrementalCompiler.new(compiler)\n          time = Benchmark.realtime { ic.compile_all(files) }\n          full_times << time\n        end\n        results[:full_compile] = calculate_stats(full_times)\n        print_result(:full_compile, results[:full_compile])\n\n        # Incremental (single file change)\n        incr_times = []\n        ic = IncrementalCompiler.new(compiler)\n        ic.compile_all(files)\n\n        warmup.times do\n          File.write(files[0], generate_test_content(0, modified: true))\n          ic.compile_incremental([files[0]])\n        end\n\n        iterations.times do\n          File.write(files[0], generate_test_content(0, modified: true))\n          time = Benchmark.realtime { ic.compile_incremental([files[0]]) }\n          incr_times << time\n        end\n        results[:incremental_single] = calculate_stats(incr_times)\n        print_result(:incremental_single, results[:incremental_single])\n\n        # Calculate speedup\n        if results[:full_compile][:avg_time].positive?\n          speedup = results[:full_compile][:avg_time] / results[:incremental_single][:avg_time]\n          puts "  Incremental speedup: #{speedup.round(2)}x"\n        end\n      end\n\n      results\n    end\n\n    # Parallel compilation benchmarks\n    def benchmark_parallel(iterations, warmup)\n      results = {}\n\n      Dir.mktmpdir("trb_parallel_bench") do |tmpdir|\n        # Create 20 test files\n        files = 20.times.map do |i|\n          path = File.join(tmpdir, "parallel_#{i}.trb")\n          File.write(path, generate_test_content(i))\n          path\n        end\n\n        # Sequential\n        seq_times = []\n        warmup.times do\n          files.each { |f| compiler.compile(f) }\n        end\n        iterations.times do\n          time = Benchmark.realtime do\n            files.each { |f| compiler.compile(f) }\n          end\n          seq_times << time\n        end\n        results[:sequential] = calculate_stats(seq_times)\n        print_result(:sequential, results[:sequential])\n\n        # Parallel (2 workers)\n        par2_times = []\n        processor = ParallelProcessor.new(workers: 2)\n        warmup.times { processor.process_files(files) { |f| compiler.compile(f) } }\n        iterations.times do\n          time = Benchmark.realtime do\n            processor.process_files(files) { |f| compiler.compile(f) }\n          end\n          par2_times << time\n        end\n        results[:parallel_2] = calculate_stats(par2_times)\n        print_result(:parallel_2, results[:parallel_2])\n\n        # Parallel (4 workers)\n        par4_times = []\n        processor4 = ParallelProcessor.new(workers: 4)\n        warmup.times { processor4.process_files(files) { |f| compiler.compile(f) } }\n        iterations.times do\n          time = Benchmark.realtime do\n            processor4.process_files(files) { |f| compiler.compile(f) }\n          end\n          par4_times << time\n        end\n        results[:parallel_4] = calculate_stats(par4_times)\n        print_result(:parallel_4, results[:parallel_4])\n\n        # Print speedups\n        if results[:sequential][:avg_time].positive?\n          puts "  Parallel(2) speedup: #{(results[:sequential][:avg_time] / results[:parallel_2][:avg_time]).round(2)}x"\n          puts "  Parallel(4) speedup: #{(results[:sequential][:avg_time] / results[:parallel_4][:avg_time]).round(2)}x"\n        end\n      end\n\n      results\n    end\n\n    # Memory benchmarks\n    def benchmark_memory\n      results = {}\n\n      # Baseline memory\n      GC.start\n      get_memory_usage\n\n      # Parser memory\n      content = generate_test_content(0)\n      GC.start\n      before = get_memory_usage\n      10.times { Parser.new(content).parse }\n      GC.start\n      after = get_memory_usage\n      results[:parsing] = { memory: (after - before) / 10.0, avg_time: 0, min_time: 0, max_time: 0, std_dev: 0 }\n      print_result(:parsing, results[:parsing], unit: "KB")\n\n      # Type checker memory\n      ast = Parser.new(content).parse\n      GC.start\n      before = get_memory_usage\n      10.times { TypeChecker.new.check(ast) }\n      GC.start\n      after = get_memory_usage\n      results[:type_checking] = { memory: (after - before) / 10.0, avg_time: 0, min_time: 0, max_time: 0, std_dev: 0 }\n      print_result(:type_checking, results[:type_checking], unit: "KB")\n\n      # Cache memory\n      GC.start\n      before = get_memory_usage\n      cache = CompilationCache.new\n      1000.times { |i| cache.set("key_#{i}", "value_#{i}") }\n      GC.start\n      after = get_memory_usage\n      results[:cache_1000] = { memory: after - before, avg_time: 0, min_time: 0, max_time: 0, std_dev: 0 }\n      print_result(:cache_1000, results[:cache_1000], unit: "KB")\n\n      results\n    end\n\n    def generate_test_files(category)\n      case category\n      when :parsing\n        {\n          small_file: generate_test_content(0, lines: 10),\n          medium_file: generate_test_content(0, lines: 100),\n          large_file: generate_test_content(0, lines: 500),\n          complex_types: generate_complex_types_content,\n        }\n      when :type_checking\n        {\n          simple_types: generate_simple_types_content,\n          generic_types: generate_generic_types_content,\n          union_types: generate_union_types_content,\n          interface_types: generate_interface_types_content,\n        }\n      when :compilation\n        {\n          minimal: "def hello: void; end",\n          with_types: generate_test_content(0, lines: 50),\n          with_interfaces: generate_interface_types_content,\n        }\n      else\n        {}\n      end\n    end\n\n    def generate_test_content(seed, lines: 50, modified: false)\n      content = []\n      content << "# Test file #{seed}#{" (modified)" if modified}"\n      content << ""\n      content << "type CustomType#{seed} = String | Integer | nil"\n      content << ""\n      content << "interface TestInterface#{seed}"\n      content << "  value: CustomType#{seed}"\n      content << "  process: Boolean"\n      content << "end"\n      content << ""\n\n      (lines - 10).times do |i|\n        content << "def method_#{seed}_#{i}(arg: String): Integer"\n        content << "  arg.length"\n        content << "end"\n        content << ""\n      end\n\n      content.join("\\n")\n    end\n\n    def generate_complex_types_content\n      <<~TRB\n        type DeepNested<T> = Hash<String, Array<Hash<Symbol, T>>>\n        type UnionOfGenerics<A, B> = Array<A> | Hash<String, B> | nil\n        type FunctionType = Proc<Integer> | Lambda<String>\n\n        interface ComplexInterface<T, U>\n          data: DeepNested<T>\n          transform: UnionOfGenerics<T, U>\n          callback: FunctionType\n        end\n\n        def complex_method<T>(\n          input: DeepNested<T>,\n          options: Hash<Symbol, String | Integer | Boolean>\n        ): UnionOfGenerics<T, String>\n          nil\n        end\n      TRB\n    end\n\n    def generate_simple_types_content\n      <<~TRB\n        def add(a: Integer, b: Integer): Integer\n          a + b\n        end\n\n        def greet(name: String): String\n          "Hello, \\#{name}"\n        end\n\n        def valid?(value: Boolean): Boolean\n          value\n        end\n      TRB\n    end\n\n    def generate_generic_types_content\n      <<~TRB\n        def first<T>(items: Array<T>): T | nil\n          items.first\n        end\n\n        def map_values<K, V, R>(hash: Hash<K, V>, &block: Proc<R>): Hash<K, R>\n          hash.transform_values(&block)\n        end\n\n        def wrap<T>(value: T): Array<T>\n          [value]\n        end\n      TRB\n    end\n\n    def generate_union_types_content\n      <<~TRB\n        type StringOrNumber = String | Integer\n        type NullableString = String | nil\n        type Status = "pending" | "active" | "completed"\n\n        def process(value: StringOrNumber): String\n          value.to_s\n        end\n\n        def safe_call(input: NullableString): String\n          input || "default"\n        end\n      TRB\n    end\n\n    def generate_interface_types_content\n      <<~TRB\n        interface Comparable<T>\n          <=>: Integer\n        end\n\n        interface Enumerable<T>\n          each: void\n          map: Array<T>\n          select: Array<T>\n        end\n\n        interface Repository<T>\n          find: T | nil\n          save: Boolean\n          delete: Boolean\n          all: Array<T>\n        end\n\n        def sort<T: Comparable<T>>(items: Array<T>): Array<T>\n          items.sort\n        end\n      TRB\n    end\n\n    def calculate_stats(times)\n      avg = times.sum / times.length.to_f\n      min = times.min\n      max = times.max\n      variance = times.map { |t| (t - avg)**2 }.sum / times.length.to_f\n      std_dev = Math.sqrt(variance)\n\n      {\n        avg_time: avg,\n        min_time: min,\n        max_time: max,\n        std_dev: std_dev,\n        iterations: times.length,\n      }\n    end\n\n    def print_result(name, stats, unit: "ms")\n      if unit == "KB"\n        puts "  #{name}: #{stats[:memory].round(2)} KB"\n      else\n        avg_ms = (stats[:avg_time] * 1000).round(3)\n        std_ms = (stats[:std_dev] * 1000).round(3)\n        puts "  #{name}: #{avg_ms}ms (\xb1#{std_ms}ms)"\n      end\n    end\n\n    def print_summary\n      puts "=" * 60\n      puts "SUMMARY"\n      puts "=" * 60\n\n      total_time = 0\n      @results.each do |category, benchmarks|\n        cat_time = benchmarks.values.sum { |b| b[:avg_time] || 0 }\n        total_time += cat_time\n        puts "#{category}: #{(cat_time * 1000).round(2)}ms total"\n      end\n\n      puts "-" * 40\n      puts "Total benchmark time: #{(total_time * 1000).round(2)}ms"\n    end\n\n    def get_memory_usage\n      # Returns memory in KB\n      if RUBY_PLATFORM =~ /linux/\n        File.read("/proc/#{Process.pid}/statm").split[1].to_i * 4 # pages * 4KB\n      else\n        # Fallback using GC stats\n        GC.stat[:heap_live_slots] * 40 / 1024.0 # approximate\n      end\n    end\n  end\n\n  # Quick benchmark helper\n  module QuickBenchmark\n    def self.measure(name = "Operation", iterations: 100)\n      times = []\n\n      iterations.times do\n        start = Process.clock_gettime(Process::CLOCK_MONOTONIC)\n        yield\n        times << (Process.clock_gettime(Process::CLOCK_MONOTONIC) - start)\n      end\n\n      avg = times.sum / times.length\n      puts "#{name}: #{(avg * 1000).round(3)}ms avg (#{iterations} iterations)"\n\n      avg\n    end\n\n    def self.compare(name, &block)\n      before = Process.clock_gettime(Process::CLOCK_MONOTONIC)\n      result = block.call\n      after = Process.clock_gettime(Process::CLOCK_MONOTONIC)\n\n      puts "#{name}: #{((after - before) * 1000).round(3)}ms"\n      result\n    end\n  end\nend\n',"lib/t_ruby/bundler_integration.rb":'# frozen_string_literal: true\n\nrequire "fileutils"\nrequire "time"\n\nmodule TRuby\n  # Integrates T-Ruby type packages with Bundler/RubyGems ecosystem\n  class BundlerIntegration\n    TYPES_GROUP = :types\n    TYPE_SUFFIX = "-types"\n    GEMFILE = "Gemfile"\n    GEMFILE_LOCK = "Gemfile.lock"\n\n    attr_reader :project_dir, :errors\n\n    def initialize(project_dir: ".")\n      @project_dir = project_dir\n      @errors = []\n      @type_gems = {}\n    end\n\n    # Check if project uses Bundler\n    def bundler_project?\n      File.exist?(gemfile_path)\n    end\n\n    # Initialize T-Ruby types support in existing Bundler project\n    def init\n      unless bundler_project?\n        @errors << "No Gemfile found. Run \'bundle init\' first."\n        return false\n      end\n\n      add_types_group_to_gemfile unless types_group_exists?\n      create_types_directory\n      true\n    end\n\n    # Find type packages for installed gems\n    def discover_type_packages\n      return {} unless bundler_project?\n\n      installed_gems = parse_gemfile_lock\n      type_packages = {}\n\n      installed_gems.each_key do |gem_name|\n        type_gem = find_type_gem(gem_name)\n        type_packages[gem_name] = type_gem if type_gem\n      end\n\n      type_packages\n    end\n\n    # Add a type package dependency\n    def add_type_gem(gem_name, version: nil)\n      type_gem_name = "#{gem_name}#{TYPE_SUFFIX}"\n      version_constraint = version || ">= 0"\n\n      append_to_gemfile(type_gem_name, version_constraint, group: TYPES_GROUP)\n      @type_gems[gem_name] = { name: type_gem_name, version: version_constraint }\n\n      { gem: type_gem_name, version: version_constraint, status: :added }\n    end\n\n    # Remove a type package dependency\n    def remove_type_gem(gem_name)\n      type_gem_name = "#{gem_name}#{TYPE_SUFFIX}"\n      remove_from_gemfile(type_gem_name)\n      @type_gems.delete(gem_name)\n\n      { gem: type_gem_name, status: :removed }\n    end\n\n    # Sync type definitions from installed type gems\n    def sync_types\n      return { synced: [], errors: @errors } unless bundler_project?\n\n      synced = []\n      type_gems = find_installed_type_gems\n\n      type_gems.each do |gem_info|\n        result = sync_gem_types(gem_info)\n        synced << result if result[:success]\n      end\n\n      { synced: synced, errors: @errors }\n    end\n\n    # Generate a .trb-bundle.json manifest for compatibility\n    def generate_bundle_manifest\n      manifest = {\n        bundler_integration: true,\n        version: TRuby::VERSION,\n        types_group: TYPES_GROUP.to_s,\n        type_gems: list_type_gems,\n        local_types: list_local_types,\n        generated_at: Time.now.iso8601,\n      }\n\n      manifest_path = File.join(@project_dir, ".trb-bundle.json")\n      File.write(manifest_path, JSON.pretty_generate(manifest))\n      manifest_path\n    end\n\n    # Load type definitions from Bundler-managed gems\n    def load_bundled_types\n      type_definitions = {}\n\n      find_installed_type_gems.each do |gem_info|\n        defs = load_gem_type_definitions(gem_info)\n        type_definitions.merge!(defs)\n      end\n\n      # Also load local types\n      local_types = load_local_type_definitions\n      type_definitions.merge!(local_types)\n\n      type_definitions\n    end\n\n    # Check compatibility between gem version and type version\n    def check_version_compatibility\n      issues = []\n      gemfile_lock = parse_gemfile_lock\n\n      @type_gems.each do |base_gem, type_info|\n        base_version = gemfile_lock[base_gem]\n        type_version = gemfile_lock[type_info[:name]]\n\n        next unless base_version && type_version\n\n        next if versions_compatible?(base_version, type_version)\n\n        issues << {\n          gem: base_gem,\n          gem_version: base_version,\n          type_gem: type_info[:name],\n          type_version: type_version,\n          message: "Version mismatch: #{base_gem}@#{base_version} vs #{type_info[:name]}@#{type_version}",\n        }\n      end\n\n      issues\n    end\n\n    # Create a new type gem scaffold\n    def create_type_gem_scaffold(gem_name, output_dir: nil)\n      type_gem_name = "#{gem_name}#{TYPE_SUFFIX}"\n      output = output_dir || File.join(@project_dir, type_gem_name)\n\n      FileUtils.mkdir_p(output)\n      FileUtils.mkdir_p(File.join(output, "lib", type_gem_name.gsub("-", "_")))\n      FileUtils.mkdir_p(File.join(output, "sig"))\n\n      # Create gemspec\n      create_type_gemspec(type_gem_name, gem_name, output)\n\n      # Create main type file\n      create_main_type_file(type_gem_name, gem_name, output)\n\n      # Create README\n      create_type_gem_readme(type_gem_name, gem_name, output)\n\n      { path: output, gem_name: type_gem_name, status: :created }\n    end\n\n    private\n\n    def gemfile_path\n      File.join(@project_dir, GEMFILE)\n    end\n\n    def gemfile_lock_path\n      File.join(@project_dir, GEMFILE_LOCK)\n    end\n\n    def types_group_exists?\n      return false unless File.exist?(gemfile_path)\n\n      content = File.read(gemfile_path)\n      content.include?("group :#{TYPES_GROUP}") || content.include?("group :types")\n    end\n\n    def add_types_group_to_gemfile\n      content = File.read(gemfile_path)\n\n      types_group = <<~RUBY\n\n        # T-Ruby type definitions\n        group :types do\n          # Add type gems here, e.g.:\n          # gem \'rails-types\', \'~> 7.0\'\n        end\n      RUBY\n\n      File.write(gemfile_path, content + types_group)\n    end\n\n    def create_types_directory\n      types_dir = File.join(@project_dir, "types")\n      FileUtils.mkdir_p(types_dir)\n\n      # Create a sample .d.trb file\n      sample_path = File.join(types_dir, "custom.d.trb")\n      return if File.exist?(sample_path)\n\n      File.write(sample_path, <<~TRB)\n        # Custom type definitions for your project\n        # These types are available throughout your T-Ruby code\n\n        # Example type alias\n        # type UserId = String\n\n        # Example interface\n        # interface Serializable\n        #   to_json: String\n        #   from_json: (String) -> self\n        # end\n      TRB\n    end\n\n    def append_to_gemfile(gem_name, version, group:)\n      content = File.read(gemfile_path)\n\n      # Find the types group and add gem there\n      if content.include?("group :#{group}")\n        # Add inside existing group\n        new_content = content.gsub(\n          /(group :#{group}.*?do\\s*\\n)/m,\n          "\\\\1  gem \'#{gem_name}\', \'#{version}\'\\n"\n        )\n        File.write(gemfile_path, new_content)\n      else\n        # Create group with gem\n        File.write(gemfile_path, content + <<~RUBY)\n\n          group :#{group} do\n            gem \'#{gem_name}\', \'#{version}\'\n          end\n        RUBY\n      end\n    end\n\n    def remove_from_gemfile(gem_name)\n      content = File.read(gemfile_path)\n      new_content = content.gsub(/^\\s*gem [\'"]#{gem_name}[\'"].*$\\n?/, "")\n      File.write(gemfile_path, new_content)\n    end\n\n    def parse_gemfile_lock\n      return {} unless File.exist?(gemfile_lock_path)\n\n      gems = {}\n      in_specs = false\n\n      File.readlines(gemfile_lock_path).each do |line|\n        if line.strip == "specs:"\n          in_specs = true\n          next\n        end\n\n        if in_specs && line.match?(/^\\s{4}(\\S+)\\s+\\((.+)\\)/)\n          match = line.match(/^\\s{4}(\\S+)\\s+\\((.+)\\)/)\n          gems[match[1]] = match[2]\n        end\n\n        in_specs = false if in_specs && !line.start_with?("  ")\n      end\n\n      gems\n    end\n\n    def find_type_gem(gem_name)\n      type_gem_name = "#{gem_name}#{TYPE_SUFFIX}"\n\n      # Check if type gem exists in known registries\n      # This is a simplified check - in production would query RubyGems API\n      {\n        name: type_gem_name,\n        available: check_gem_availability(type_gem_name),\n      }\n    end\n\n    def check_gem_availability(gem_name)\n      # Simplified availability check\n      # In production, would use: Gem::SpecFetcher.fetcher.detect(:latest)\n      # For now, return based on common type packages\n      common_type_gems = %w[\n        rails-types\n        activerecord-types\n        activesupport-types\n        rspec-types\n        sidekiq-types\n        redis-types\n        pg-types\n      ]\n\n      common_type_gems.include?(gem_name)\n    end\n\n    def find_installed_type_gems\n      gems = parse_gemfile_lock\n      gems.select { |name, _| name.end_with?(TYPE_SUFFIX) }.map do |name, version|\n        base_gem = name.sub(/#{TYPE_SUFFIX}$/, "")\n        {\n          name: name,\n          base_gem: base_gem,\n          version: version,\n          path: find_gem_path(name, version),\n        }\n      end\n    end\n\n    def find_gem_path(gem_name, version)\n      # Try to find gem in standard locations\n      possible_paths = [\n        File.join(ENV["GEM_HOME"] || "", "gems", "#{gem_name}-#{version}"),\n        File.join(Dir.home, ".gem", "ruby", "*", "gems", "#{gem_name}-#{version}"),\n        File.join(@project_dir, "vendor", "bundle", "**", "gems", "#{gem_name}-#{version}"),\n      ]\n\n      possible_paths.each do |pattern|\n        matches = Dir.glob(pattern)\n        return matches.first if matches.any?\n      end\n\n      nil\n    end\n\n    def sync_gem_types(gem_info)\n      return { success: false, gem: gem_info[:name] } unless gem_info[:path]\n\n      # Look for type definitions in the gem\n      type_files = Dir.glob(File.join(gem_info[:path], "**", "*.d.trb"))\n      rbs_files = Dir.glob(File.join(gem_info[:path], "sig", "**", "*.rbs"))\n\n      target_dir = File.join(@project_dir, ".trb-types", gem_info[:name])\n      FileUtils.mkdir_p(target_dir)\n\n      copied = []\n\n      (type_files + rbs_files).each do |file|\n        target = File.join(target_dir, File.basename(file))\n        FileUtils.cp(file, target)\n        copied << target\n      end\n\n      { success: true, gem: gem_info[:name], files: copied }\n    end\n\n    def load_gem_type_definitions(gem_info)\n      definitions = {}\n      return definitions unless gem_info[:path]\n\n      type_files = Dir.glob(File.join(gem_info[:path], "**", "*.d.trb"))\n\n      type_files.each do |file|\n        content = File.read(file)\n        parsed = parse_type_definitions(content)\n        definitions.merge!(parsed)\n      end\n\n      definitions\n    end\n\n    def load_local_type_definitions\n      definitions = {}\n      types_dir = File.join(@project_dir, "types")\n\n      return definitions unless Dir.exist?(types_dir)\n\n      Dir.glob(File.join(types_dir, "**", "*.d.trb")).each do |file|\n        content = File.read(file)\n        parsed = parse_type_definitions(content)\n        definitions.merge!(parsed)\n      end\n\n      definitions\n    end\n\n    def parse_type_definitions(content)\n      definitions = {}\n\n      # Parse type aliases\n      content.scan(/^\\s*type\\s+(\\w+)\\s*=\\s*(.+)$/).each do |match|\n        definitions[match[0]] = { kind: :alias, definition: match[1] }\n      end\n\n      # Parse interfaces\n      content.scan(/^\\s*interface\\s+(\\w+)/).each do |match|\n        definitions[match[0]] = { kind: :interface }\n      end\n\n      definitions\n    end\n\n    def list_type_gems\n      find_installed_type_gems.map do |gem_info|\n        {\n          name: gem_info[:name],\n          base_gem: gem_info[:base_gem],\n          version: gem_info[:version],\n        }\n      end\n    end\n\n    def list_local_types\n      types_dir = File.join(@project_dir, "types")\n      return [] unless Dir.exist?(types_dir)\n\n      Dir.glob(File.join(types_dir, "**", "*.d.trb")).map do |file|\n        File.basename(file)\n      end\n    end\n\n    def versions_compatible?(gem_version, type_version)\n      # Check if major.minor versions match\n      gem_parts = gem_version.split(".")\n      type_parts = type_version.split(".")\n\n      gem_parts[0] == type_parts[0] && gem_parts[1] == type_parts[1]\n    end\n\n    def create_type_gemspec(type_gem_name, base_gem, output_dir)\n      gemspec_content = <<~RUBY\n        # frozen_string_literal: true\n\n        Gem::Specification.new do |spec|\n          spec.name          = "#{type_gem_name}"\n          spec.version       = "0.1.0"\n          spec.authors       = ["Your Name"]\n          spec.email         = ["your.email@example.com"]\n\n          spec.summary       = "T-Ruby type definitions for #{base_gem}"\n          spec.description   = "Type definitions for #{base_gem} to be used with T-Ruby"\n          spec.homepage      = "https://github.com/your-username/#{type_gem_name}"\n          spec.license       = "MIT"\n          spec.required_ruby_version = ">= 3.0.0"\n\n          spec.metadata["rubygems_mfa_required"] = "true"\n          spec.metadata["source_code_uri"] = spec.homepage\n          spec.metadata["changelog_uri"] = "\\#{spec.homepage}/blob/main/CHANGELOG.md"\n\n          spec.files = Dir.glob("{lib,sig}/**/*") + %w[README.md LICENSE.txt]\n          spec.require_paths = ["lib"]\n\n          # Match the base gem version\n          spec.add_dependency "#{base_gem}"\n        end\n      RUBY\n\n      File.write(File.join(output_dir, "#{type_gem_name}.gemspec"), gemspec_content)\n    end\n\n    def create_main_type_file(type_gem_name, base_gem, output_dir)\n      module_name = type_gem_name.gsub("-", "_").split("_").map(&:capitalize).join\n      lib_dir = File.join(output_dir, "lib", type_gem_name.gsub("-", "_"))\n\n      main_file = <<~RUBY\n        # frozen_string_literal: true\n\n        # Type definitions for #{base_gem}\n        # Auto-generated scaffold - customize as needed\n\n        module #{module_name}\n          VERSION = "0.1.0"\n        end\n      RUBY\n\n      File.write(File.join(lib_dir, "version.rb"), main_file)\n\n      # Create types directory and sample file\n      types_dir = File.join(output_dir, "sig")\n      FileUtils.mkdir_p(types_dir)\n\n      types_file = <<~TRB\n        # Type definitions for #{base_gem}\n        # Add your type definitions here\n\n        # Example:\n        # interface #{base_gem.capitalize}Client\n        #   connect: (String) -> Boolean\n        #   disconnect: () -> void\n        # end\n      TRB\n\n      File.write(File.join(types_dir, "#{base_gem}.d.trb"), types_file)\n    end\n\n    def create_type_gem_readme(type_gem_name, base_gem, output_dir)\n      readme = <<~MARKDOWN\n        # #{type_gem_name}\n\n        T-Ruby type definitions for [#{base_gem}](https://rubygems.org/gems/#{base_gem}).\n\n        ## Installation\n\n        Add this line to your Gemfile:\n\n        ```ruby\n        group :types do\n          gem \'#{type_gem_name}\'\n        end\n        ```\n\n        Then run:\n\n        ```bash\n        bundle install\n        ```\n\n        ## Usage\n\n        The type definitions will be automatically loaded by T-Ruby when compiling your `.trb` files.\n\n        ## Contributing\n\n        Bug reports and pull requests are welcome.\n\n        ## License\n\n        MIT License\n      MARKDOWN\n\n      File.write(File.join(output_dir, "README.md"), readme)\n    end\n  end\n\n  # Extension to PackageManager for Bundler support\n  class PackageManager\n    attr_reader :bundler\n\n    def initialize(project_dir: ".")\n      @project_dir = project_dir\n      @manifest = PackageManifest.load(File.join(project_dir, PackageManifest::MANIFEST_FILE))\n      @registry = PackageRegistry.new(local_path: File.join(project_dir, ".trb-packages"))\n      @resolver = DependencyResolver.new(@registry)\n      @bundler = BundlerIntegration.new(project_dir: project_dir)\n    end\n\n    # Use Bundler if available, fall back to native package management\n    def install_with_bundler_fallback\n      if @bundler.bundler_project?\n        @bundler.sync_types\n      else\n        install\n      end\n    end\n\n    # Migrate from native T-Ruby packages to Bundler\n    def migrate_to_bundler\n      return { success: false, error: "Not a Bundler project" } unless @bundler.bundler_project?\n\n      migrated = []\n\n      # Read existing T-Ruby manifest\n      @manifest&.dependencies&.each do |name, version|\n        result = @bundler.add_type_gem(name, version: version)\n        migrated << result\n      end\n\n      # Generate new bundle manifest\n      @bundler.generate_bundle_manifest\n\n      { success: true, migrated: migrated }\n    end\n  end\nend\n',"lib/t_ruby/cache.rb":'# frozen_string_literal: true\n\nrequire "digest"\nrequire "json"\nrequire "fileutils"\n\nmodule TRuby\n  # Cache entry with metadata\n  class CacheEntry\n    attr_reader :key, :value, :created_at, :accessed_at, :hits\n\n    def initialize(key, value)\n      @key = key\n      @value = value\n      @created_at = Time.now\n      @accessed_at = Time.now\n      @hits = 0\n    end\n\n    def access\n      @accessed_at = Time.now\n      @hits += 1\n      @value\n    end\n\n    def stale?(max_age)\n      Time.now - @created_at > max_age\n    end\n\n    def to_h\n      {\n        key: @key,\n        value: @value,\n        created_at: @created_at.to_i,\n        hits: @hits,\n      }\n    end\n  end\n\n  # In-memory LRU cache\n  class MemoryCache\n    attr_reader :max_size, :hits, :misses\n\n    def initialize(max_size: 1000)\n      @max_size = max_size\n      @cache = {}\n      @access_order = []\n      @hits = 0\n      @misses = 0\n      @mutex = Mutex.new\n    end\n\n    def get(key)\n      @mutex.synchronize do\n        if @cache.key?(key)\n          @hits += 1\n          touch(key)\n          @cache[key].access\n        else\n          @misses += 1\n          nil\n        end\n      end\n    end\n\n    def set(key, value)\n      @mutex.synchronize do\n        evict if @cache.size >= @max_size && !@cache.key?(key)\n\n        @cache[key] = CacheEntry.new(key, value)\n        touch(key)\n        value\n      end\n    end\n\n    def delete(key)\n      @mutex.synchronize do\n        @cache.delete(key)\n        @access_order.delete(key)\n      end\n    end\n\n    def clear\n      @mutex.synchronize do\n        @cache.clear\n        @access_order.clear\n        @hits = 0\n        @misses = 0\n      end\n    end\n\n    def size\n      @cache.size\n    end\n\n    def hit_rate\n      total = @hits + @misses\n      return 0.0 if total.zero?\n\n      @hits.to_f / total\n    end\n\n    def stats\n      {\n        size: size,\n        max_size: @max_size,\n        hits: @hits,\n        misses: @misses,\n        hit_rate: hit_rate,\n      }\n    end\n\n    private\n\n    def touch(key)\n      @access_order.delete(key)\n      @access_order.push(key)\n    end\n\n    def evict\n      return if @access_order.empty?\n\n      # Evict least recently used\n      oldest_key = @access_order.shift\n      @cache.delete(oldest_key)\n    end\n  end\n\n  # File-based persistent cache\n  class FileCache\n    attr_reader :cache_dir, :max_age\n\n    def initialize(cache_dir: ".t-ruby-cache", max_age: 3600)\n      @cache_dir = cache_dir\n      @max_age = max_age\n      FileUtils.mkdir_p(@cache_dir)\n    end\n\n    def get(key)\n      path = cache_path(key)\n      return nil unless File.exist?(path)\n\n      # Check if stale\n      if File.mtime(path) < Time.now - @max_age\n        File.delete(path)\n        return nil\n      end\n\n      data = File.read(path)\n      JSON.parse(data, symbolize_names: true)\n    rescue JSON::ParserError\n      File.delete(path)\n      nil\n    end\n\n    def set(key, value)\n      path = cache_path(key)\n      File.write(path, JSON.generate(value))\n      value\n    end\n\n    def delete(key)\n      path = cache_path(key)\n      FileUtils.rm_f(path)\n    end\n\n    def clear\n      FileUtils.rm_rf(@cache_dir)\n      FileUtils.mkdir_p(@cache_dir)\n    end\n\n    def prune\n      Dir.glob(File.join(@cache_dir, "*.json")).each do |path|\n        File.delete(path) if File.mtime(path) < Time.now - @max_age\n      end\n    end\n\n    private\n\n    def cache_path(key)\n      hash = Digest::SHA256.hexdigest(key.to_s)[0, 16]\n      File.join(@cache_dir, "#{hash}.json")\n    end\n  end\n\n  # AST parse tree cache\n  class ParseCache\n    def initialize(memory_cache: nil, file_cache: nil)\n      @memory_cache = memory_cache || MemoryCache.new(max_size: 500)\n      @file_cache = file_cache\n    end\n\n    def get(source)\n      key = source_key(source)\n\n      # Try memory first\n      result = @memory_cache.get(key)\n      return result if result\n\n      # Try file cache\n      if @file_cache\n        result = @file_cache.get(key)\n        if result\n          @memory_cache.set(key, result)\n          return result\n        end\n      end\n\n      nil\n    end\n\n    def set(source, parse_result)\n      key = source_key(source)\n\n      @memory_cache.set(key, parse_result)\n      @file_cache&.set(key, parse_result)\n\n      parse_result\n    end\n\n    def invalidate(source)\n      key = source_key(source)\n      @memory_cache.delete(key)\n      @file_cache&.delete(key)\n    end\n\n    def stats\n      @memory_cache.stats\n    end\n\n    private\n\n    def source_key(source)\n      Digest::SHA256.hexdigest(source)\n    end\n  end\n\n  # Type resolution cache\n  class TypeResolutionCache\n    def initialize\n      @cache = MemoryCache.new(max_size: 2000)\n    end\n\n    def get(type_expression)\n      @cache.get(type_expression)\n    end\n\n    def set(type_expression, resolved_type)\n      @cache.set(type_expression, resolved_type)\n    end\n\n    def clear\n      @cache.clear\n    end\n\n    def stats\n      @cache.stats\n    end\n  end\n\n  # Declaration file cache\n  class DeclarationCache\n    def initialize(cache_dir: ".t-ruby-cache/declarations")\n      @file_cache = FileCache.new(cache_dir: cache_dir, max_age: 86_400) # 24 hours\n      @memory_cache = MemoryCache.new(max_size: 200)\n    end\n\n    def get(file_path)\n      # Check modification time\n      return nil unless File.exist?(file_path)\n\n      mtime = File.mtime(file_path).to_i\n      cache_key = "#{file_path}:#{mtime}"\n\n      # Try memory first\n      result = @memory_cache.get(cache_key)\n      return result if result\n\n      # Try file cache\n      result = @file_cache.get(cache_key)\n      if result\n        @memory_cache.set(cache_key, result)\n        return result\n      end\n\n      nil\n    end\n\n    def set(file_path, declarations)\n      mtime = File.mtime(file_path).to_i\n      cache_key = "#{file_path}:#{mtime}"\n\n      @memory_cache.set(cache_key, declarations)\n      @file_cache.set(cache_key, declarations)\n\n      declarations\n    end\n\n    def clear\n      @memory_cache.clear\n      @file_cache.clear\n    end\n  end\n\n  # Incremental compilation support\n  class IncrementalCompiler\n    attr_reader :file_hashes, :dependencies\n\n    def initialize(compiler, cache: nil)\n      @compiler = compiler\n      @cache = cache || ParseCache.new\n      @file_hashes = {}\n      @dependencies = {}\n      @compiled_files = {}\n    end\n\n    # Check if file needs recompilation\n    def needs_compile?(file_path)\n      return true unless File.exist?(file_path)\n\n      current_hash = compute_file_hash(file_path)\n      stored_hash = @file_hashes[file_path]\n\n      return true if stored_hash.nil? || stored_hash != current_hash\n\n      # Check dependencies\n      deps = @dependencies[file_path] || []\n      deps.any? { |dep| needs_compile?(dep) }\n    end\n\n    # Compile file with caching\n    def compile(file_path)\n      return @compiled_files[file_path] unless needs_compile?(file_path)\n\n      result = @compiler.compile(file_path)\n      @file_hashes[file_path] = compute_file_hash(file_path)\n      @compiled_files[file_path] = result\n\n      result\n    end\n\n    # Compile multiple files, skipping unchanged\n    def compile_all(file_paths)\n      results = {}\n      to_compile = file_paths.select { |f| needs_compile?(f) }\n\n      to_compile.each do |file_path|\n        results[file_path] = compile(file_path)\n      end\n\n      results\n    end\n\n    # Register dependency between files\n    def add_dependency(file_path, depends_on)\n      @dependencies[file_path] ||= []\n      @dependencies[file_path] << depends_on unless @dependencies[file_path].include?(depends_on)\n    end\n\n    # Clear compilation cache\n    def clear\n      @file_hashes.clear\n      @dependencies.clear\n      @compiled_files.clear\n      @cache.stats # Just accessing for potential cleanup\n    end\n\n    # Update file hash after external compile (for watcher integration)\n    def update_file_hash(file_path)\n      @file_hashes[file_path] = compute_file_hash(file_path)\n    end\n\n    private\n\n    def compute_file_hash(file_path)\n      return nil unless File.exist?(file_path)\n\n      Digest::SHA256.hexdigest(File.read(file_path))\n    end\n  end\n\n  # Parallel file processor\n  class ParallelProcessor\n    attr_reader :thread_count\n\n    def initialize(thread_count: nil)\n      @thread_count = thread_count || determine_thread_count\n    end\n\n    # Process files in parallel\n    def process_files(file_paths, &block)\n      return [] if file_paths.empty?\n\n      # Split into batches\n      batches = file_paths.each_slice(batch_size(file_paths.length)).to_a\n\n      results = []\n      mutex = Mutex.new\n\n      threads = batches.map do |batch|\n        Thread.new do\n          batch_results = batch.map { |file| block.call(file) }\n          mutex.synchronize { results.concat(batch_results) }\n        end\n      end\n\n      threads.each(&:join)\n      results\n    end\n\n    # Process with work stealing\n    def process_with_queue(file_paths, &block)\n      queue = Queue.new\n      file_paths.each { |f| queue << f }\n\n      results = []\n      mutex = Mutex.new\n\n      threads = @thread_count.times.map do\n        Thread.new do\n          loop do\n            file = begin\n              queue.pop(true)\n            rescue StandardError\n              break\n            end\n            result = block.call(file)\n            mutex.synchronize { results << result }\n          end\n        end\n      end\n\n      threads.each(&:join)\n      results\n    end\n\n    private\n\n    def determine_thread_count\n      # Use number of CPU cores, max 8\n      [Etc.nprocessors, 8].min\n    rescue StandardError\n      4\n    end\n\n    def batch_size(total)\n      [total / @thread_count, 1].max\n    end\n  end\n\n  # Cross-file Type Checker\n  class CrossFileTypeChecker\n    attr_reader :errors, :warnings, :file_types\n\n    def initialize(type_checker: nil)\n      @type_checker = type_checker || TypeChecker.new\n      @file_types = {} # file_path => { types: [], functions: [], interfaces: [] }\n      @global_registry = {} # name => { file: path, kind: :type/:func/:interface, definition: ... }\n      @errors = []\n      @warnings = []\n    end\n\n    # Register types from a file\n    def register_file(file_path, ir_program)\n      types = []\n      functions = []\n      interfaces = []\n\n      ir_program.declarations.each do |decl|\n        case decl\n        when IR::TypeAlias\n          types << { name: decl.name, definition: decl.definition }\n          register_global(decl.name, file_path, :type, decl)\n        when IR::Interface\n          interfaces << { name: decl.name, members: decl.members }\n          register_global(decl.name, file_path, :interface, decl)\n        when IR::MethodDef\n          functions << { name: decl.name, params: decl.params, return_type: decl.return_type }\n          register_global(decl.name, file_path, :function, decl)\n        end\n      end\n\n      @file_types[file_path] = { types: types, functions: functions, interfaces: interfaces }\n    end\n\n    # Check cross-file type consistency\n    def check_all\n      @errors = []\n      @warnings = []\n\n      # Check for duplicate definitions\n      check_duplicate_definitions\n\n      # Check for unresolved type references\n      check_unresolved_references\n\n      # Check interface implementations\n      check_interface_implementations\n\n      {\n        success: @errors.empty?,\n        errors: @errors,\n        warnings: @warnings,\n      }\n    end\n\n    # Check a specific file against global types\n    def check_file(file_path, ir_program)\n      file_errors = []\n\n      ir_program.declarations.each do |decl|\n        case decl\n        when IR::MethodDef\n          # Check parameter types\n          decl.params.each do |param|\n            next unless param.type_annotation && !type_exists?(param.type_annotation)\n\n            file_errors << {\n              file: file_path,\n              message: "Unknown type \'#{type_name(param.type_annotation)}\' in parameter \'#{param.name}\'",\n            }\n          end\n\n          # Check return type\n          if decl.return_type && !type_exists?(decl.return_type)\n            file_errors << {\n              file: file_path,\n              message: "Unknown return type \'#{type_name(decl.return_type)}\' in function \'#{decl.name}\'",\n            }\n          end\n        end\n      end\n\n      file_errors\n    end\n\n    # Get all registered types\n    def all_types\n      @global_registry.keys\n    end\n\n    # Find where a type is defined\n    def find_definition(name)\n      @global_registry[name]\n    end\n\n    # Clear all registrations\n    def clear\n      @file_types.clear\n      @global_registry.clear\n      @errors.clear\n      @warnings.clear\n    end\n\n    private\n\n    def register_global(name, file_path, kind, definition)\n      if @global_registry[name] && @global_registry[name][:file] != file_path\n        # Duplicate definition from different file\n        @warnings << {\n          message: "#{kind.to_s.capitalize} \'#{name}\' defined in multiple files",\n          files: [@global_registry[name][:file], file_path],\n        }\n      end\n\n      @global_registry[name] = { file: file_path, kind: kind, definition: definition }\n    end\n\n    def check_duplicate_definitions\n      @global_registry.group_by { |_, v| v[:file] }.each do |file, entries|\n        # Check for duplicates within file\n        names = entries.map(&:first)\n        duplicates = names.select { |n| names.count(n) > 1 }.uniq\n\n        duplicates.each do |name|\n          @errors << {\n            file: file,\n            message: "Duplicate definition of \'#{name}\'",\n          }\n        end\n      end\n    end\n\n    def check_unresolved_references\n      @file_types.each do |file_path, info|\n        # Check type alias definitions for unresolved types\n        info[:types].each do |type_info|\n          referenced_types = extract_type_references(type_info[:definition])\n          referenced_types.each do |ref|\n            next if type_exists_by_name?(ref)\n\n            @errors << {\n              file: file_path,\n              message: "Unresolved type reference \'#{ref}\' in type alias \'#{type_info[:name]}\'",\n            }\n          end\n        end\n      end\n    end\n\n    def check_interface_implementations\n      # For future: check that classes implement all interface methods\n    end\n\n    def type_exists?(type_node)\n      case type_node\n      when IR::SimpleType\n        type_exists_by_name?(type_node.name)\n      when IR::GenericType\n        type_exists_by_name?(type_node.base)\n      when IR::UnionType\n        type_node.types.all? { |t| type_exists?(t) }\n      when IR::IntersectionType\n        type_node.types.all? { |t| type_exists?(t) }\n      when IR::NullableType\n        type_exists?(type_node.inner_type)\n      else\n        true # Assume valid for unknown types\n      end\n    end\n\n    def type_exists_by_name?(name)\n      return true if %w[String Integer Float Boolean Array Hash Symbol void nil Object Numeric\n                        Enumerable].include?(name)\n      return true if @global_registry[name]\n\n      false\n    end\n\n    def type_name(type_node)\n      case type_node\n      when IR::SimpleType\n        type_node.name\n      when IR::GenericType\n        "#{type_node.base}<...>"\n      else\n        type_node.to_s\n      end\n    end\n\n    def extract_type_references(definition)\n      return [] unless definition\n\n      case definition\n      when IR::SimpleType\n        [definition.name]\n      when IR::GenericType\n        [definition.base] + definition.type_args.flat_map { |t| extract_type_references(t) }\n      when IR::UnionType\n        definition.types.flat_map { |t| extract_type_references(t) }\n      when IR::IntersectionType\n        definition.types.flat_map { |t| extract_type_references(t) }\n      when IR::NullableType\n        extract_type_references(definition.inner_type)\n      else\n        []\n      end\n    end\n  end\n\n  # Enhanced Incremental Compiler with IR and Cross-file support\n  class EnhancedIncrementalCompiler < IncrementalCompiler\n    attr_reader :cross_file_checker, :ir_cache\n\n    def initialize(compiler, cache: nil, enable_cross_file: true)\n      super(compiler, cache: cache)\n      @ir_cache = {} # file_path => IR::Program\n      @cross_file_checker = CrossFileTypeChecker.new if enable_cross_file\n    end\n\n    # Compile with IR caching\n    def compile_with_ir(file_path)\n      return @compiled_files[file_path] unless needs_compile?(file_path)\n\n      # Get IR from compiler\n      ir_program = @compiler.compile_to_ir(file_path)\n      @ir_cache[file_path] = ir_program\n\n      # Register with cross-file checker\n      @cross_file_checker&.register_file(file_path, ir_program)\n\n      # Compile from IR\n      result = @compiler.compile(file_path)\n      @file_hashes[file_path] = file_hash(file_path)\n      @compiled_files[file_path] = result\n\n      result\n    end\n\n    # Compile all with cross-file checking\n    # Returns diagnostics using unified Diagnostic format\n    def compile_all_with_checking(file_paths)\n      results = {}\n      all_diagnostics = []\n\n      # First pass: compile and register all files\n      file_paths.each do |file_path|\n        source = File.exist?(file_path) ? File.read(file_path) : nil\n\n        begin\n          results[file_path] = compile_with_ir(file_path)\n        rescue TypeCheckError => e\n          all_diagnostics << Diagnostic.from_type_check_error(e, file: file_path, source: source)\n        rescue ParseError => e\n          all_diagnostics << Diagnostic.from_parse_error(e, file: file_path, source: source)\n        rescue Scanner::ScanError => e\n          all_diagnostics << Diagnostic.from_scan_error(e, file: file_path, source: source)\n        rescue StandardError => e\n          all_diagnostics << Diagnostic.new(\n            code: "TR0001",\n            message: e.message,\n            file: file_path,\n            line: 1,\n            column: 1\n          )\n        end\n      end\n\n      # Second pass: cross-file type checking\n      if @cross_file_checker\n        check_result = @cross_file_checker.check_all\n        check_result[:errors].each do |e|\n          all_diagnostics << Diagnostic.new(\n            code: "TR2002",\n            message: e[:message],\n            file: e[:file],\n            line: 1,\n            column: 1\n          )\n        end\n      end\n\n      {\n        results: results,\n        diagnostics: all_diagnostics,\n        success: all_diagnostics.empty?,\n      }\n    end\n\n    # Get cached IR for a file\n    def get_ir(file_path)\n      @ir_cache[file_path]\n    end\n\n    # Clear all caches\n    def clear\n      super\n      @ir_cache.clear\n      @cross_file_checker&.clear\n    end\n\n    private\n\n    def file_hash(file_path)\n      return nil unless File.exist?(file_path)\n\n      Digest::SHA256.hexdigest(File.read(file_path))\n    end\n  end\n\n  # Compilation profiler\n  class CompilationProfiler\n    def initialize\n      @timings = {}\n      @call_counts = {}\n    end\n\n    def profile(name, &block)\n      start = Process.clock_gettime(Process::CLOCK_MONOTONIC)\n      result = block.call\n      elapsed = Process.clock_gettime(Process::CLOCK_MONOTONIC) - start\n\n      @timings[name] ||= 0.0\n      @timings[name] += elapsed\n\n      @call_counts[name] ||= 0\n      @call_counts[name] += 1\n\n      result\n    end\n\n    def report\n      puts "=== Compilation Profile ==="\n      @timings.sort_by { |_, v| -v }.each do |name, time|\n        calls = @call_counts[name]\n        avg = time / calls\n        puts "#{name}: #{format("%.3f", time)}s total, #{calls} calls, #{format("%.3f", avg * 1000)}ms avg"\n      end\n    end\n\n    def reset\n      @timings.clear\n      @call_counts.clear\n    end\n\n    def to_h\n      @timings.map do |name, time|\n        {\n          name: name,\n          total_time: time,\n          call_count: @call_counts[name],\n          avg_time: time / @call_counts[name],\n        }\n      end\n    end\n  end\nend\n',"lib/t_ruby/cli.rb":'# frozen_string_literal: true\n\nmodule TRuby\n  class CLI\n    HELP_TEXT = <<~HELP.freeze\n      t-ruby compiler (trc) v#{VERSION}\n\n      Usage:\n        trc <file.trb>           Compile a .trb file to .rb\n        trc <file.rb>            Copy .rb file to build/ and generate .rbs\n        trc --init               Initialize a new t-ruby project\n        trc --config, -c <path>  Use custom config file\n        trc --watch, -w          Watch input files and recompile on change\n        trc --decl <file.trb>    Generate .d.trb declaration file\n        trc --lsp                Start LSP server (for IDE integration)\n        trc run <file.trb>       Run a .trb file directly (delegates to t-ruby)\n        trc update               Update t-ruby to the latest version\n        trc --version, -v        Show version (and check for updates)\n        trc --help, -h           Show this help\n\n      Examples:\n        trc hello.trb            Compile hello.trb to build/hello.rb\n        trc utils.rb             Copy utils.rb to build/ and generate utils.rbs\n        trc --init               Create trbconfig.yml and src/, build/ directories\n        trc -c custom.yml file.trb  Compile with custom config file\n        trc -w                   Watch all .trb and .rb files in current directory\n        trc -w src/              Watch all .trb and .rb files in src/ directory\n        trc --watch hello.trb    Watch specific file for changes\n        trc --decl hello.trb     Generate hello.d.trb declaration file\n        trc --lsp                Start language server for VS Code\n        trc run hello.trb        Run hello.trb directly without compilation\n    HELP\n\n    def self.run(args)\n      new(args).run\n    end\n\n    def initialize(args)\n      @args = args\n    end\n\n    def run\n      if @args.empty? || @args.include?("--help") || @args.include?("-h")\n        puts HELP_TEXT\n        return\n      end\n\n      if @args.include?("--version") || @args.include?("-v")\n        puts "trc #{VERSION}"\n        check_for_updates\n        return\n      end\n\n      if @args.include?("update")\n        update_gem\n        return\n      end\n\n      if @args.include?("--init")\n        init_project\n        return\n      end\n\n      if @args.include?("--lsp")\n        start_lsp_server\n        return\n      end\n\n      if @args.first == "run"\n        run_direct\n        return\n      end\n\n      if @args.include?("--watch") || @args.include?("-w")\n        start_watch_mode\n        return\n      end\n\n      if @args.include?("--decl")\n        input_file = @args[@args.index("--decl") + 1]\n        generate_declaration(input_file)\n        return\n      end\n\n      # Extract config path if --config or -c flag is present\n      config_path = extract_config_path\n\n      # Get input file (first non-flag argument)\n      input_file = find_input_file\n      compile(input_file, config_path: config_path)\n    end\n\n    private\n\n    def check_for_updates\n      result = VersionChecker.check\n      return unless result\n\n      puts ""\n      puts "New version available: #{result[:latest]} (current: #{result[:current]})"\n      puts "Run \'trc update\' to update"\n    end\n\n    def update_gem\n      puts "Updating t-ruby..."\n      if VersionChecker.update\n        puts "Successfully updated t-ruby!"\n      else\n        puts "Update failed. Try: gem install t-ruby"\n      end\n    end\n\n    def init_project\n      config_file = "trbconfig.yml"\n      src_dir = "src"\n      build_dir = "build"\n\n      created = []\n      skipped = []\n\n      # Create trbconfig.yml with new schema\n      if File.exist?(config_file)\n        skipped << config_file\n      else\n        File.write(config_file, <<~YAML)\n          # T-Ruby configuration file\n          # See: https://type-ruby.github.io/docs/getting-started/project-configuration\n\n          source:\n            include:\n              - #{src_dir}\n            exclude: []\n            extensions:\n              - ".trb"\n              - ".rb"\n\n          output:\n            ruby_dir: #{build_dir}\n            # rbs_dir: sig  # Optional: separate directory for .rbs files\n            # clean_before_build: false\n\n          compiler:\n            strictness: standard  # strict | standard | permissive\n            generate_rbs: true\n            target_ruby: "#{RubyVersion.current.major}.#{RubyVersion.current.minor}"\n            # experimental: []\n            # checks:\n            #   no_implicit_any: false\n            #   no_unused_vars: false\n            #   strict_nil: false\n\n          watch:\n            # paths: []  # Additional paths to watch\n            debounce: 100\n            # clear_screen: false\n            # on_success: "bundle exec rspec"\n        YAML\n        created << config_file\n      end\n\n      # Create src/ directory\n      if Dir.exist?(src_dir)\n        skipped << "#{src_dir}/"\n      else\n        Dir.mkdir(src_dir)\n        created << "#{src_dir}/"\n      end\n\n      # Create build/ directory\n      if Dir.exist?(build_dir)\n        skipped << "#{build_dir}/"\n      else\n        Dir.mkdir(build_dir)\n        created << "#{build_dir}/"\n      end\n\n      # Output results\n      if created.any?\n        puts "Created: #{created.join(", ")}"\n      end\n      if skipped.any?\n        puts "Skipped (already exists): #{skipped.join(", ")}"\n      end\n      if created.empty? && skipped.any?\n        puts "Project already initialized."\n      else\n        puts "t-ruby project initialized successfully!"\n      end\n    end\n\n    def start_lsp_server\n      server = LSPServer.new\n      server.run\n    end\n\n    def run_direct\n      remaining_args = @args[1..] || []\n\n      # Find t-ruby executable path\n      t_ruby_bin = File.expand_path("../../bin/t-ruby", __dir__)\n\n      # Execute t-ruby (replaces current process)\n      exec(t_ruby_bin, *remaining_args)\n    end\n\n    def start_watch_mode\n      # Get paths to watch (everything after --watch or -w flag)\n      watch_index = @args.index("--watch") || @args.index("-w")\n      paths = @args[(watch_index + 1)..]\n\n      # Default to current directory if no paths specified\n      paths = ["."] if paths.empty?\n\n      config = Config.new\n      watcher = Watcher.new(paths: paths, config: config)\n      watcher.watch\n    end\n\n    def generate_declaration(input_file)\n      config = Config.new\n      generator = DeclarationGenerator.new\n\n      output_path = generator.generate_file(input_file, config.out_dir)\n      puts "Generated: #{input_file} -> #{output_path}"\n    rescue ArgumentError => e\n      puts "Error: #{e.message}"\n      exit 1\n    end\n\n    def compile(input_file, config_path: nil)\n      config = Config.new(config_path)\n      compiler = Compiler.new(config)\n\n      result = compiler.compile_with_diagnostics(input_file)\n\n      if result[:success]\n        puts "Compiled: #{input_file} -> #{result[:output_path]}"\n      else\n        formatter = DiagnosticFormatter.new(use_colors: $stdout.tty?)\n        result[:diagnostics].each do |diagnostic|\n          puts formatter.format(diagnostic)\n        end\n        puts\n        puts formatter.send(:format_summary, result[:diagnostics])\n        exit 1\n      end\n    end\n\n    # Extract config path from --config or -c flag\n    def extract_config_path\n      config_index = @args.index("--config") || @args.index("-c")\n      return nil unless config_index\n\n      @args[config_index + 1]\n    end\n\n    # Find the input file (first non-flag argument)\n    def find_input_file\n      skip_next = false\n      @args.each do |arg|\n        if skip_next\n          skip_next = false\n          next\n        end\n\n        # Skip known flags with arguments\n        if %w[--config -c --decl].include?(arg)\n          skip_next = true\n          next\n        end\n\n        # Skip flags without arguments\n        next if arg.start_with?("-")\n\n        return arg\n      end\n      nil\n    end\n  end\nend\n',"lib/t_ruby/code_emitter.rb":'# frozen_string_literal: true\n\nmodule TRuby\n  # Version-specific code transformation strategies\n  #\n  # @example\n  #   emitter = CodeEmitter.for_version("4.0")\n  #   result = emitter.transform(source)\n  #\n  module CodeEmitter\n    # Factory method to get appropriate emitter for target Ruby version\n    #\n    # @param target_ruby [String] target Ruby version (e.g., "3.0", "4.0")\n    # @return [Base] appropriate emitter instance\n    def self.for_version(target_ruby)\n      version = RubyVersion.parse(target_ruby)\n\n      if version.numbered_parameters_raise_error?\n        Ruby40.new(version)\n      elsif version.supports_it_parameter?\n        Ruby34.new(version)\n      elsif version.supports_anonymous_block_forwarding?\n        Ruby31.new(version)\n      else\n        Ruby30.new(version)\n      end\n    end\n\n    # Base class for version-specific code emitters\n    class Base\n      attr_reader :version\n\n      def initialize(version)\n        @version = version\n      end\n\n      # Apply all transformations for this version\n      #\n      # @param source [String] source code to transform\n      # @return [String] transformed source code\n      def transform(source)\n        result = source.dup\n        result = transform_numbered_params(result)\n        transform_block_forwarding(result)\n      end\n\n      # Transform numbered block parameters (_1, _2, etc.)\n      # Default: no transformation\n      #\n      # @param source [String] source code\n      # @return [String] transformed source code\n      def transform_numbered_params(source)\n        source\n      end\n\n      # Transform block forwarding syntax\n      # Default: no transformation\n      #\n      # @param source [String] source code\n      # @return [String] transformed source code\n      def transform_block_forwarding(source)\n        source\n      end\n\n      # Check if this version supports the `it` implicit block parameter\n      #\n      # @return [Boolean]\n      def supports_it?\n        false\n      end\n\n      # Check if numbered parameters raise NameError in this version\n      #\n      # @return [Boolean]\n      def numbered_params_error?\n        false\n      end\n    end\n\n    # Ruby 3.0 emitter - baseline, no transformations\n    class Ruby30 < Base\n      # Ruby 3.0 uses standard syntax, no transformations needed\n    end\n\n    # Ruby 3.1+ emitter - supports anonymous block forwarding\n    class Ruby31 < Base\n      # Transform `def foo(&block) ... bar(&block)` to `def foo(&) ... bar(&)`\n      #\n      # Only transforms when the block parameter is ONLY used for forwarding,\n      # not when it\'s called directly (e.g., block.call)\n      def transform_block_forwarding(source)\n        result = source.dup\n\n        # Find method definitions with block parameters\n        # Pattern: def method_name(&block_name)\n        result.gsub!(/def\\s+(\\w+[?!=]?)\\s*\\(([^)]*?)&(\\w+)\\s*\\)/) do |_match|\n          method_name = ::Regexp.last_match(1)\n          other_params = ::Regexp.last_match(2)\n          block_name = ::Regexp.last_match(3)\n\n          # Find the method body to check block usage\n          method_start = ::Regexp.last_match.begin(0)\n          remaining = result[method_start..]\n\n          # Check if block is only used for forwarding (not called directly)\n          if block_only_forwarded?(remaining, block_name)\n            "def #{method_name}(#{other_params}&)"\n          else\n            "def #{method_name}(#{other_params}&#{block_name})"\n          end\n        end\n\n        # Replace block forwarding calls with anonymous forwarding\n        # This is a simplified approach - in practice we\'d need proper scope tracking\n        result.gsub!(/(\\w+)\\s*\\(\\s*&(\\w+)\\s*\\)/) do |match|\n          call_name = ::Regexp.last_match(1)\n          ::Regexp.last_match(2)\n\n          # Check if this block name was converted to anonymous\n          if result.include?("def ") && result.include?("(&)")\n            "#{call_name}(&)"\n          else\n            match\n          end\n        end\n\n        result\n      end\n\n      private\n\n      # Check if a block parameter is only used for forwarding\n      def block_only_forwarded?(method_body, block_name)\n        # Simple heuristic: if block_name appears with .call or without &, it\'s not just forwarding\n        # Look for patterns like: block_name.call, block_name.(), yield\n\n        # Extract method body (until next def or end of class)\n        lines = method_body.lines\n        depth = 0\n        body_lines = []\n\n        lines.each do |line|\n          depth += 1 if line.match?(/\\b(def|class|module|do|begin|case|if|unless|while|until)\\b/)\n          depth -= 1 if line.match?(/\\bend\\b/)\n          body_lines << line\n          break if depth <= 0 && body_lines.length > 1\n        end\n\n        body = body_lines.join\n\n        # Check for direct block usage\n        return false if body.match?(/\\b#{block_name}\\s*\\./)     # block.call, block.(), etc.\n        return false if body.match?(/\\b#{block_name}\\s*\\[/)     # block[args]\n        return false if body.match?(/\\byield\\b/)                # yield instead of forwarding\n\n        # Only &block_name patterns - this is forwarding\n        true\n      end\n    end\n\n    # Ruby 3.4+ emitter - supports `it` implicit block parameter\n    class Ruby34 < Ruby31\n      def supports_it?\n        true\n      end\n\n      # Ruby 3.4 still supports _1 syntax, so no transformation needed by default\n      # Users can opt-in to using `it` style if they want\n    end\n\n    # Ruby 4.0+ emitter - _1 raises NameError, must use `it`\n    class Ruby40 < Ruby34\n      def numbered_params_error?\n        true\n      end\n\n      # Transform numbered parameters to appropriate syntax\n      #\n      # - Single _1 \u2192 it\n      # - Multiple (_1, _2) \u2192 explicit |k, v| params\n      def transform_numbered_params(source)\n        result = source.dup\n\n        # Simple approach: replace all _1 with it when it\'s the only numbered param in scope\n        # For complex cases with _2+, we\'d need proper parsing\n        # For now, do a global replacement if _2 etc are not present\n        if result.match?(/\\b_[2-9]\\b/)\n          # Has multiple numbered params - need to convert to explicit params\n          # This is a complex case that requires proper block parsing\n          transform_multi_numbered_params(result)\n        else\n          # Only _1 is used - simple replacement\n          result.gsub(/\\b_1\\b/, "it")\n        end\n      end\n\n      private\n\n      def transform_multi_numbered_params(source)\n        result = source.dup\n\n        # Find blocks and transform them\n        # Use a recursive approach with placeholder replacement\n\n        # Replace innermost blocks first\n        loop do\n          changed = false\n          result = result.gsub(/\\{([^{}]*)\\}/) do |block|\n            content = ::Regexp.last_match(1)\n            max_param = find_max_numbered_param(content)\n\n            if max_param > 1\n              # Multiple params - convert to explicit\n              param_names = generate_param_names(max_param)\n              new_content = content.dup\n              (1..max_param).each do |i|\n                new_content.gsub!(/\\b_#{i}\\b/, param_names[i - 1])\n              end\n              changed = true\n              "{ |#{param_names.join(", ")}| #{new_content.strip} }"\n            elsif max_param == 1\n              # Single _1 - convert to it\n              changed = true\n              "{ #{content.gsub(/\\b_1\\b/, "it").strip} }"\n            else\n              block\n            end\n          end\n          break unless changed\n        end\n\n        result\n      end\n\n      def find_max_numbered_param(content)\n        max = 0\n        content.scan(/\\b_(\\d+)\\b/) do |match|\n          num = match[0].to_i\n          max = num if num > max\n        end\n        max\n      end\n\n      def generate_param_names(count)\n        # Generate simple parameter names: a, b, c, ... or k, v for 2\n        if count == 2\n          %w[k v]\n        else\n          ("a".."z").take(count)\n        end\n      end\n    end\n  end\nend\n',"lib/t_ruby/compiler.rb":'# frozen_string_literal: true\n\nrequire "fileutils"\n\nmodule TRuby\n  # Pattern for method names that supports Unicode characters\n  # \\p{L} matches any Unicode letter, \\p{N} matches any Unicode number\n  IDENTIFIER_CHAR = \'[\\p{L}\\p{N}_]\'\n  METHOD_NAME_PATTERN = "#{IDENTIFIER_CHAR}+[?!]?".freeze\n  # Visibility modifiers for method definitions\n  VISIBILITY_PATTERN = \'(?:(?:private|protected|public)\\s+)?\'\n\n  class Compiler\n    attr_reader :declaration_loader, :optimizer\n\n    def initialize(config = nil, optimize: true)\n      @config = config || Config.new\n      @optimize = optimize\n      @declaration_loader = DeclarationLoader.new\n      @optimizer = IR::Optimizer.new if optimize\n      @type_inferrer = ASTTypeInferrer.new if type_check?\n      setup_declaration_paths if @config\n    end\n\n    def type_check?\n      @config.type_check?\n    end\n\n    def compile(input_path)\n      unless File.exist?(input_path)\n        raise ArgumentError, "File not found: #{input_path}"\n      end\n\n      # Handle .rb files separately\n      if input_path.end_with?(".rb")\n        return copy_ruby_file(input_path)\n      end\n\n      unless input_path.end_with?(".trb")\n        raise ArgumentError, "Expected .trb or .rb file, got: #{input_path}"\n      end\n\n      source = File.read(input_path)\n\n      # Parse with IR support\n      parser = Parser.new(source)\n      parser.parse\n\n      # Run type checking if enabled\n      if type_check? && parser.ir_program\n        check_types(parser.ir_program, input_path)\n      end\n\n      # Transform source to Ruby code\n      output = transform_with_ir(source, parser)\n\n      # Compute output path (respects preserve_structure setting)\n      output_path = compute_output_path(input_path, @config.ruby_dir, ".rb")\n      FileUtils.mkdir_p(File.dirname(output_path))\n\n      File.write(output_path, output)\n\n      # Generate .rbs file if enabled in config\n      if @config.compiler["generate_rbs"]\n        rbs_path = compute_output_path(input_path, @config.rbs_dir, ".rbs")\n        FileUtils.mkdir_p(File.dirname(rbs_path))\n        generate_rbs_from_ir_to_path(rbs_path, parser.ir_program)\n      end\n\n      # Generate .d.trb file if enabled in config (legacy support)\n      # TODO: Add compiler.generate_dtrb option in future\n      if @config.compiler.key?("generate_dtrb") && @config.compiler["generate_dtrb"]\n        generate_dtrb_file(input_path, @config.ruby_dir)\n      end\n\n      output_path\n    end\n\n    # Compile a file and return result with diagnostics\n    # This is the unified compilation interface for CLI and Watcher\n    # @param input_path [String] Path to the input file\n    # @return [Hash] Result with :success, :output_path, :diagnostics keys\n    def compile_with_diagnostics(input_path)\n      source = File.exist?(input_path) ? File.read(input_path) : nil\n      all_diagnostics = []\n\n      # Run analyze first to get all diagnostics (colon spacing, etc.)\n      if source\n        all_diagnostics = analyze(source, file: input_path)\n      end\n\n      begin\n        output_path = compile(input_path)\n        # Compilation succeeded, but we may still have diagnostics from analyze\n        {\n          success: all_diagnostics.empty?,\n          output_path: all_diagnostics.empty? ? output_path : nil,\n          diagnostics: all_diagnostics,\n        }\n      rescue TypeCheckError => e\n        # Skip if already reported by analyze (same message and location)\n        new_diag = Diagnostic.from_type_check_error(e, file: input_path, source: source)\n        unless all_diagnostics.any? { |d| d.message == new_diag.message && d.line == new_diag.line }\n          all_diagnostics << new_diag\n        end\n        {\n          success: false,\n          output_path: nil,\n          diagnostics: all_diagnostics,\n        }\n      rescue ParseError => e\n        new_diag = Diagnostic.from_parse_error(e, file: input_path, source: source)\n        unless all_diagnostics.any? { |d| d.message == new_diag.message && d.line == new_diag.line }\n          all_diagnostics << new_diag\n        end\n        {\n          success: false,\n          output_path: nil,\n          diagnostics: all_diagnostics,\n        }\n      rescue Scanner::ScanError => e\n        new_diag = Diagnostic.from_scan_error(e, file: input_path, source: source)\n        unless all_diagnostics.any? { |d| d.message == new_diag.message && d.line == new_diag.line }\n          all_diagnostics << new_diag\n        end\n        {\n          success: false,\n          output_path: nil,\n          diagnostics: all_diagnostics,\n        }\n      rescue ArgumentError => e\n        all_diagnostics << Diagnostic.new(\n          code: "TR0001",\n          message: e.message,\n          file: input_path,\n          severity: Diagnostic::SEVERITY_ERROR\n        )\n        {\n          success: false,\n          output_path: nil,\n          diagnostics: all_diagnostics,\n        }\n      end\n    end\n\n    # Analyze source code without compiling - returns diagnostics only\n    # This is the unified analysis interface for LSP and other tools\n    # @param source [String] T-Ruby source code\n    # @param file [String] File path for error reporting (optional)\n    # @return [Array<Diagnostic>] Array of diagnostic objects\n    def analyze(source, file: "<source>")\n      diagnostics = []\n      source_lines = source.split("\\n")\n\n      # Run ErrorHandler checks (syntax validation, duplicate definitions, etc.)\n      error_handler = ErrorHandler.new(source)\n      errors = error_handler.check\n      errors.each do |error|\n        # Parse line number from "Line N: message" format\n        next unless error =~ /^Line (\\d+):\\s*(.+)$/\n\n        line_num = Regexp.last_match(1).to_i\n        message = Regexp.last_match(2)\n        source_line = source_lines[line_num - 1] if line_num.positive?\n        diagnostics << Diagnostic.new(\n          code: "TR1002",\n          message: message,\n          file: file,\n          line: line_num,\n          column: 1,\n          source_line: source_line,\n          severity: Diagnostic::SEVERITY_ERROR\n        )\n      end\n\n      # Run TokenDeclarationParser for colon spacing and declaration syntax validation\n      begin\n        scanner = Scanner.new(source)\n        tokens = scanner.scan_all\n        decl_parser = ParserCombinator::TokenDeclarationParser.new\n        decl_parser.parse_program(tokens)\n\n        if decl_parser.has_errors?\n          decl_parser.errors.each do |err|\n            source_line = source_lines[err.line - 1] if err.line.positive? && err.line <= source_lines.length\n            diagnostics << Diagnostic.new(\n              code: "TR1003",\n              message: err.message,\n              file: file,\n              line: err.line,\n              column: err.column,\n              source_line: source_line,\n              severity: Diagnostic::SEVERITY_ERROR\n            )\n          end\n        end\n      rescue Scanner::ScanError\n        # Scanner errors will be caught below in the main parse section\n      rescue StandardError\n        # Ignore TokenDeclarationParser errors for now - regex parser is authoritative\n      end\n\n      begin\n        # Parse source with regex-based parser for IR generation\n        parser = Parser.new(source)\n        parser.parse\n\n        # Run type checking if enabled and IR is available\n        if type_check? && parser.ir_program\n          begin\n            check_types(parser.ir_program, file)\n          rescue TypeCheckError => e\n            diagnostics << Diagnostic.from_type_check_error(e, file: file, source: source)\n          end\n        end\n      rescue ParseError => e\n        diagnostics << Diagnostic.from_parse_error(e, file: file, source: source)\n      rescue Scanner::ScanError => e\n        diagnostics << Diagnostic.from_scan_error(e, file: file, source: source)\n      rescue StandardError => e\n        diagnostics << Diagnostic.new(\n          code: "TR0001",\n          message: e.message,\n          file: file,\n          line: 1,\n          column: 1,\n          severity: Diagnostic::SEVERITY_ERROR\n        )\n      end\n\n      diagnostics\n    end\n\n    # Compile T-Ruby source code from a string (useful for WASM/playground)\n    # @param source [String] T-Ruby source code\n    # @param options [Hash] Options for compilation\n    # @option options [Boolean] :rbs Whether to generate RBS output (default: true)\n    # @return [Hash] Result with :ruby, :rbs, :errors keys\n    def compile_string(source, options = {})\n      generate_rbs = options.fetch(:rbs, true)\n\n      parser = Parser.new(source)\n      parser.parse\n\n      # Transform source to Ruby code\n      ruby_output = transform_with_ir(source, parser)\n\n      # Generate RBS if requested\n      rbs_output = ""\n      if generate_rbs && parser.ir_program\n        generator = IR::RBSGenerator.new\n        rbs_output = generator.generate(parser.ir_program)\n      end\n\n      {\n        ruby: ruby_output,\n        rbs: rbs_output,\n        errors: [],\n      }\n    rescue ParseError => e\n      {\n        ruby: "",\n        rbs: "",\n        errors: [e.message],\n      }\n    rescue StandardError => e\n      {\n        ruby: "",\n        rbs: "",\n        errors: ["Compilation error: #{e.message}"],\n      }\n    end\n\n    # Compile to IR without generating output files\n    def compile_to_ir(input_path)\n      unless File.exist?(input_path)\n        raise ArgumentError, "File not found: #{input_path}"\n      end\n\n      source = File.read(input_path)\n      parser = Parser.new(source)\n      parser.parse\n      parser.ir_program\n    end\n\n    # Compile from IR program directly\n    def compile_from_ir(ir_program, output_path)\n      out_dir = File.dirname(output_path)\n      FileUtils.mkdir_p(out_dir)\n\n      # Optimize if enabled\n      program = ir_program\n      if @optimize && @optimizer\n        result = @optimizer.optimize(program)\n        program = result[:program]\n      end\n\n      # Generate Ruby code\n      generator = IRCodeGenerator.new\n      output = generator.generate(program)\n      File.write(output_path, output)\n\n      output_path\n    end\n\n    # Load external declarations from a file\n    def load_declaration(name)\n      @declaration_loader.load(name)\n    end\n\n    # Add a search path for declaration files\n    def add_declaration_path(path)\n      @declaration_loader.add_search_path(path)\n    end\n\n    # Get optimization statistics (only available after IR compilation)\n    def optimization_stats\n      @optimizer&.stats\n    end\n\n    # Compute output path for a source file\n    # @param input_path [String] path to source file\n    # @param output_dir [String] base output directory\n    # @param new_extension [String] new file extension (e.g., ".rb", ".rbs")\n    # @return [String] computed output path (always preserves directory structure)\n    def compute_output_path(input_path, output_dir, new_extension)\n      relative = compute_relative_path(input_path)\n      base = relative.sub(/\\.[^.]+$/, new_extension)\n      File.join(output_dir, base)\n    end\n\n    # Compute relative path from source directory\n    # @param input_path [String] path to source file\n    # @return [String] relative path preserving directory structure\n    def compute_relative_path(input_path)\n      # Use realpath to resolve symlinks (e.g., /var vs /private/var on macOS)\n      absolute_input = resolve_path(input_path)\n      source_dirs = @config.source_include\n\n      # Check if file is inside any source_include directory\n      if source_dirs.size > 1\n        # Multiple source directories: include the source dir name in output\n        # src/models/user.trb \u2192 src/models/user.trb\n        source_dirs.each do |src_dir|\n          absolute_src = resolve_path(src_dir)\n          next unless absolute_input.start_with?("#{absolute_src}/")\n\n          # Return path relative to parent of source dir (includes src dir name)\n          parent_of_src = File.dirname(absolute_src)\n          return absolute_input.sub("#{parent_of_src}/", "")\n        end\n      else\n        # Single source directory: exclude the source dir name from output\n        # src/models/user.trb \u2192 models/user.trb\n        src_dir = source_dirs.first\n        if src_dir\n          absolute_src = resolve_path(src_dir)\n          if absolute_input.start_with?("#{absolute_src}/")\n            return absolute_input.sub("#{absolute_src}/", "")\n          end\n        end\n      end\n\n      # File outside source directories: use path relative to current working directory\n      # external/foo.trb \u2192 external/foo.trb\n      cwd = resolve_path(".")\n      if absolute_input.start_with?("#{cwd}/")\n        return absolute_input.sub("#{cwd}/", "")\n      end\n\n      # Absolute path from outside cwd: use basename only\n      File.basename(input_path)\n    end\n\n    private\n\n    # Check types in IR program and raise TypeCheckError if mismatches found\n    # @param ir_program [IR::Program] IR program to check\n    # @param file_path [String] source file path for error messages\n    def check_types(ir_program, file_path)\n      ir_program.declarations.each do |decl|\n        case decl\n        when IR::MethodDef\n          check_method_return_type(decl, nil, file_path)\n        when IR::ClassDecl\n          decl.body.each do |member|\n            check_method_return_type(member, decl, file_path) if member.is_a?(IR::MethodDef)\n          end\n        end\n      end\n    end\n\n    # Check if method\'s inferred return type matches declared return type\n    # @param method [IR::MethodDef] method to check\n    # @param class_def [IR::ClassDef, nil] containing class if any\n    # @param file_path [String] source file path for error messages\n    def check_method_return_type(method, class_def, file_path)\n      # Skip if no explicit return type annotation\n      return unless method.return_type\n\n      declared_type = normalize_type(method.return_type.to_rbs)\n\n      # Create type environment for the class context\n      class_env = create_class_env(class_def) if class_def\n\n      # Infer actual return type\n      inferred_type = @type_inferrer.infer_method_return_type(method, class_env)\n      inferred_type = normalize_type(inferred_type || "nil")\n\n      # Check compatibility\n      return if types_compatible?(inferred_type, declared_type)\n\n      location = method.location ? "#{file_path}:#{method.location}" : file_path\n      method_name = class_def ? "#{class_def.name}##{method.name}" : method.name\n\n      raise TypeCheckError.new(\n        message: "Return type mismatch in method \'#{method_name}\': " \\\n                 "declared \'#{declared_type}\' but inferred \'#{inferred_type}\'",\n        location: location,\n        expected: declared_type,\n        actual: inferred_type\n      )\n    end\n\n    # Create type environment for class context\n    # @param class_def [IR::ClassDecl] class declaration\n    # @return [TypeEnv] type environment with instance variables\n    def create_class_env(class_def)\n      env = TypeEnv.new\n\n      # Register instance variables from class\n      class_def.instance_vars&.each do |ivar|\n        type = ivar.type_annotation&.to_rbs || "untyped"\n        env.define_instance_var(ivar.name, type)\n      end\n\n      env\n    end\n\n    # Normalize type string for comparison\n    # @param type [String] type string\n    # @return [String] normalized type string\n    def normalize_type(type)\n      return "untyped" if type.nil?\n\n      normalized = type.to_s.strip\n\n      # Normalize boolean types (bool/Boolean/TrueClass/FalseClass -> bool)\n      case normalized\n      when "Boolean", "TrueClass", "FalseClass"\n        "bool"\n      else\n        normalized\n      end\n    end\n\n    # Check if inferred type is compatible with declared type\n    # @param inferred [String] inferred type\n    # @param declared [String] declared type\n    # @return [Boolean] true if compatible\n    def types_compatible?(inferred, declared)\n      # Exact match\n      return true if inferred == declared\n\n      # untyped is compatible with anything\n      return true if inferred == "untyped" || declared == "untyped"\n\n      # void is compatible with anything (no return value check)\n      return true if declared == "void"\n\n      # nil is compatible with nullable types\n      return true if inferred == "nil" && declared.end_with?("?")\n\n      # Subtype relationships\n      return true if subtype_of?(inferred, declared)\n\n      # Handle generic types (e.g., Array[untyped] is compatible with Array[String])\n      if inferred.include?("[") && declared.include?("[")\n        inferred_base = inferred.split("[").first\n        declared_base = declared.split("[").first\n        if inferred_base == declared_base\n          # Extract type arguments\n          inferred_args = inferred[/\\[(.+)\\]/, 1]\n          declared_args = declared[/\\[(.+)\\]/, 1]\n          # untyped type argument is compatible with any type argument\n          return true if inferred_args == "untyped" || declared_args == "untyped"\n        end\n      end\n\n      # Handle union types in declared\n      if declared.include?("|")\n        declared_types = declared.split("|").map(&:strip)\n        return true if declared_types.include?(inferred)\n        return true if declared_types.any? { |t| types_compatible?(inferred, t) }\n      end\n\n      # Handle union types in inferred - all must be compatible\n      if inferred.include?("|")\n        inferred_types = inferred.split("|").map(&:strip)\n        return inferred_types.all? { |t| types_compatible?(t, declared) }\n      end\n\n      false\n    end\n\n    # Check if subtype is a subtype of supertype\n    # @param subtype [String] potential subtype\n    # @param supertype [String] potential supertype\n    # @return [Boolean] true if subtype\n    def subtype_of?(subtype, supertype)\n      # Handle nullable - X is subtype of X?\n      return true if supertype.end_with?("?") && supertype[0..-2] == subtype\n\n      # Numeric hierarchy\n      return true if subtype == "Integer" && supertype == "Numeric"\n      return true if subtype == "Float" && supertype == "Numeric"\n\n      # Object is supertype of everything\n      return true if supertype == "Object"\n\n      false\n    end\n\n    # Resolve path to absolute path, following symlinks\n    # Falls back to expand_path if realpath fails (e.g., file doesn\'t exist yet)\n    def resolve_path(path)\n      File.realpath(path)\n    rescue Errno::ENOENT\n      File.expand_path(path)\n    end\n\n    def setup_declaration_paths\n      # Add default declaration paths\n      @declaration_loader.add_search_path(@config.out_dir)\n      @declaration_loader.add_search_path(@config.src_dir)\n      @declaration_loader.add_search_path("./types")\n      @declaration_loader.add_search_path("./lib/types")\n    end\n\n    # Transform using IR system\n    def transform_with_ir(source, parser)\n      ir_program = parser.ir_program\n      return source unless ir_program\n\n      # Run optimization passes if enabled\n      if @optimize && @optimizer\n        result = @optimizer.optimize(ir_program)\n        ir_program = result[:program]\n      end\n\n      # Generate Ruby code using IR-aware generator with target Ruby version\n      generator = IRCodeGenerator.new(target_ruby: @config.target_ruby)\n      generator.generate_with_source(ir_program, source)\n    end\n\n    # Generate RBS from IR to a specific path\n    def generate_rbs_from_ir_to_path(rbs_path, ir_program)\n      return unless ir_program\n\n      generator = IR::RBSGenerator.new\n      rbs_content = generator.generate(ir_program)\n      File.write(rbs_path, rbs_content) unless rbs_content.strip.empty?\n    end\n\n    def generate_dtrb_file(input_path, out_dir)\n      dtrb_path = compute_output_path(input_path, out_dir, DeclarationGenerator::DECLARATION_EXTENSION)\n      FileUtils.mkdir_p(File.dirname(dtrb_path))\n\n      generator = DeclarationGenerator.new\n      generator.generate_file_to_path(input_path, dtrb_path)\n    end\n\n    # Copy .rb file to output directory and generate .rbs signature\n    def copy_ruby_file(input_path)\n      unless File.exist?(input_path)\n        raise ArgumentError, "File not found: #{input_path}"\n      end\n\n      # Compute output path (respects preserve_structure setting)\n      output_path = compute_output_path(input_path, @config.ruby_dir, ".rb")\n      FileUtils.mkdir_p(File.dirname(output_path))\n\n      # Copy the .rb file to output directory\n      FileUtils.cp(input_path, output_path)\n\n      # Generate .rbs file if enabled in config\n      if @config.compiler["generate_rbs"]\n        rbs_path = compute_output_path(input_path, @config.rbs_dir, ".rbs")\n        FileUtils.mkdir_p(File.dirname(rbs_path))\n        generate_rbs_from_ruby_to_path(rbs_path, input_path)\n      end\n\n      output_path\n    end\n\n    # Generate RBS from Ruby file using rbs prototype to a specific path\n    def generate_rbs_from_ruby_to_path(rbs_path, input_path)\n      result = `rbs prototype rb #{input_path} 2>/dev/null`\n      File.write(rbs_path, result) unless result.strip.empty?\n    end\n  end\n\n  # IR-aware code generator for source-preserving transformation\n  class IRCodeGenerator\n    attr_reader :emitter\n\n    # @param target_ruby [String] target Ruby version (e.g., "3.0", "4.0")\n    def initialize(target_ruby: "3.0")\n      @output = []\n      @emitter = CodeEmitter.for_version(target_ruby)\n    end\n\n    # Generate Ruby code from IR program\n    def generate(program)\n      generator = IR::CodeGenerator.new\n      generator.generate(program)\n    end\n\n    # Generate Ruby code while preserving source structure\n    def generate_with_source(program, source)\n      result = source.dup\n\n      # Collect type alias names to remove\n      program.declarations\n             .select { |d| d.is_a?(IR::TypeAlias) }\n             .map(&:name)\n\n      # Collect interface names to remove\n      program.declarations\n             .select { |d| d.is_a?(IR::Interface) }\n             .map(&:name)\n\n      # Remove type alias definitions\n      result = result.gsub(/^\\s*type\\s+\\w+\\s*=\\s*.+?$\\n?/, "")\n\n      # Remove interface definitions (multi-line)\n      result = result.gsub(/^\\s*interface\\s+\\w+.*?^\\s*end\\s*$/m, "")\n\n      # Remove parameter type annotations using IR info\n      # Enhanced: Handle complex types (generics, unions, etc.)\n      result = erase_parameter_types(result)\n\n      # Remove return type annotations\n      result = erase_return_types(result)\n\n      # Apply version-specific transformations\n      result = @emitter.transform(result)\n\n      # Clean up extra blank lines\n      result.gsub(/\\n{3,}/, "\\n\\n")\n    end\n\n    private\n\n    # Erase parameter type annotations\n    def erase_parameter_types(source)\n      result = source.dup\n\n      # Match function definitions and remove type annotations from parameters\n      # Also supports visibility modifiers: private def, protected def, public def\n      result.gsub!(/^(\\s*#{TRuby::VISIBILITY_PATTERN}def\\s+#{TRuby::METHOD_NAME_PATTERN}\\s*\\()([^)]+)(\\)\\s*)(?::\\s*[^\\n]+)?(\\s*$)/) do |_match|\n        indent = ::Regexp.last_match(1)\n        params = ::Regexp.last_match(2)\n        close_paren = ::Regexp.last_match(3)\n        ending = ::Regexp.last_match(4)\n\n        # Remove type annotations from each parameter\n        cleaned_params = remove_param_types(params)\n\n        "#{indent}#{cleaned_params}#{close_paren.rstrip}#{ending}"\n      end\n\n      result\n    end\n\n    # Remove type annotations from parameter list\n    def remove_param_types(params_str)\n      return params_str if params_str.strip.empty?\n\n      params = []\n      current = ""\n      depth = 0\n      brace_depth = 0\n\n      params_str.each_char do |char|\n        case char\n        when "<", "[", "("\n          depth += 1\n          current += char\n        when ">", "]", ")"\n          depth -= 1\n          current += char\n        when "{"\n          brace_depth += 1\n          current += char\n        when "}"\n          brace_depth -= 1\n          current += char\n        when ","\n          if depth.zero? && brace_depth.zero?\n            cleaned = clean_param(current.strip)\n            params.concat(Array(cleaned)) if cleaned\n            current = ""\n          else\n            current += char\n          end\n        else\n          current += char\n        end\n      end\n\n      cleaned = clean_param(current.strip) unless current.empty?\n      params.concat(Array(cleaned)) if cleaned\n      params.join(", ")\n    end\n\n    # Clean a single parameter (remove type annotation, preserve default value)\n    # Returns String or Array of Strings (for keyword args group)\n    def clean_param(param)\n      param = param.strip\n      return nil if param.empty?\n\n      # 0. \ube14\ub85d \ud30c\ub77c\ubbf8\ud130: &name: Type -> &name\n      if param.start_with?("&")\n        match = param.match(/^&(\\w+)(?::\\s*.+)?$/)\n        return "&#{match[1]}" if match\n\n        return param\n      end\n\n      # 1. \ub354\ube14 \uc2a4\ud50c\ub7ab: **name: Type -> **name\n      if param.start_with?("**")\n        match = param.match(/^\\*\\*(\\w+)(?::\\s*.+)?$/)\n        return "**#{match[1]}" if match\n\n        return param\n      end\n\n      # 2. \ud0a4\uc6cc\ub4dc \uc778\uc790 \uadf8\ub8f9: { ... } \ub610\ub294 { ... }: InterfaceName\n      if param.start_with?("{")\n        return clean_keyword_args_group(param)\n      end\n\n      # 3. Hash \ub9ac\ud130\ub7f4: name: { ... } -> name\n      if param.match?(/^\\w+:\\s*\\{/)\n        match = param.match(/^(\\w+):\\s*\\{.+\\}(?::\\s*\\w+)?$/)\n        return match[1] if match\n\n        return param\n      end\n\n      # 4. \uc77c\ubc18 \ud30c\ub77c\ubbf8\ud130: name: Type = value -> name = value \ub610\ub294 name: Type -> name\n      # Match: name: Type = value (with default value)\n      if (match = param.match(/^(#{TRuby::IDENTIFIER_CHAR}+)\\s*:\\s*.+?\\s*(=\\s*.+)$/))\n        "#{match[1]} #{match[2]}"\n      # Match: name: Type (without default value)\n      elsif (match = param.match(/^(#{TRuby::IDENTIFIER_CHAR}+)\\s*:/))\n        match[1]\n      else\n        param\n      end\n    end\n\n    # \ud0a4\uc6cc\ub4dc \uc778\uc790 \uadf8\ub8f9\uc744 Ruby \ud0a4\uc6cc\ub4dc \uc778\uc790\ub85c \ubcc0\ud658\n    # { name: String, age: Integer = 0 } -> name:, age: 0\n    # { name:, age: 0 }: UserParams -> name:, age: 0\n    def clean_keyword_args_group(param)\n      # { ... }: InterfaceName \ub610\ub294 { ... } \ud615\ud0dc \ud30c\uc2f1\n      interface_match = param.match(/^\\{(.+)\\}\\s*:\\s*\\w+\\s*$/)\n      inline_match = param.match(/^\\{(.+)\\}\\s*$/) unless interface_match\n\n      inner_content = if interface_match\n                        interface_match[1]\n                      elsif inline_match\n                        inline_match[1]\n                      else\n                        return param\n                      end\n\n      # \ub0b4\ubd80 \ud30c\ub77c\ubbf8\ud130 \ubd84\ub9ac\n      parts = split_nested_content(inner_content)\n      keyword_params = []\n\n      parts.each do |part|\n        part = part.strip\n        next if part.empty?\n\n        if interface_match\n          # interface \ucc38\uc870: name: default_value \ub610\ub294 name:\n          if (match = part.match(/^(\\w+):\\s*(.*)$/))\n            name = match[1]\n            default_value = match[2].strip\n            keyword_params << if default_value.empty?\n                                "#{name}:"\n                              else\n                                "#{name}: #{default_value}"\n                              end\n          end\n        elsif (match = part.match(/^(\\w+):\\s*(.+)$/))\n          # \uc778\ub77c\uc778 \ud0c0\uc785: name: Type = default \ub610\ub294 name: Type\n          name = match[1]\n          type_and_default = match[2].strip\n\n          # Type = default \ubd84\ub9ac\n          default_value = extract_default_value(type_and_default)\n          keyword_params << if default_value\n                              "#{name}: #{default_value}"\n                            else\n                              "#{name}:"\n                            end\n        end\n      end\n\n      keyword_params\n    end\n\n    # \uc911\ucca9\ub41c \ub0b4\uc6a9\uc744 \ucf64\ub9c8\ub85c \ubd84\ub9ac\n    def split_nested_content(content)\n      StringUtils.split_by_comma(content)\n    end\n\n    # \ud0c0\uc785\uacfc \uae30\ubcf8\uac12\uc5d0\uc11c \uae30\ubcf8\uac12\ub9cc \ucd94\ucd9c\n    def extract_default_value(type_and_default)\n      StringUtils.extract_default_value(type_and_default)\n    end\n\n    # Erase return type annotations\n    def erase_return_types(source)\n      result = source.dup\n\n      # Remove return type after parentheses: ): Type or ): Type<Foo> etc.\n      result.gsub!(/\\)\\s*:\\s*[^\\n]+?(?=\\s*$)/m) do |_match|\n        ")"\n      end\n\n      # Remove return type for methods without parentheses: def method_name: Type\n      result.gsub!(/^(\\s*#{TRuby::VISIBILITY_PATTERN}def\\s+#{TRuby::METHOD_NAME_PATTERN})\\s*:\\s*[^\\n]+?(?=\\s*$)/m) do |_match|\n        ::Regexp.last_match(1)\n      end\n\n      result\n    end\n  end\nend\n',"lib/t_ruby/config.rb":'# frozen_string_literal: true\n\nrequire "yaml"\n\nmodule TRuby\n  # Error raised when configuration is invalid\n  class ConfigError < StandardError; end\n\n  class Config\n    # Valid strictness levels\n    VALID_STRICTNESS = %w[strict standard permissive].freeze\n    # New schema structure (v0.0.12+)\n    DEFAULT_CONFIG = {\n      "source" => {\n        "include" => ["src"],\n        "exclude" => [],\n        "extensions" => [".trb"],\n      },\n      "output" => {\n        "ruby_dir" => "build",\n        "rbs_dir" => nil,\n        "clean_before_build" => false,\n      },\n      "compiler" => {\n        "strictness" => "standard",\n        "generate_rbs" => true,\n        "type_check" => true,\n        "target_ruby" => nil, # Auto-detect from current Ruby version\n        "experimental" => [],\n        "checks" => {\n          "no_implicit_any" => false,\n          "no_unused_vars" => false,\n          "strict_nil" => false,\n        },\n      },\n      "watch" => {\n        "paths" => [],\n        "debounce" => 100,\n        "clear_screen" => false,\n        "on_success" => nil,\n      },\n    }.freeze\n\n    # Legacy keys for migration detection\n    LEGACY_KEYS = %w[emit paths strict include exclude].freeze\n\n    # Always excluded (not configurable)\n    AUTO_EXCLUDE = [".git"].freeze\n\n    attr_reader :source, :output, :compiler, :watch, :version_requirement\n\n    def initialize(config_path = nil)\n      raw_config = load_raw_config(config_path)\n      config = process_config(raw_config)\n\n      @source = config["source"]\n      @output = config["output"]\n      @compiler = config["compiler"]\n      @watch = config["watch"]\n      @version_requirement = raw_config["version"]\n    end\n\n    # Get output directory for compiled Ruby files\n    # @return [String] output directory path\n    def ruby_dir\n      @output["ruby_dir"] || "build"\n    end\n\n    # Get output directory for RBS files\n    # @return [String] RBS output directory (defaults to ruby_dir if not specified)\n    def rbs_dir\n      @output["rbs_dir"] || ruby_dir\n    end\n\n    # Check if output directory should be cleaned before build\n    # @return [Boolean] true if should clean before build\n    def clean_before_build?\n      @output["clean_before_build"] == true\n    end\n\n    # Get compiler strictness level\n    # @return [String] one of: strict, standard, permissive\n    def strictness\n      @compiler["strictness"] || "standard"\n    end\n\n    # Check if RBS files should be generated\n    # @return [Boolean] true if RBS files should be generated\n    def generate_rbs?\n      @compiler["generate_rbs"] != false\n    end\n\n    # Check if type checking is enabled\n    # @return [Boolean] true if type checking is enabled (default: true)\n    def type_check?\n      @compiler["type_check"] != false\n    end\n\n    # Get target Ruby version\n    # If not specified in config, auto-detects from current Ruby environment\n    # @return [String] target Ruby version (e.g., "3.0", "3.2", "4.0")\n    # @raise [UnsupportedRubyVersionError] if detected version is not supported\n    def target_ruby\n      configured = @compiler["target_ruby"]\n      if configured\n        RubyVersion.parse(configured).validate!\n        configured.to_s\n      else\n        version = RubyVersion.current.validate!\n        "#{version.major}.#{version.minor}"\n      end\n    end\n\n    # Get target Ruby version as RubyVersion object\n    # @return [RubyVersion] target Ruby version object\n    def target_ruby_version\n      RubyVersion.parse(target_ruby)\n    end\n\n    # Get list of enabled experimental features\n    # @return [Array<String>] list of experimental feature names\n    def experimental_features\n      @compiler["experimental"] || []\n    end\n\n    # Check if a specific experimental feature is enabled\n    # @param feature [String] feature name to check\n    # @return [Boolean] true if feature is enabled\n    def experimental_enabled?(feature)\n      experimental_features.include?(feature)\n    end\n\n    # Check if no_implicit_any check is enabled\n    # @return [Boolean] true if check is enabled\n    def check_no_implicit_any?\n      @compiler.dig("checks", "no_implicit_any") == true\n    end\n\n    # Check if no_unused_vars check is enabled\n    # @return [Boolean] true if check is enabled\n    def check_no_unused_vars?\n      @compiler.dig("checks", "no_unused_vars") == true\n    end\n\n    # Check if strict_nil check is enabled\n    # @return [Boolean] true if check is enabled\n    def check_strict_nil?\n      @compiler.dig("checks", "strict_nil") == true\n    end\n\n    # Get additional watch paths\n    # @return [Array<String>] list of additional paths to watch\n    def watch_paths\n      @watch["paths"] || []\n    end\n\n    # Get watch debounce delay in milliseconds\n    # @return [Integer] debounce delay in milliseconds\n    def watch_debounce\n      @watch["debounce"] || 100\n    end\n\n    # Check if terminal should be cleared before rebuild\n    # @return [Boolean] true if terminal should be cleared\n    def watch_clear_screen?\n      @watch["clear_screen"] == true\n    end\n\n    # Get command to run after successful compilation\n    # @return [String, nil] command to run on success\n    def watch_on_success\n      @watch["on_success"]\n    end\n\n    # Check if current T-Ruby version satisfies the version requirement\n    # @return [Boolean] true if version is satisfied or no requirement specified\n    def version_satisfied?\n      return true if @version_requirement.nil?\n\n      requirement = Gem::Requirement.new(@version_requirement)\n      current = Gem::Version.new(TRuby::VERSION)\n      requirement.satisfied_by?(current)\n    rescue ArgumentError\n      false\n    end\n\n    # Validate the configuration\n    # @raise [ConfigError] if configuration is invalid\n    def validate!\n      validate_strictness!\n      true\n    end\n\n    # Backwards compatible: alias for ruby_dir\n    def out_dir\n      ruby_dir\n    end\n\n    # Backwards compatible: first source.include directory\n    def src_dir\n      @source["include"].first || "src"\n    end\n\n    # Get source include directories\n    # @return [Array<String>] list of include directories\n    def source_include\n      @source["include"] || ["src"]\n    end\n\n    # Get source exclude patterns\n    # @return [Array<String>] list of exclude patterns\n    def source_exclude\n      @source["exclude"] || []\n    end\n\n    # Get source file extensions\n    # @return [Array<String>] list of file extensions (e.g., [".trb", ".truby"])\n    def source_extensions\n      @source["extensions"] || [".trb"]\n    end\n\n    # Get include patterns for file discovery\n    def include_patterns\n      extensions = @source["extensions"] || [".trb"]\n      extensions.map { |ext| "**/*#{ext}" }\n    end\n\n    # Get exclude patterns\n    def exclude_patterns\n      @source["exclude"] || []\n    end\n\n    # Find all source files matching include patterns, excluding exclude patterns\n    # @return [Array<String>] list of matching file paths\n    def find_source_files\n      files = []\n\n      @source["include"].each do |include_dir|\n        base_dir = File.expand_path(include_dir)\n        next unless Dir.exist?(base_dir)\n\n        include_patterns.each do |pattern|\n          full_pattern = File.join(base_dir, pattern)\n          files.concat(Dir.glob(full_pattern))\n        end\n      end\n\n      # Filter out excluded files\n      files.reject { |f| excluded?(f) }.uniq.sort\n    end\n\n    # Check if a file path should be excluded\n    # @param file_path [String] absolute or relative file path\n    # @return [Boolean] true if file should be excluded\n    def excluded?(file_path)\n      relative_path = relative_to_src(file_path)\n      all_exclude_patterns.any? { |pattern| matches_pattern?(relative_path, pattern) }\n    end\n\n    private\n\n    # Validate strictness value\n    def validate_strictness!\n      value = strictness\n      return if VALID_STRICTNESS.include?(value)\n\n      raise ConfigError, "Invalid compiler.strictness: \'#{value}\'. Must be one of: #{VALID_STRICTNESS.join(", ")}"\n    end\n\n    def load_raw_config(config_path)\n      raw = if config_path && File.exist?(config_path)\n              YAML.safe_load_file(config_path, permitted_classes: [Symbol]) || {}\n            elsif File.exist?("trbconfig.yml")\n              YAML.safe_load_file("trbconfig.yml", permitted_classes: [Symbol]) || {}\n            else\n              {}\n            end\n      expand_env_vars(raw)\n    end\n\n    # Expand environment variables in config values\n    # Supports ${VAR} and ${VAR:-default} syntax\n    def expand_env_vars(obj)\n      case obj\n      when Hash\n        obj.transform_values { |v| expand_env_vars(v) }\n      when Array\n        obj.map { |v| expand_env_vars(v) }\n      when String\n        expand_env_string(obj)\n      else\n        obj\n      end\n    end\n\n    # Expand environment variables in a single string\n    def expand_env_string(str)\n      str.gsub(/\\$\\{([^}]+)\\}/) do |_match|\n        var_expr = ::Regexp.last_match(1)\n        if var_expr.include?(":-")\n          var_name, default_value = var_expr.split(":-", 2)\n          ENV.fetch(var_name, default_value)\n        else\n          ENV.fetch(var_expr, "")\n        end\n      end\n    end\n\n    def process_config(raw_config)\n      if legacy_config?(raw_config)\n        warn "DEPRECATED: trbconfig.yml uses legacy format. Please migrate to new schema (source/output/compiler/watch)."\n        migrate_legacy_config(raw_config)\n      else\n        merge_with_defaults(raw_config)\n      end\n    end\n\n    def legacy_config?(raw_config)\n      LEGACY_KEYS.any? { |key| raw_config.key?(key) }\n    end\n\n    def migrate_legacy_config(raw_config)\n      result = deep_dup(DEFAULT_CONFIG)\n\n      # Migrate emit -> compiler.generate_rbs\n      if raw_config["emit"]&.key?("rbs")\n        result["compiler"]["generate_rbs"] = raw_config["emit"]["rbs"]\n      end\n\n      # Migrate paths -> source.include and output.ruby_dir\n      if raw_config["paths"]\n        if raw_config["paths"]["src"]\n          src_path = raw_config["paths"]["src"].sub(%r{^\\./}, "")\n          result["source"]["include"] = [src_path]\n        end\n        if raw_config["paths"]["out"]\n          out_path = raw_config["paths"]["out"].sub(%r{^\\./}, "")\n          result["output"]["ruby_dir"] = out_path\n        end\n      end\n\n      # Migrate include/exclude patterns\n      if raw_config["include"]\n        # Keep legacy include patterns as-is for now\n        result["source"]["include"] = [result["source"]["include"].first || "src"]\n      end\n\n      if raw_config["exclude"]\n        result["source"]["exclude"] = raw_config["exclude"]\n      end\n\n      result\n    end\n\n    def merge_with_defaults(user_config)\n      result = deep_dup(DEFAULT_CONFIG)\n      deep_merge(result, user_config)\n      result\n    end\n\n    def deep_dup(hash)\n      hash.transform_values do |value|\n        if value.is_a?(Hash)\n          deep_dup(value)\n        else\n          (value.is_a?(Array) ? value.dup : value)\n        end\n      end\n    end\n\n    def deep_merge(target, source)\n      source.each do |key, value|\n        if value.is_a?(Hash) && target[key].is_a?(Hash)\n          deep_merge(target[key], value)\n        elsif !value.nil?\n          target[key] = value\n        end\n      end\n    end\n\n    # Combine auto-excluded patterns with user-configured patterns\n    def all_exclude_patterns\n      patterns = AUTO_EXCLUDE.dup\n      patterns << out_dir.sub(%r{^\\./}, "") # Add output directory\n      patterns.concat(exclude_patterns)\n      patterns.uniq\n    end\n\n    # Convert absolute path to relative path from first src_dir\n    def relative_to_src(file_path)\n      base_dir = File.expand_path(src_dir)\n      full_path = File.expand_path(file_path)\n\n      if full_path.start_with?(base_dir)\n        full_path.sub("#{base_dir}/", "")\n      else\n        file_path\n      end\n    end\n\n    # Check if path matches a glob/directory pattern\n    def matches_pattern?(path, pattern)\n      # Direct directory match (e.g., "node_modules" matches "node_modules/foo.rb")\n      return true if path.start_with?("#{pattern}/") || path == pattern\n\n      # Check if any path component matches\n      path_parts = path.split("/")\n      return true if path_parts.include?(pattern)\n\n      # Glob pattern match\n      File.fnmatch?(pattern, path, File::FNM_PATHNAME | File::FNM_DOTMATCH)\n    end\n  end\nend\n',"lib/t_ruby/constraint_checker.rb":'# frozen_string_literal: true\n\nmodule TRuby\n  # Represents a type constraint\n  class Constraint\n    attr_reader :type, :condition, :message\n\n    def initialize(type:, condition:, message: nil)\n      @type = type\n      @condition = condition\n      @message = message\n    end\n\n    def to_s\n      "#{@type} where #{@condition}"\n    end\n  end\n\n  # Bounds constraint: T <: BaseType (T is subtype of BaseType)\n  class BoundsConstraint < Constraint\n    attr_reader :subtype, :supertype\n\n    def initialize(subtype:, supertype:)\n      @subtype = subtype\n      @supertype = supertype\n      super(type: :bounds, condition: "#{subtype} <: #{supertype}")\n    end\n\n    def satisfied?(type_hierarchy)\n      type_hierarchy.subtype_of?(@subtype, @supertype)\n    end\n  end\n\n  # Equality constraint: T == SpecificType\n  class EqualityConstraint < Constraint\n    attr_reader :left_type, :right_type\n\n    def initialize(left_type:, right_type:)\n      @left_type = left_type\n      @right_type = right_type\n      super(type: :equality, condition: "#{left_type} == #{right_type}")\n    end\n\n    def satisfied?(value_type)\n      [@left_type, @right_type].include?(value_type)\n    end\n  end\n\n  # Numeric range constraint: Integer where min..max\n  class NumericRangeConstraint < Constraint\n    attr_reader :base_type, :min, :max\n\n    def initialize(base_type:, min: nil, max: nil)\n      @base_type = base_type\n      @min = min\n      @max = max\n      range_str = build_range_string\n      super(type: :numeric_range, condition: range_str)\n    end\n\n    def satisfied?(value)\n      return false unless value.is_a?(Numeric)\n      return false if @min && value < @min\n      return false if @max && value > @max\n\n      true\n    end\n\n    def validation_code(var_name)\n      conditions = []\n      conditions << "#{var_name} >= #{@min}" if @min\n      conditions << "#{var_name} <= #{@max}" if @max\n      conditions.join(" && ")\n    end\n\n    private\n\n    def build_range_string\n      return "#{@min}..#{@max}" if @min && @max\n      return ">= #{@min}" if @min\n      return "<= #{@max}" if @max\n\n      ""\n    end\n  end\n\n  # Pattern constraint for strings: String where /pattern/\n  class PatternConstraint < Constraint\n    attr_reader :base_type, :pattern\n\n    def initialize(base_type:, pattern:)\n      @base_type = base_type\n      @pattern = pattern.is_a?(Regexp) ? pattern : Regexp.new(pattern)\n      super(type: :pattern, condition: "=~ #{@pattern.inspect}")\n    end\n\n    def satisfied?(value)\n      return false unless value.is_a?(String)\n\n      @pattern.match?(value)\n    end\n\n    def validation_code(var_name)\n      "#{@pattern.inspect}.match?(#{var_name})"\n    end\n  end\n\n  # Predicate constraint: Type where predicate_method\n  class PredicateConstraint < Constraint\n    attr_reader :base_type, :predicate\n\n    def initialize(base_type:, predicate:)\n      @base_type = base_type\n      @predicate = predicate\n      super(type: :predicate, condition: predicate.to_s)\n    end\n\n    def satisfied?(value)\n      if @predicate.is_a?(Proc)\n        @predicate.call(value)\n      elsif @predicate.is_a?(Symbol)\n        value.respond_to?(@predicate) && value.send(@predicate)\n      else\n        false\n      end\n    end\n\n    def validation_code(var_name)\n      if @predicate.is_a?(Symbol)\n        "#{var_name}.#{@predicate}"\n      else\n        "true" # Proc constraints require runtime evaluation\n      end\n    end\n  end\n\n  # Length constraint for strings/arrays: Type where length condition\n  class LengthConstraint < Constraint\n    attr_reader :base_type, :min_length, :max_length, :exact_length\n\n    def initialize(base_type:, min_length: nil, max_length: nil, exact_length: nil)\n      @base_type = base_type\n      @min_length = min_length\n      @max_length = max_length\n      @exact_length = exact_length\n      super(type: :length, condition: build_condition)\n    end\n\n    def satisfied?(value)\n      return false unless value.respond_to?(:length)\n\n      len = value.length\n      return len == @exact_length if @exact_length\n      return false if @min_length && len < @min_length\n      return false if @max_length && len > @max_length\n\n      true\n    end\n\n    def validation_code(var_name)\n      conditions = []\n      if @exact_length\n        conditions << "#{var_name}.length == #{@exact_length}"\n      else\n        conditions << "#{var_name}.length >= #{@min_length}" if @min_length\n        conditions << "#{var_name}.length <= #{@max_length}" if @max_length\n      end\n      conditions.join(" && ")\n    end\n\n    private\n\n    def build_condition\n      return "length == #{@exact_length}" if @exact_length\n\n      parts = []\n      parts << "length >= #{@min_length}" if @min_length\n      parts << "length <= #{@max_length}" if @max_length\n      parts.join(", ")\n    end\n  end\n\n  # Main constraint checker class\n  class ConstraintChecker\n    attr_reader :constraints, :errors\n\n    def initialize\n      @constraints = {}\n      @errors = []\n    end\n\n    # Register a constrained type\n    def register(name, base_type:, constraints: [])\n      @constraints[name] = {\n        base_type: base_type,\n        constraints: constraints,\n      }\n    end\n\n    # Parse constraint syntax from source\n    def parse_constraint(definition)\n      # Match: type Name <: BaseType where condition\n      if definition.match?(/^(\\w+)\\s*<:\\s*(\\w+)\\s*where\\s*(.+)$/)\n        match = definition.match(/^(\\w+)\\s*<:\\s*(\\w+)\\s*where\\s*(.+)$/)\n        name = match[1]\n        base_type = match[2]\n        condition = match[3].strip\n\n        constraints = parse_condition(base_type, condition)\n        return { name: name, base_type: base_type, constraints: constraints }\n      end\n\n      # Match: type Name <: BaseType (bounds only)\n      if definition.match?(/^(\\w+)\\s*<:\\s*(\\w+)\\s*$/)\n        match = definition.match(/^(\\w+)\\s*<:\\s*(\\w+)\\s*$/)\n        name = match[1]\n        base_type = match[2]\n\n        return {\n          name: name,\n          base_type: base_type,\n          constraints: [BoundsConstraint.new(subtype: name, supertype: base_type)],\n        }\n      end\n\n      # Match: type Name = BaseType where condition\n      if definition.match?(/^(\\w+)\\s*=\\s*(\\w+)\\s*where\\s*(.+)$/)\n        match = definition.match(/^(\\w+)\\s*=\\s*(\\w+)\\s*where\\s*(.+)$/)\n        name = match[1]\n        base_type = match[2]\n        condition = match[3].strip\n\n        constraints = parse_condition(base_type, condition)\n        return { name: name, base_type: base_type, constraints: constraints }\n      end\n\n      nil\n    end\n\n    # Validate a value against a constrained type\n    def validate(type_name, value)\n      @errors = []\n\n      unless @constraints.key?(type_name)\n        @errors << "Unknown constrained type: #{type_name}"\n        return false\n      end\n\n      type_info = @constraints[type_name]\n\n      # Check base type\n      unless matches_base_type?(value, type_info[:base_type])\n        @errors << "Value #{value.inspect} does not match base type #{type_info[:base_type]}"\n        return false\n      end\n\n      # Check all constraints\n      type_info[:constraints].each do |constraint|\n        unless constraint.satisfied?(value)\n          @errors << "Constraint violation: #{constraint.condition}"\n          return false\n        end\n      end\n\n      true\n    end\n\n    # Generate validation code for runtime checking\n    def generate_validation_code(type_name, var_name)\n      return nil unless @constraints.key?(type_name)\n\n      type_info = @constraints[type_name]\n      conditions = []\n\n      # Base type check\n      case type_info[:base_type]\n      when "Integer"\n        conditions << "#{var_name}.is_a?(Integer)"\n      when "String"\n        conditions << "#{var_name}.is_a?(String)"\n      when "Float"\n        conditions << "#{var_name}.is_a?(Float)"\n      when "Numeric"\n        conditions << "#{var_name}.is_a?(Numeric)"\n      when "Array"\n        conditions << "#{var_name}.is_a?(Array)"\n      end\n\n      # Constraint checks\n      type_info[:constraints].each do |constraint|\n        if constraint.respond_to?(:validation_code)\n          code = constraint.validation_code(var_name)\n          conditions << code unless code.empty?\n        end\n      end\n\n      conditions.join(" && ")\n    end\n\n    private\n\n    def parse_condition(base_type, condition)\n      constraints = []\n\n      # Numeric comparison: > N, < N, >= N, <= N\n      if condition.match?(/^([<>]=?)\\s*(\\d+(?:\\.\\d+)?)$/)\n        match = condition.match(/^([<>]=?)\\s*(\\d+(?:\\.\\d+)?)$/)\n        op = match[1]\n        value = match[2].include?(".") ? match[2].to_f : match[2].to_i\n\n        case op\n        when ">"\n          constraints << NumericRangeConstraint.new(base_type: base_type, min: value + 1)\n        when ">="\n          constraints << NumericRangeConstraint.new(base_type: base_type, min: value)\n        when "<"\n          constraints << NumericRangeConstraint.new(base_type: base_type, max: value - 1)\n        when "<="\n          constraints << NumericRangeConstraint.new(base_type: base_type, max: value)\n        end\n      end\n\n      # Range: min..max\n      if condition.match?(/^(\\d+)\\.\\.(\\d+)$/)\n        match = condition.match(/^(\\d+)\\.\\.(\\d+)$/)\n        constraints << NumericRangeConstraint.new(\n          base_type: base_type,\n          min: match[1].to_i,\n          max: match[2].to_i\n        )\n      end\n\n      # Pattern: /regex/\n      if condition.match?(%r{^/(.+)/$})\n        match = condition.match(%r{^/(.+)/$})\n        constraints << PatternConstraint.new(base_type: base_type, pattern: match[1])\n      end\n\n      # Length constraint: length > N, length == N, etc.\n      if condition.match?(/^length\\s*([<>=]+)\\s*(\\d+)$/)\n        match = condition.match(/^length\\s*([<>=]+)\\s*(\\d+)$/)\n        op = match[1]\n        value = match[2].to_i\n\n        case op\n        when "=="\n          constraints << LengthConstraint.new(base_type: base_type, exact_length: value)\n        when ">="\n          constraints << LengthConstraint.new(base_type: base_type, min_length: value)\n        when "<="\n          constraints << LengthConstraint.new(base_type: base_type, max_length: value)\n        when ">"\n          constraints << LengthConstraint.new(base_type: base_type, min_length: value + 1)\n        when "<"\n          constraints << LengthConstraint.new(base_type: base_type, max_length: value - 1)\n        end\n      end\n\n      # Predicate: positive?, negative?, empty?, etc.\n      if condition.match?(/^(\\w+)\\?$/)\n        match = condition.match(/^(\\w+)\\?$/)\n        constraints << PredicateConstraint.new(base_type: base_type, predicate: :"#{match[1]}?")\n      end\n\n      constraints\n    end\n\n    def matches_base_type?(value, type_name)\n      case type_name\n      when "Integer" then value.is_a?(Integer)\n      when "String" then value.is_a?(String)\n      when "Float" then value.is_a?(Float)\n      when "Numeric" then value.is_a?(Numeric)\n      when "Array" then value.is_a?(Array)\n      when "Hash" then value.is_a?(Hash)\n      when "Boolean" then [true, false].include?(value)\n      when "Symbol" then value.is_a?(Symbol)\n      else true # Unknown types pass through\n      end\n    end\n  end\n\n  # Constrained type registry for managing type constraints\n  class ConstrainedTypeRegistry\n    attr_reader :types\n\n    def initialize\n      @types = {}\n      @checker = ConstraintChecker.new\n    end\n\n    # Register a constrained type from parsed definition\n    def register(name, base_type:, constraints: [])\n      @types[name] = {\n        base_type: base_type,\n        constraints: constraints,\n        defined_at: caller_locations(1, 1).first,\n      }\n      @checker.register(name, base_type: base_type, constraints: constraints)\n    end\n\n    # Parse and register from source line\n    def register_from_source(line)\n      result = @checker.parse_constraint(line)\n      return false unless result\n\n      register(result[:name], base_type: result[:base_type], constraints: result[:constraints])\n      true\n    end\n\n    # Check if a type is registered\n    def registered?(name)\n      @types.key?(name)\n    end\n\n    # Get type info\n    def get(name)\n      @types[name]\n    end\n\n    # Validate value against type\n    def validate(type_name, value)\n      @checker.validate(type_name, value)\n    end\n\n    # Get validation errors\n    def errors\n      @checker.errors\n    end\n\n    # Generate validation code\n    def validation_code(type_name, var_name)\n      @checker.generate_validation_code(type_name, var_name)\n    end\n\n    # List all registered types\n    def list\n      @types.keys\n    end\n\n    # Clear all registrations\n    def clear\n      @types.clear\n      @checker = ConstraintChecker.new\n    end\n  end\nend\n',"lib/t_ruby/declaration_generator.rb":'# frozen_string_literal: true\n\nmodule TRuby\n  # Generator for .d.trb type declaration files\n  # Similar to TypeScript\'s .d.ts files\n  class DeclarationGenerator\n    DECLARATION_EXTENSION = ".d.trb"\n\n    def initialize\n      @parser = nil\n    end\n\n    # Generate declaration content from source code\n    def generate(source)\n      @parser = Parser.new(source)\n      result = @parser.parse\n\n      declarations = []\n\n      # Add header comment\n      declarations << "# Auto-generated type declaration file"\n      declarations << "# Do not edit manually"\n      declarations << ""\n\n      # Generate type alias declarations\n      (result[:type_aliases] || []).each do |type_alias|\n        declarations << generate_type_alias(type_alias)\n      end\n\n      # Generate interface declarations\n      (result[:interfaces] || []).each do |interface|\n        declarations << generate_interface(interface)\n      end\n\n      # Generate function declarations\n      (result[:functions] || []).each do |function|\n        declarations << generate_function(function)\n      end\n\n      declarations.join("\\n")\n    end\n\n    # Generate declaration file from a .trb source file\n    def generate_file(input_path, output_dir = nil)\n      unless File.exist?(input_path)\n        raise ArgumentError, "File not found: #{input_path}"\n      end\n\n      unless input_path.end_with?(".trb")\n        raise ArgumentError, "Expected .trb file, got: #{input_path}"\n      end\n\n      source = File.read(input_path)\n      content = generate(source)\n\n      # Determine output path\n      output_dir ||= File.dirname(input_path)\n      FileUtils.mkdir_p(output_dir)\n\n      base_name = File.basename(input_path, ".trb")\n      output_path = File.join(output_dir, "#{base_name}#{DECLARATION_EXTENSION}")\n\n      File.write(output_path, content)\n      output_path\n    end\n\n    # Generate declaration file to a specific output path\n    def generate_file_to_path(input_path, output_path)\n      unless File.exist?(input_path)\n        raise ArgumentError, "File not found: #{input_path}"\n      end\n\n      unless input_path.end_with?(".trb")\n        raise ArgumentError, "Expected .trb file, got: #{input_path}"\n      end\n\n      source = File.read(input_path)\n      content = generate(source)\n\n      File.write(output_path, content)\n      output_path\n    end\n\n    private\n\n    def generate_type_alias(type_alias)\n      "type #{type_alias[:name]} = #{type_alias[:definition]}"\n    end\n\n    def generate_interface(interface)\n      lines = []\n      lines << "interface #{interface[:name]}"\n\n      interface[:members].each do |member|\n        lines << "  #{member[:name]}: #{member[:type]}"\n      end\n\n      lines << "end"\n      lines.join("\\n")\n    end\n\n    def generate_function(function)\n      params = function[:params].map do |param|\n        if param[:type]\n          "#{param[:name]}: #{param[:type]}"\n        else\n          param[:name]\n        end\n      end.join(", ")\n\n      return_type = function[:return_type] ? ": #{function[:return_type]}" : ""\n\n      "def #{function[:name]}(#{params})#{return_type}"\n    end\n  end\n\n  # Parser for .d.trb declaration files\n  class DeclarationParser\n    attr_reader :type_aliases, :interfaces, :functions\n\n    def initialize\n      @type_aliases = {}\n      @interfaces = {}\n      @functions = {}\n    end\n\n    # Parse a declaration file content (resets existing data)\n    def parse(content)\n      @type_aliases = {}\n      @interfaces = {}\n      @functions = {}\n\n      parse_and_merge(content)\n    end\n\n    # Parse content and merge with existing data\n    def parse_and_merge(content)\n      parser = Parser.new(content)\n      result = parser.parse\n\n      # Process type aliases\n      (result[:type_aliases] || []).each do |type_alias|\n        @type_aliases[type_alias[:name]] = type_alias[:definition]\n      end\n\n      # Process interfaces\n      (result[:interfaces] || []).each do |interface|\n        @interfaces[interface[:name]] = interface\n      end\n\n      # Process functions\n      (result[:functions] || []).each do |function|\n        @functions[function[:name]] = function\n      end\n\n      self\n    end\n\n    # Parse a declaration file from path\n    def parse_file(file_path)\n      unless File.exist?(file_path)\n        raise ArgumentError, "Declaration file not found: #{file_path}"\n      end\n\n      unless file_path.end_with?(DeclarationGenerator::DECLARATION_EXTENSION)\n        raise ArgumentError, "Expected #{DeclarationGenerator::DECLARATION_EXTENSION} file, got: #{file_path}"\n      end\n\n      content = File.read(file_path)\n      parse(content)\n    end\n\n    # Load multiple declaration files from a directory\n    def load_directory(dir_path, recursive: false)\n      unless Dir.exist?(dir_path)\n        raise ArgumentError, "Directory not found: #{dir_path}"\n      end\n\n      pattern = recursive ? "**/*#{DeclarationGenerator::DECLARATION_EXTENSION}" : "*#{DeclarationGenerator::DECLARATION_EXTENSION}"\n      files = Dir.glob(File.join(dir_path, pattern))\n\n      files.each do |file|\n        content = File.read(file)\n        parse_and_merge(content)\n      end\n\n      self\n    end\n\n    # Check if a type is defined\n    def type_defined?(name)\n      @type_aliases.key?(name) || @interfaces.key?(name)\n    end\n\n    # Resolve a type alias\n    def resolve_type(name)\n      @type_aliases[name]\n    end\n\n    # Get an interface definition\n    def get_interface(name)\n      @interfaces[name]\n    end\n\n    # Get a function signature\n    def get_function(name)\n      @functions[name]\n    end\n\n    # Get all declarations as a hash\n    def to_h\n      {\n        type_aliases: @type_aliases,\n        interfaces: @interfaces,\n        functions: @functions,\n      }\n    end\n\n    # Merge another parser\'s declarations into this one\n    def merge(other_parser)\n      @type_aliases.merge!(other_parser.type_aliases)\n      @interfaces.merge!(other_parser.interfaces)\n      @functions.merge!(other_parser.functions)\n      self\n    end\n  end\n\n  # Loader for managing declaration files\n  class DeclarationLoader\n    attr_reader :search_paths\n\n    def initialize\n      @search_paths = []\n      @loaded_declarations = DeclarationParser.new\n      @loaded_files = Set.new\n    end\n\n    # Add a search path for declaration files\n    def add_search_path(path)\n      @search_paths << path unless @search_paths.include?(path)\n      self\n    end\n\n    # Load a specific declaration file by name (without extension)\n    def load(name)\n      file_name = "#{name}#{DeclarationGenerator::DECLARATION_EXTENSION}"\n\n      @search_paths.each do |path|\n        full_path = File.join(path, file_name)\n        next unless File.exist?(full_path) && !@loaded_files.include?(full_path)\n\n        parser = DeclarationParser.new\n        parser.parse_file(full_path)\n        @loaded_declarations.merge(parser)\n        @loaded_files.add(full_path)\n        return true\n      end\n\n      false\n    end\n\n    # Load all declaration files from search paths\n    def load_all\n      @search_paths.each do |path|\n        next unless Dir.exist?(path)\n\n        Dir.glob(File.join(path, "*#{DeclarationGenerator::DECLARATION_EXTENSION}")).each do |file|\n          next if @loaded_files.include?(file)\n\n          parser = DeclarationParser.new\n          parser.parse_file(file)\n          @loaded_declarations.merge(parser)\n          @loaded_files.add(file)\n        end\n      end\n\n      self\n    end\n\n    # Get the combined declarations\n    def declarations\n      @loaded_declarations\n    end\n\n    # Check if a type is defined in any loaded declaration\n    def type_defined?(name)\n      @loaded_declarations.type_defined?(name)\n    end\n\n    # Resolve a type from loaded declarations\n    def resolve_type(name)\n      @loaded_declarations.resolve_type(name)\n    end\n\n    # Get all loaded type aliases\n    def type_aliases\n      @loaded_declarations.type_aliases\n    end\n\n    # Get all loaded interfaces\n    def interfaces\n      @loaded_declarations.interfaces\n    end\n\n    # Get all loaded functions\n    def functions\n      @loaded_declarations.functions\n    end\n\n    # Get list of loaded files\n    def loaded_files\n      @loaded_files.to_a\n    end\n  end\nend\n',"lib/t_ruby/diagnostic.rb":'# frozen_string_literal: true\n\nmodule TRuby\n  class Diagnostic\n    SEVERITY_ERROR = :error\n    SEVERITY_WARNING = :warning\n    SEVERITY_INFO = :info\n    SEVERITY_HINT = :hint\n\n    attr_reader :code, :message, :file, :line, :column, :end_column,\n                :severity, :expected, :actual, :suggestion, :source_line\n\n    # rubocop:disable Metrics/ParameterLists\n    def initialize(\n      code:,\n      message:,\n      file: nil,\n      line: nil,\n      column: nil,\n      end_column: nil,\n      severity: SEVERITY_ERROR,\n      expected: nil,\n      actual: nil,\n      suggestion: nil,\n      source_line: nil\n    )\n      # rubocop:enable Metrics/ParameterLists\n      @code = code\n      @message = message\n      @file = file\n      @line = line\n      @column = column || 1\n      @end_column = end_column || (@column + 1)\n      @severity = severity\n      @expected = expected\n      @actual = actual\n      @suggestion = suggestion\n      @source_line = source_line\n    end\n\n    def self.from_type_check_error(error, file: nil, source: nil)\n      line, col = parse_location(error.location)\n      source_line = extract_source_line(source, line) if source && line\n\n      new(\n        code: "TR2001",\n        message: error.error_message,\n        file: file,\n        line: line,\n        column: col,\n        severity: error.severity || SEVERITY_ERROR,\n        expected: error.expected,\n        actual: error.actual,\n        suggestion: error.suggestion,\n        source_line: source_line\n      )\n    end\n\n    def self.from_parse_error(error, file: nil, source: nil)\n      source_line = extract_source_line(source, error.line) if source && error.line\n\n      new(\n        code: "TR1001",\n        message: error.message,\n        file: file,\n        line: error.line,\n        column: error.column,\n        source_line: source_line\n      )\n    end\n\n    def self.from_scan_error(error, file: nil, source: nil)\n      source_line = extract_source_line(source, error.line) if source && error.line\n      # ScanError adds " at line X, column Y" to the message in its constructor\n      message = error.message.sub(/ at line \\d+, column \\d+\\z/, "")\n\n      new(\n        code: "TR1001",\n        message: message,\n        file: file,\n        line: error.line,\n        column: error.column,\n        source_line: source_line\n      )\n    end\n\n    def error?\n      @severity == SEVERITY_ERROR\n    end\n\n    def self.parse_location(location_str)\n      return [nil, 1] unless location_str\n\n      case location_str\n      when /:(\\d+):(\\d+)$/\n        [::Regexp.last_match(1).to_i, ::Regexp.last_match(2).to_i]\n      when /:(\\d+)$/\n        [::Regexp.last_match(1).to_i, 1]\n      when /line (\\d+)/i\n        [::Regexp.last_match(1).to_i, 1]\n      else\n        [nil, 1]\n      end\n    end\n\n    def self.extract_source_line(source, line_num)\n      return nil unless source && line_num\n\n      lines = source.split("\\n")\n      lines[line_num - 1] if line_num.positive? && line_num <= lines.length\n    end\n\n    private_class_method :parse_location, :extract_source_line\n  end\nend\n',"lib/t_ruby/diagnostic_formatter.rb":'# frozen_string_literal: true\n\nmodule TRuby\n  class DiagnosticFormatter\n    COLORS = {\n      reset: "\\e[0m",\n      bold: "\\e[1m",\n      dim: "\\e[2m",\n      red: "\\e[31m",\n      green: "\\e[32m",\n      yellow: "\\e[33m",\n      blue: "\\e[34m",\n      cyan: "\\e[36m",\n      gray: "\\e[90m",\n      white: "\\e[37m",\n    }.freeze\n\n    def initialize(use_colors: nil)\n      @use_colors = use_colors.nil? ? $stdout.tty? : use_colors\n    end\n\n    def format(diagnostic)\n      lines = []\n\n      lines << format_header(diagnostic)\n\n      if diagnostic.source_line && diagnostic.line\n        lines << ""\n        lines << format_source_snippet(diagnostic)\n        lines << format_marker(diagnostic)\n        lines.concat(format_context(diagnostic))\n      end\n\n      lines.join("\\n")\n    end\n\n    def format_all(diagnostics)\n      return "" if diagnostics.empty?\n\n      output = diagnostics.map { |d| format(d) }.join("\\n\\n")\n      "#{output}\\n\\n#{format_summary(diagnostics)}"\n    end\n\n    private\n\n    def format_header(diagnostic)\n      location = format_location(diagnostic)\n      severity_text = colorize(severity_color(diagnostic.severity), diagnostic.severity.to_s)\n      code_text = colorize(:gray, diagnostic.code)\n\n      "#{location} - #{severity_text} #{code_text}: #{diagnostic.message}"\n    end\n\n    def format_location(diagnostic)\n      file_part = colorize(:cyan, diagnostic.file || "<unknown>")\n\n      if diagnostic.line\n        line_part = colorize(:yellow, diagnostic.line.to_s)\n        col_part = colorize(:yellow, diagnostic.column.to_s)\n        "#{file_part}:#{line_part}:#{col_part}"\n      else\n        file_part\n      end\n    end\n\n    def format_source_snippet(diagnostic)\n      line_num = diagnostic.line.to_s.rjust(4)\n      line_num_colored = colorize(:gray, line_num)\n\n      "#{line_num_colored} | #{diagnostic.source_line}"\n    end\n\n    def format_marker(diagnostic)\n      col = diagnostic.column || 1\n      width = calculate_marker_width(diagnostic)\n\n      indent = "#{" " * 4} | #{" " * (col - 1)}"\n      marker = colorize(:red, "~" * width)\n\n      "#{indent}#{marker}"\n    end\n\n    def calculate_marker_width(diagnostic)\n      # If end_column is explicitly set (not just default column + 1), use it\n      if diagnostic.end_column && diagnostic.end_column > diagnostic.column + 1\n        diagnostic.end_column - diagnostic.column\n      elsif diagnostic.source_line\n        # Try to guess width from identifier at error position\n        remaining = diagnostic.source_line[(diagnostic.column - 1)..]\n        if remaining && remaining =~ /^(\\w+)/\n          ::Regexp.last_match(1).length\n        else\n          1\n        end\n      else\n        1\n      end\n    end\n\n    def format_context(diagnostic)\n      lines = []\n      indent = "#{" " * 4} | "\n\n      if diagnostic.expected\n        label = colorize(:dim, "Expected:")\n        value = colorize(:green, diagnostic.expected)\n        lines << "#{indent}#{label} #{value}"\n      end\n\n      if diagnostic.actual\n        label = colorize(:dim, "Actual:")\n        value = colorize(:red, diagnostic.actual)\n        lines << "#{indent}#{label} #{value}"\n      end\n\n      if diagnostic.suggestion\n        label = colorize(:dim, "Suggestion:")\n        lines << "#{indent}#{label} #{diagnostic.suggestion}"\n      end\n\n      lines\n    end\n\n    def format_summary(diagnostics)\n      error_count = diagnostics.count { |d| d.severity == Diagnostic::SEVERITY_ERROR }\n      warning_count = diagnostics.count { |d| d.severity == Diagnostic::SEVERITY_WARNING }\n\n      parts = []\n\n      if error_count.positive?\n        error_word = error_count == 1 ? "error" : "errors"\n        parts << colorize(:red, "#{error_count} #{error_word}")\n      end\n\n      if warning_count.positive?\n        warning_word = warning_count == 1 ? "warning" : "warnings"\n        parts << colorize(:yellow, "#{warning_count} #{warning_word}")\n      end\n\n      if parts.empty?\n        colorize(:green, "No errors found.")\n      else\n        "Found #{parts.join(" and ")}."\n      end\n    end\n\n    def severity_color(severity)\n      case severity\n      when :error then :red\n      when :warning then :yellow\n      else :white\n      end\n    end\n\n    def colorize(color, text)\n      return text.to_s unless @use_colors\n      return text.to_s unless COLORS[color]\n\n      "#{COLORS[color]}#{text}#{COLORS[:reset]}"\n    end\n  end\nend\n',"lib/t_ruby/doc_generator.rb":'# frozen_string_literal: true\n\nrequire "json"\nrequire "fileutils"\nrequire "time"\n\nmodule TRuby\n  # API Documentation Generator\n  class DocGenerator\n    attr_reader :docs, :config\n\n    def initialize(config = nil)\n      @config = config || Config.new\n      @docs = {\n        types: {},\n        interfaces: {},\n        functions: {},\n        modules: {},\n      }\n      @parser = nil\n    end\n\n    # Generate documentation from source files\n    def generate(paths, output_dir: "docs")\n      puts "Generating T-Ruby API Documentation..."\n\n      # Parse all files\n      files = collect_files(paths)\n      files.each { |file| parse_file(file) }\n\n      # Generate output\n      FileUtils.mkdir_p(output_dir)\n\n      generate_index(output_dir)\n      generate_type_docs(output_dir)\n      generate_interface_docs(output_dir)\n      generate_function_docs(output_dir)\n      generate_module_docs(output_dir)\n      generate_search_index(output_dir)\n\n      puts "Documentation generated in #{output_dir}/"\n      @docs\n    end\n\n    # Generate single-file markdown documentation\n    def generate_markdown(paths, output_path: "API.md")\n      files = collect_files(paths)\n      files.each { |file| parse_file(file) }\n\n      md = []\n      md << "# T-Ruby API Documentation"\n      md << ""\n      md << "**Generated:** #{Time.now}"\n      md << ""\n      md << "## Table of Contents"\n      md << ""\n      md << "- [Types](#types)"\n      md << "- [Interfaces](#interfaces)"\n      md << "- [Functions](#functions)"\n      md << ""\n\n      # Types section\n      md << "## Types"\n      md << ""\n      @docs[:types].each do |name, info|\n        md << "### `#{name}`"\n        md << ""\n        md << "```typescript"\n        md << "type #{name} = #{info[:definition]}"\n        md << "```"\n        md << ""\n        md << info[:description] if info[:description]\n        md << ""\n        md << "**Source:** `#{info[:source]}`" if info[:source]\n        md << ""\n      end\n\n      # Interfaces section\n      md << "## Interfaces"\n      md << ""\n      @docs[:interfaces].each do |name, info|\n        md << "### `#{name}`"\n        md << ""\n        md << info[:description] if info[:description]\n        md << ""\n\n        if info[:type_params]&.any?\n          md << "**Type Parameters:** `<#{info[:type_params].join(", ")}>`"\n          md << ""\n        end\n\n        if info[:members]&.any?\n          md << "#### Members"\n          md << ""\n          md << "| Name | Type | Description |"\n          md << "|------|------|-------------|"\n          info[:members].each do |member|\n            md << "| `#{member[:name]}` | `#{member[:type]}` | #{member[:description] || "-"} |"\n          end\n          md << ""\n        end\n\n        md << "**Source:** `#{info[:source]}`" if info[:source]\n        md << ""\n      end\n\n      # Functions section\n      md << "## Functions"\n      md << ""\n      @docs[:functions].each do |name, info|\n        md << "### `#{name}`"\n        md << ""\n        md << info[:description] if info[:description]\n        md << ""\n\n        # Signature\n        params = info[:params]&.map { |p| "#{p[:name]}: #{p[:type]}" }&.join(", ") || ""\n        type_params = info[:type_params]&.any? ? "<#{info[:type_params].join(", ")}>" : ""\n        md << "```ruby"\n        md << "def #{name}#{type_params}(#{params}): #{info[:return_type] || "void"}"\n        md << "```"\n        md << ""\n\n        if info[:params]&.any?\n          md << "#### Parameters"\n          md << ""\n          md << "| Name | Type | Description |"\n          md << "|------|------|-------------|"\n          info[:params].each do |param|\n            md << "| `#{param[:name]}` | `#{param[:type]}` | #{param[:description] || "-"} |"\n          end\n          md << ""\n        end\n\n        md << "**Returns:** `#{info[:return_type]}`" if info[:return_type]\n        md << ""\n        md << "**Source:** `#{info[:source]}`" if info[:source]\n        md << ""\n      end\n\n      File.write(output_path, md.join("\\n"))\n      puts "Documentation generated: #{output_path}"\n    end\n\n    # Generate JSON documentation\n    def generate_json(paths, output_path: "api.json")\n      files = collect_files(paths)\n      files.each { |file| parse_file(file) }\n\n      File.write(output_path, JSON.pretty_generate({\n                                                     generated_at: Time.now.iso8601,\n                                                     version: TRuby::VERSION,\n                                                     types: @docs[:types],\n                                                     interfaces: @docs[:interfaces],\n                                                     functions: @docs[:functions],\n                                                     modules: @docs[:modules],\n                                                   }))\n\n      puts "JSON documentation generated: #{output_path}"\n    end\n\n    private\n\n    def parser\n      @parser ||= Parser.new("")\n    end\n\n    def collect_files(paths)\n      files = []\n      paths.each do |path|\n        if File.directory?(path)\n          files.concat(Dir.glob(File.join(path, "**", "*.trb")))\n          files.concat(Dir.glob(File.join(path, "**", "*.d.trb")))\n        elsif File.file?(path)\n          files << path\n        end\n      end\n      files.uniq\n    end\n\n    def parse_file(file_path)\n      content = File.read(file_path)\n      relative_path = file_path.sub("#{Dir.pwd}/", "")\n\n      # Extract documentation comments\n      doc_comments = extract_doc_comments(content)\n\n      # Parse type aliases\n      content.scan(/^type\\s+(\\w+)(?:<([^>]+)>)?\\s*=\\s*(.+)$/) do |name, type_params, definition|\n        @docs[:types][name] = {\n          name: name,\n          type_params: type_params&.split(/\\s*,\\s*/),\n          definition: definition.strip,\n          description: doc_comments["type:#{name}"],\n          source: relative_path,\n        }\n      end\n\n      # Parse interfaces\n      parse_interfaces(content, relative_path, doc_comments)\n\n      # Parse functions\n      parse_functions(content, relative_path, doc_comments)\n    end\n\n    def extract_doc_comments(content)\n      comments = {}\n      current_comment = []\n      current_target = nil\n\n      content.each_line do |line|\n        if line =~ /^\\s*#\\s*@doc\\s+(\\w+):(\\w+)/\n          current_target = "#{Regexp.last_match(1)}:#{Regexp.last_match(2)}"\n          current_comment = []\n        elsif line =~ /^\\s*#\\s*(.+)/ && current_target\n          current_comment << Regexp.last_match(1).strip\n        elsif line !~ /^\\s*#/ && current_target\n          comments[current_target] = current_comment.join(" ")\n          current_target = nil\n          current_comment = []\n        end\n\n        # Also check inline comments before definitions\n        if line =~ /^\\s*#\\s*(.+)$/\n          current_comment << Regexp.last_match(1).strip\n        elsif line =~ /^(type|interface|def)\\s+(\\w+)/\n          type = Regexp.last_match(1)\n          name = Regexp.last_match(2)\n          unless current_comment.empty?\n            comments["#{type}:#{name}"] = current_comment.join(" ")\n          end\n          current_comment = []\n        end\n      end\n\n      comments\n    end\n\n    def parse_interfaces(content, source, doc_comments)\n      # Match interface blocks\n      content.scan(/interface\\s+(\\w+)(?:<([^>]+)>)?\\s*\\n((?:(?!^end).)*?)^end/m) do |name, type_params, body|\n        members = []\n\n        body.scan(/^\\s*(\\w+[?!]?)\\s*:\\s*(.+)$/) do |member_name, member_type|\n          members << {\n            name: member_name,\n            type: member_type.strip,\n            description: doc_comments["member:#{name}.#{member_name}"],\n          }\n        end\n\n        @docs[:interfaces][name] = {\n          name: name,\n          type_params: type_params&.split(/\\s*,\\s*/),\n          members: members,\n          description: doc_comments["interface:#{name}"],\n          source: source,\n        }\n      end\n    end\n\n    def parse_functions(content, source, doc_comments)\n      # Match function definitions\n      content.scan(/def\\s+(\\w+[?!]?)(?:<([^>]+)>)?\\s*\\(([^)]*)\\)(?:\\s*:\\s*(.+?))?(?:\\n|$)/) do |name, type_params, params_str, return_type|\n        params = []\n\n        params_str.scan(/(\\w+)\\s*:\\s*([^,]+)/) do |param_name, param_type|\n          params << {\n            name: param_name,\n            type: param_type.strip,\n            description: doc_comments["param:#{name}.#{param_name}"],\n          }\n        end\n\n        @docs[:functions][name] = {\n          name: name,\n          type_params: type_params&.split(/\\s*,\\s*/),\n          params: params,\n          return_type: return_type&.strip,\n          description: doc_comments["def:#{name}"],\n          source: source,\n        }\n      end\n    end\n\n    def generate_index(output_dir)\n      html = <<~HTML\n        <!DOCTYPE html>\n        <html>\n        <head>\n          <title>T-Ruby API Documentation</title>\n          <style>\n            body { font-family: -apple-system, BlinkMacSystemFont, \'Segoe UI\', Roboto, sans-serif; margin: 40px; }\n            h1 { color: #cc342d; }\n            .section { margin: 20px 0; }\n            a { color: #0366d6; text-decoration: none; }\n            a:hover { text-decoration: underline; }\n            .item { padding: 5px 0; }\n            code { background: #f6f8fa; padding: 2px 6px; border-radius: 3px; }\n          </style>\n        </head>\n        <body>\n          <h1>T-Ruby API Documentation</h1>\n          <p>Generated: #{Time.now}</p>\n\n          <div class="section">\n            <h2>Types (#{@docs[:types].size})</h2>\n            #{@docs[:types].keys.sort.map { |name| "<div class=\'item\'><a href=\'types/#{name}.html\'><code>#{name}</code></a></div>" }.join}\n          </div>\n\n          <div class="section">\n            <h2>Interfaces (#{@docs[:interfaces].size})</h2>\n            #{@docs[:interfaces].keys.sort.map { |name| "<div class=\'item\'><a href=\'interfaces/#{name}.html\'><code>#{name}</code></a></div>" }.join}\n          </div>\n\n          <div class="section">\n            <h2>Functions (#{@docs[:functions].size})</h2>\n            #{@docs[:functions].keys.sort.map { |name| "<div class=\'item\'><a href=\'functions/#{name}.html\'><code>#{name}</code></a></div>" }.join}\n          </div>\n        </body>\n        </html>\n      HTML\n\n      File.write(File.join(output_dir, "index.html"), html)\n    end\n\n    def generate_type_docs(output_dir)\n      types_dir = File.join(output_dir, "types")\n      FileUtils.mkdir_p(types_dir)\n\n      @docs[:types].each do |name, info|\n        html = generate_type_html(name, info)\n        File.write(File.join(types_dir, "#{name}.html"), html)\n      end\n    end\n\n    def generate_interface_docs(output_dir)\n      interfaces_dir = File.join(output_dir, "interfaces")\n      FileUtils.mkdir_p(interfaces_dir)\n\n      @docs[:interfaces].each do |name, info|\n        html = generate_interface_html(name, info)\n        File.write(File.join(interfaces_dir, "#{name}.html"), html)\n      end\n    end\n\n    def generate_function_docs(output_dir)\n      functions_dir = File.join(output_dir, "functions")\n      FileUtils.mkdir_p(functions_dir)\n\n      @docs[:functions].each do |name, info|\n        html = generate_function_html(name, info)\n        File.write(File.join(functions_dir, "#{name}.html"), html)\n      end\n    end\n\n    def generate_module_docs(output_dir)\n      # Placeholder for module documentation\n    end\n\n    def generate_search_index(output_dir)\n      search_data = []\n\n      @docs[:types].each_key do |name|\n        search_data << { type: "type", name: name, url: "types/#{name}.html" }\n      end\n\n      @docs[:interfaces].each_key do |name|\n        search_data << { type: "interface", name: name, url: "interfaces/#{name}.html" }\n      end\n\n      @docs[:functions].each_key do |name|\n        search_data << { type: "function", name: name, url: "functions/#{name}.html" }\n      end\n\n      File.write(File.join(output_dir, "search-index.json"), JSON.generate(search_data))\n    end\n\n    def generate_type_html(name, info)\n      <<~HTML\n        <!DOCTYPE html>\n        <html>\n        <head>\n          <title>#{name} - T-Ruby API</title>\n          <style>\n            body { font-family: -apple-system, BlinkMacSystemFont, \'Segoe UI\', Roboto, sans-serif; margin: 40px; }\n            h1 { color: #cc342d; }\n            pre { background: #f6f8fa; padding: 16px; border-radius: 6px; overflow-x: auto; }\n            .meta { color: #6a737d; font-size: 14px; }\n            a { color: #0366d6; }\n          </style>\n        </head>\n        <body>\n          <a href="../index.html">\u2190 Back to Index</a>\n          <h1>type #{name}</h1>\n          #{"<p>#{info[:description]}</p>" if info[:description]}\n          <pre>type #{name}#{"<#{info[:type_params].join(", ")}>" if info[:type_params]} = #{info[:definition]}</pre>\n          <p class="meta">Source: <code>#{info[:source]}</code></p>\n        </body>\n        </html>\n      HTML\n    end\n\n    def generate_interface_html(name, info)\n      members_html = info[:members]&.map do |m|\n        "<tr><td><code>#{m[:name]}</code></td><td><code>#{m[:type]}</code></td><td>#{m[:description] || "-"}</td></tr>"\n      end&.join || ""\n\n      <<~HTML\n        <!DOCTYPE html>\n        <html>\n        <head>\n          <title>#{name} - T-Ruby API</title>\n          <style>\n            body { font-family: -apple-system, BlinkMacSystemFont, \'Segoe UI\', Roboto, sans-serif; margin: 40px; }\n            h1 { color: #cc342d; }\n            table { border-collapse: collapse; width: 100%; }\n            th, td { border: 1px solid #ddd; padding: 8px; text-align: left; }\n            th { background: #f6f8fa; }\n            pre { background: #f6f8fa; padding: 16px; border-radius: 6px; }\n            .meta { color: #6a737d; font-size: 14px; }\n            a { color: #0366d6; }\n          </style>\n        </head>\n        <body>\n          <a href="../index.html">\u2190 Back to Index</a>\n          <h1>interface #{name}#{"&lt;#{info[:type_params].join(", ")}&gt;" if info[:type_params]}</h1>\n          #{"<p>#{info[:description]}</p>" if info[:description]}\n          #{"<h2>Members</h2><table><tr><th>Name</th><th>Type</th><th>Description</th></tr>#{members_html}</table>" unless members_html.empty?}\n          <p class="meta">Source: <code>#{info[:source]}</code></p>\n        </body>\n        </html>\n      HTML\n    end\n\n    def generate_function_html(name, info)\n      params_html = info[:params]&.map do |p|\n        "<tr><td><code>#{p[:name]}</code></td><td><code>#{p[:type]}</code></td><td>#{p[:description] || "-"}</td></tr>"\n      end&.join || ""\n\n      params_sig = info[:params]&.map { |p| "#{p[:name]}: #{p[:type]}" }&.join(", ") || ""\n      type_params = info[:type_params]&.any? ? "<#{info[:type_params].join(", ")}>" : ""\n\n      <<~HTML\n        <!DOCTYPE html>\n        <html>\n        <head>\n          <title>#{name} - T-Ruby API</title>\n          <style>\n            body { font-family: -apple-system, BlinkMacSystemFont, \'Segoe UI\', Roboto, sans-serif; margin: 40px; }\n            h1 { color: #cc342d; }\n            table { border-collapse: collapse; width: 100%; }\n            th, td { border: 1px solid #ddd; padding: 8px; text-align: left; }\n            th { background: #f6f8fa; }\n            pre { background: #f6f8fa; padding: 16px; border-radius: 6px; }\n            .meta { color: #6a737d; font-size: 14px; }\n            a { color: #0366d6; }\n          </style>\n        </head>\n        <body>\n          <a href="../index.html">\u2190 Back to Index</a>\n          <h1>#{name}</h1>\n          #{"<p>#{info[:description]}</p>" if info[:description]}\n          <h2>Signature</h2>\n          <pre>def #{name}#{type_params}(#{params_sig}): #{info[:return_type] || "void"}</pre>\n          #{"<h2>Parameters</h2><table><tr><th>Name</th><th>Type</th><th>Description</th></tr>#{params_html}</table>" unless params_html.empty?}\n          <h2>Returns</h2>\n          <p><code>#{info[:return_type] || "void"}</code></p>\n          <p class="meta">Source: <code>#{info[:source]}</code></p>\n        </body>\n        </html>\n      HTML\n    end\n  end\nend\n',"lib/t_ruby/docs_badge_generator.rb":'# frozen_string_literal: true\n\nrequire "time"\nrequire_relative "docs_example_verifier"\n\nmodule TRuby\n  # Generates badges and reports for documentation verification results.\n  #\n  # Supports:\n  # - Shields.io compatible JSON badges\n  # - SVG badge generation\n  # - Markdown report generation\n  # - JSON report generation\n  #\n  # @example\n  #   generator = DocsBadgeGenerator.new\n  #   verifier = DocsExampleVerifier.new\n  #   results = verifier.verify_glob("docs/**/*.md")\n  #   generator.generate_badge(results, "coverage/docs_badge.json")\n  #\n  class DocsBadgeGenerator\n    # Badge colors based on pass rate\n    COLORS = {\n      excellent: "brightgreen",   # 95-100%\n      good: "green",              # 80-94%\n      fair: "yellow",             # 60-79%\n      poor: "orange",             # 40-59%\n      critical: "red",            # 0-39%\n    }.freeze\n\n    def initialize\n      @verifier = DocsExampleVerifier.new\n    end\n\n    # Generate all outputs\n    #\n    # @param results [Array<DocsExampleVerifier::VerificationResult>] Results\n    # @param output_dir [String] Output directory\n    def generate_all(results, output_dir)\n      FileUtils.mkdir_p(output_dir)\n\n      generate_badge_json(results, File.join(output_dir, "docs_badge.json"))\n      generate_badge_svg(results, File.join(output_dir, "docs_badge.svg"))\n      generate_report_json(results, File.join(output_dir, "docs_report.json"))\n      generate_report_markdown(results, File.join(output_dir, "docs_report.md"))\n    end\n\n    # Generate Shields.io compatible JSON badge\n    #\n    # @param results [Array<DocsExampleVerifier::VerificationResult>] Results\n    # @param output_path [String] Output file path\n    def generate_badge_json(results, output_path)\n      summary = @verifier.summary(results)\n      pass_rate = summary[:pass_rate]\n\n      badge = {\n        schemaVersion: 1,\n        label: "docs examples",\n        message: "#{pass_rate}%",\n        color: color_for_rate(pass_rate),\n      }\n\n      File.write(output_path, JSON.pretty_generate(badge))\n    end\n\n    # Generate SVG badge\n    #\n    # @param results [Array<DocsExampleVerifier::VerificationResult>] Results\n    # @param output_path [String] Output file path\n    def generate_badge_svg(results, output_path)\n      summary = @verifier.summary(results)\n      pass_rate = summary[:pass_rate]\n      color = svg_color_for_rate(pass_rate)\n\n      svg = <<~SVG\n        <svg xmlns="http://www.w3.org/2000/svg" width="140" height="20">\n          <linearGradient id="b" x2="0" y2="100%">\n            <stop offset="0" stop-color="#bbb" stop-opacity=".1"/>\n            <stop offset="1" stop-opacity=".1"/>\n          </linearGradient>\n          <mask id="a">\n            <rect width="140" height="20" rx="3" fill="#fff"/>\n          </mask>\n          <g mask="url(#a)">\n            <path fill="#555" d="M0 0h85v20H0z"/>\n            <path fill="#{color}" d="M85 0h55v20H85z"/>\n            <path fill="url(#b)" d="M0 0h140v20H0z"/>\n          </g>\n          <g fill="#fff" text-anchor="middle" font-family="DejaVu Sans,Verdana,Geneva,sans-serif" font-size="11">\n            <text x="42.5" y="15" fill="#010101" fill-opacity=".3">docs examples</text>\n            <text x="42.5" y="14">docs examples</text>\n            <text x="112" y="15" fill="#010101" fill-opacity=".3">#{pass_rate}%</text>\n            <text x="112" y="14">#{pass_rate}%</text>\n          </g>\n        </svg>\n      SVG\n\n      File.write(output_path, svg)\n    end\n\n    # Generate JSON report\n    #\n    # @param results [Array<DocsExampleVerifier::VerificationResult>] Results\n    # @param output_path [String] Output file path\n    def generate_report_json(results, output_path)\n      summary = @verifier.summary(results)\n\n      report = {\n        generated_at: Time.now.iso8601,\n        summary: summary,\n        files: group_results_by_file(results),\n      }\n\n      File.write(output_path, JSON.pretty_generate(report))\n    end\n\n    # Generate Markdown report\n    #\n    # @param results [Array<DocsExampleVerifier::VerificationResult>] Results\n    # @param output_path [String] Output file path\n    def generate_report_markdown(results, output_path)\n      summary = @verifier.summary(results)\n      grouped = group_results_by_file(results)\n\n      markdown = <<~MD\n        # Documentation Examples Verification Report\n\n        Generated: #{Time.now.strftime("%Y-%m-%d %H:%M:%S")}\n\n        ## Summary\n\n        | Metric | Value |\n        |--------|-------|\n        | Total Examples | #{summary[:total]} |\n        | Passed | #{summary[:passed]} |\n        | Failed | #{summary[:failed]} |\n        | Skipped | #{summary[:skipped]} |\n        | **Pass Rate** | **#{summary[:pass_rate]}%** |\n\n        ## Results by File\n\n      MD\n\n      grouped.each do |file_path, file_results|\n        file_summary = @verifier.summary(file_results)\n        status_emoji = file_summary[:failed].zero? ? "\u2705" : "\u274c"\n\n        markdown += "### #{status_emoji} #{file_path}\\n\\n"\n        markdown += "Pass rate: #{file_summary[:pass_rate]}% (#{file_summary[:passed]}/#{file_summary[:total]})\\n\\n"\n\n        failed_results = file_results.select(&:fail?)\n        next unless failed_results.any?\n\n        markdown += "**Failed examples:**\\n\\n"\n        failed_results.each do |result|\n          markdown += "- Line #{result.line_number}:\\n"\n          result.errors.each do |error|\n            markdown += "  - #{error}\\n"\n          end\n        end\n        markdown += "\\n"\n      end\n\n      File.write(output_path, markdown)\n    end\n\n    private\n\n    def color_for_rate(rate)\n      case rate\n      when 95..100 then COLORS[:excellent]\n      when 80...95 then COLORS[:good]\n      when 60...80 then COLORS[:fair]\n      when 40...60 then COLORS[:poor]\n      else COLORS[:critical]\n      end\n    end\n\n    def svg_color_for_rate(rate)\n      case rate\n      when 95..100 then "#4c1"      # bright green\n      when 80...95 then "#97ca00"   # green\n      when 60...80 then "#dfb317"   # yellow\n      when 40...60 then "#fe7d37"   # orange\n      else "#e05d44"                # red\n      end\n    end\n\n    def group_results_by_file(results)\n      results.group_by(&:file_path)\n    end\n  end\nend\n',"lib/t_ruby/docs_example_extractor.rb":'# frozen_string_literal: true\n\nmodule TRuby\n  # Extracts code examples from Markdown documentation files.\n  #\n  # Supports extracting:\n  # - T-Ruby code blocks (```trb, ```t-ruby, ```ruby with type annotations)\n  # - Ruby code blocks for comparison\n  # - RBS type definitions\n  #\n  # @example\n  #   extractor = DocsExampleExtractor.new\n  #   examples = extractor.extract_from_file("docs/getting-started.md")\n  #   examples.each { |ex| puts ex.code }\n  #\n  class DocsExampleExtractor\n    # Represents an extracted code example\n    CodeExample = Struct.new(\n      :code,           # The code content\n      :language,       # Language identifier (trb, ruby, rbs)\n      :file_path,      # Source file path\n      :line_number,    # Starting line number\n      :metadata,       # Optional metadata from code fence\n      keyword_init: true\n    ) do\n      def trb?\n        %w[trb t-ruby].include?(language)\n      end\n\n      def ruby?\n        language == "ruby"\n      end\n\n      def rbs?\n        language == "rbs"\n      end\n\n      def should_verify?\n        !metadata&.include?("skip-verify")\n      end\n\n      def should_compile?\n        !metadata&.include?("no-compile")\n      end\n\n      def should_typecheck?\n        !metadata&.include?("no-typecheck")\n      end\n    end\n\n    # Code fence pattern: ```language title="file.ext" {metadata}\n    # Supports Docusaurus format: ```ruby title="example.trb"\n    CODE_FENCE_PATTERN = /^```(\\w+)?(?:\\s+title="([^"]*)")?(?:\\s*\\{([^}]*)\\})?/\n\n    # Extract all code examples from a file\n    #\n    # @param file_path [String] Path to the markdown file\n    # @return [Array<CodeExample>] Extracted code examples\n    def extract_from_file(file_path)\n      content = File.read(file_path, encoding: "UTF-8")\n      extract_from_content(content, file_path)\n    end\n\n    # Extract all code examples from content\n    #\n    # @param content [String] Markdown content\n    # @param file_path [String] Source file path (for reference)\n    # @return [Array<CodeExample>] Extracted code examples\n    def extract_from_content(content, file_path = "<string>")\n      examples = []\n      lines = content.lines\n      in_code_block = false\n      current_block = nil\n      block_start_line = 0\n\n      lines.each_with_index do |line, index|\n        line_number = index + 1\n\n        if !in_code_block && (match = line.match(CODE_FENCE_PATTERN))\n          in_code_block = true\n          block_start_line = line_number\n          lang = match[1] || "text"\n          title = match[2]\n          metadata = match[3]\n\n          # If title ends with .trb, treat as T-Ruby regardless of language tag\n          if title&.end_with?(".trb")\n            lang = "trb"\n          end\n\n          current_block = {\n            language: lang,\n            metadata: metadata,\n            title: title,\n            lines: [],\n          }\n        elsif in_code_block && line.match(/^```\\s*$/)\n          in_code_block = false\n\n          # Only include relevant languages\n          if relevant_language?(current_block[:language])\n            examples << CodeExample.new(\n              code: current_block[:lines].join,\n              language: normalize_language(current_block[:language]),\n              file_path: file_path,\n              line_number: block_start_line,\n              metadata: current_block[:metadata]\n            )\n          end\n\n          current_block = nil\n        elsif in_code_block\n          current_block[:lines] << line\n        end\n      end\n\n      examples\n    end\n\n    # Extract from multiple files using glob pattern\n    #\n    # @param pattern [String] Glob pattern (e.g., "docs/**/*.md")\n    # @return [Array<CodeExample>] All extracted examples\n    def extract_from_glob(pattern)\n      Dir.glob(pattern).flat_map { |file| extract_from_file(file) }\n    end\n\n    # Get statistics about extracted examples\n    #\n    # @param examples [Array<CodeExample>] Code examples\n    # @return [Hash] Statistics\n    def statistics(examples)\n      {\n        total: examples.size,\n        trb: examples.count(&:trb?),\n        ruby: examples.count(&:ruby?),\n        rbs: examples.count(&:rbs?),\n        verifiable: examples.count(&:should_verify?),\n        files: examples.map(&:file_path).uniq.size,\n      }\n    end\n\n    private\n\n    def relevant_language?(lang)\n      %w[trb t-ruby ruby rbs].include?(lang&.downcase)\n    end\n\n    def normalize_language(lang)\n      case lang&.downcase\n      when "t-ruby" then "trb"\n      else lang&.downcase || "text"\n      end\n    end\n  end\nend\n',"lib/t_ruby/docs_example_verifier.rb":'# frozen_string_literal: true\n\nrequire_relative "docs_example_extractor"\n\nmodule TRuby\n  # Verifies code examples extracted from documentation.\n  #\n  # Performs:\n  # - Syntax validation (parsing)\n  # - Type checking (for .trb examples)\n  # - Compilation (generates Ruby output)\n  #\n  # @example\n  #   verifier = DocsExampleVerifier.new\n  #   results = verifier.verify_file("docs/getting-started.md")\n  #   results.each { |r| puts "#{r.status}: #{r.file_path}:#{r.line_number}" }\n  #\n  class DocsExampleVerifier\n    # Result of verifying a single example\n    VerificationResult = Struct.new(\n      :example,        # The original CodeExample\n      :status,         # :pass, :fail, :skip\n      :errors,         # Array of error messages\n      :output,         # Compiled output (if applicable)\n      keyword_init: true\n    ) do\n      def pass?\n        status == :pass\n      end\n\n      def fail?\n        status == :fail\n      end\n\n      def skip?\n        status == :skip\n      end\n\n      def file_path\n        example.file_path\n      end\n\n      def line_number\n        example.line_number\n      end\n    end\n\n    def initialize\n      @extractor = DocsExampleExtractor.new\n      @compiler = TRuby::Compiler.new\n    end\n\n    # Verify all examples in a file\n    #\n    # @param file_path [String] Path to the markdown file\n    # @return [Array<VerificationResult>] Results for each example\n    def verify_file(file_path)\n      examples = @extractor.extract_from_file(file_path)\n      examples.map { |example| verify_example(example) }\n    end\n\n    # Verify all examples from multiple files\n    #\n    # @param pattern [String] Glob pattern\n    # @return [Array<VerificationResult>] All results\n    def verify_glob(pattern)\n      examples = @extractor.extract_from_glob(pattern)\n      examples.map { |example| verify_example(example) }\n    end\n\n    # Verify a single code example\n    #\n    # @param example [DocsExampleExtractor::CodeExample] The example to verify\n    # @return [VerificationResult] The verification result\n    def verify_example(example)\n      return skip_result(example, "Marked as skip-verify") unless example.should_verify?\n\n      case example.language\n      when "trb"\n        verify_trb_example(example)\n      when "ruby"\n        verify_ruby_example(example)\n      when "rbs"\n        verify_rbs_example(example)\n      else\n        skip_result(example, "Unknown language: #{example.language}")\n      end\n    rescue StandardError => e\n      fail_result(example, ["Exception: #{e.message}"])\n    end\n\n    # Generate a summary report\n    #\n    # @param results [Array<VerificationResult>] Verification results\n    # @return [Hash] Summary statistics\n    def summary(results)\n      {\n        total: results.size,\n        passed: results.count(&:pass?),\n        failed: results.count(&:fail?),\n        skipped: results.count(&:skip?),\n        pass_rate: results.empty? ? 0 : (results.count(&:pass?).to_f / results.size * 100).round(2),\n      }\n    end\n\n    # Print results to stdout\n    #\n    # @param results [Array<VerificationResult>] Verification results\n    # @param verbose [Boolean] Show passing tests too\n    def print_results(results, verbose: false)\n      results.each do |result|\n        next if result.pass? && !verbose\n\n        status_icon = case result.status\n                      when :pass then "\\e[32m\u2713\\e[0m"\n                      when :fail then "\\e[31m\u2717\\e[0m"\n                      when :skip then "\\e[33m\u25cb\\e[0m"\n                      end\n\n        puts "#{status_icon} #{result.file_path}:#{result.line_number}"\n\n        result.errors&.each do |error|\n          puts "    #{error}"\n        end\n      end\n\n      summary_data = summary(results)\n      puts\n      puts "Results: #{summary_data[:passed]} passed, #{summary_data[:failed]} failed, #{summary_data[:skipped]} skipped"\n      puts "Pass rate: #{summary_data[:pass_rate]}%"\n    end\n\n    private\n\n    def verify_trb_example(example)\n      errors = []\n\n      # Step 1: Parse\n      ir_program = nil\n      begin\n        parser = TRuby::Parser.new(example.code)\n        parser.parse\n        ir_program = parser.ir_program\n      rescue TRuby::ParseError => e\n        return fail_result(example, ["Parse error: #{e.message}"])\n      end\n\n      # Step 2: Type check (if enabled)\n      if example.should_typecheck? && ir_program\n        begin\n          type_checker = TRuby::TypeChecker.new(use_smt: false)\n          result = type_checker.check_program(ir_program)\n          if result[:errors]&.any?\n            errors.concat(result[:errors].map { |e| "Type error: #{e}" })\n          end\n        rescue StandardError => e\n          errors << "Type check error: #{e.message}"\n        end\n      end\n\n      # Step 3: Compile (if enabled)\n      output = nil\n      if example.should_compile?\n        begin\n          output = @compiler.compile_string(example.code)\n        rescue StandardError => e\n          errors << "Compile error: #{e.message}"\n        end\n      end\n\n      errors.empty? ? pass_result(example, output) : fail_result(example, errors)\n    end\n\n    def verify_ruby_example(example)\n      # For Ruby examples, just validate syntax\n\n      RubyVM::InstructionSequence.compile(example.code)\n      pass_result(example)\n    rescue SyntaxError => e\n      fail_result(example, ["Ruby syntax error: #{e.message}"])\n    end\n\n    def verify_rbs_example(example)\n      # For RBS, we just do basic validation\n      # Full RBS validation would require rbs gem\n      if example.code.include?("def ") || example.code.include?("type ") ||\n         example.code.include?("interface ") || example.code.include?("class ")\n        pass_result(example)\n      else\n        skip_result(example, "Cannot validate RBS without rbs gem")\n      end\n    end\n\n    def pass_result(example, output = nil)\n      VerificationResult.new(\n        example: example,\n        status: :pass,\n        errors: [],\n        output: output\n      )\n    end\n\n    def fail_result(example, errors)\n      VerificationResult.new(\n        example: example,\n        status: :fail,\n        errors: errors,\n        output: nil\n      )\n    end\n\n    def skip_result(example, reason)\n      VerificationResult.new(\n        example: example,\n        status: :skip,\n        errors: [reason],\n        output: nil\n      )\n    end\n  end\nend\n',"lib/t_ruby/error_handler.rb":'# frozen_string_literal: true\n\nmodule TRuby\n  class ErrorHandler\n    VALID_TYPES = %w[String Integer Float Boolean Array Hash Symbol void nil].freeze\n    # Unicode-aware identifier pattern for method/variable names (supports Korean, etc.)\n    IDENTIFIER_PATTERN = /[\\w\\p{L}\\p{N}]+[!?]?/\n\n    def initialize(source)\n      @source = source\n      @lines = source.split("\\n")\n      @errors = []\n      @functions = {}\n      @type_parser = ParserCombinator::TypeParser.new\n    end\n\n    def check\n      @errors = []\n      @functions = {}\n      @type_aliases = {}\n      @interfaces = {}\n\n      check_type_alias_errors\n      check_interface_errors\n      check_syntax_errors\n      check_method_signature_errors\n      check_type_validation\n      check_duplicate_definitions\n\n      @errors\n    end\n\n    private\n\n    def check_interface_errors\n      @lines.each_with_index do |line, idx|\n        next unless line.match?(/^\\s*interface\\s+[\\w:]+/)\n\n        match = line.match(/^\\s*interface\\s+([\\w:]+)/)\n        next unless match\n\n        interface_name = match[1]\n\n        if @interfaces[interface_name]\n          @errors << "Line #{idx + 1}: Interface \'#{interface_name}\' is already defined at line #{@interfaces[interface_name]}"\n        else\n          @interfaces[interface_name] = idx + 1\n        end\n      end\n    end\n\n    def check_type_alias_errors\n      @lines.each_with_index do |line, idx|\n        next unless line.match?(/^\\s*type\\s+\\w+/)\n\n        match = line.match(/^\\s*type\\s+(\\w+)\\s*=\\s*(.+)$/)\n        next unless match\n\n        alias_name = match[1]\n\n        if @type_aliases[alias_name]\n          @errors << "Line #{idx + 1}: Type alias \'#{alias_name}\' is already defined at line #{@type_aliases[alias_name]}"\n        else\n          @type_aliases[alias_name] = idx + 1\n        end\n      end\n    end\n\n    def check_syntax_errors\n      @lines.each_with_index do |line, idx|\n        next unless line.match?(/^\\s*def\\s+/)\n\n        # Check for unclosed parenthesis\n        if line.match?(/def\\s+\\w+\\([^)]*$/) && @lines[(idx + 1)..].none? { |l| l.match?(/\\)/) }\n          @errors << "Line #{idx + 1}: Potential unclosed parenthesis in function definition"\n        end\n\n        # Check for invalid parameter syntax (e.g., "def test(: String)")\n        if line.match?(/def\\s+\\w+\\(\\s*:\\s*\\w+/)\n          @errors << "Line #{idx + 1}: Invalid parameter syntax - parameter name missing"\n        end\n      end\n    end\n\n    # New comprehensive method signature validation\n    def check_method_signature_errors\n      @lines.each_with_index do |line, idx|\n        next unless line.match?(/^\\s*def\\s+/)\n\n        check_single_method_signature(line, idx)\n      end\n    end\n\n    def check_single_method_signature(line, idx)\n      # Pattern 1: Check for colon without type (e.g., "def test():")\n      if line.match?(/def\\s+\\w+[^:]*\\)\\s*:\\s*$/)\n        @errors << "Line #{idx + 1}: Expected type after colon, but found end of line"\n        return\n      end\n\n      # Pattern 2: Check for text after closing paren without colon (e.g., "def test() something")\n      # Use balanced paren matching to find the correct closing paren\n      params_end = find_params_closing_paren(line)\n      if params_end\n        after_params = line[params_end..].strip\n        # Check if there\'s trailing content that\'s not a return type annotation\n        if (match = after_params.match(/^\\)\\s*([^:\\s].+?)\\s*$/))\n          trailing = match[1].strip\n          # Allow if it\'s just end-of-line content or a valid Ruby block start\n          unless trailing.empty? || trailing.start_with?("#") || trailing == "end"\n            @errors << "Line #{idx + 1}: Unexpected token \'#{trailing}\' after method parameters - did you forget \':\'?"\n          end\n          return\n        end\n      end\n\n      # Pattern 3: Check for parameter with colon but no type (e.g., "def test(x:)")\n      # Skip this check for keyword args group { name:, age: } - they\'re valid\n      params_str = extract_params_string(line)\n      # Check each parameter for colon without type\n      # Match: "x:" at end, "x:," in middle, or "x: )" with space before closing\n      if params_str && !params_str.include?("{") &&\n         (params_str.match?(/\\w+:\\s*$/) || params_str.match?(/\\w+:\\s*,/))\n        @errors << "Line #{idx + 1}: Expected type after parameter colon"\n        return\n      end\n\n      # Pattern 4: Extract and validate return type\n      if params_end\n        after_params = line[params_end..]\n        if (match = after_params.match(/\\)\\s*:\\s*(.+?)\\s*$/))\n          return_type_str = match[1].strip\n          validate_type_expression(return_type_str, idx, "return type")\n        end\n      end\n\n      # Pattern 5: Extract and validate parameter types\n      if params_str\n        validate_parameter_types_expression(params_str, idx)\n      end\n    end\n\n    # Find the position of the closing paren for method parameters (balanced matching)\n    def find_params_closing_paren(line)\n      start_pos = line.index("(")\n      return nil unless start_pos\n\n      depth = 0\n      line[start_pos..].each_char.with_index do |char, i|\n        case char\n        when "("\n          depth += 1\n        when ")"\n          depth -= 1\n          return start_pos + i if depth.zero?\n        end\n      end\n      nil\n    end\n\n    # Extract the parameters string from a method definition line\n    def extract_params_string(line)\n      start_pos = line.index("(")\n      return nil unless start_pos\n\n      end_pos = find_params_closing_paren(line)\n      return nil unless end_pos\n\n      line[(start_pos + 1)...end_pos]\n    end\n\n    def validate_type_expression(type_str, line_idx, context = "type")\n      return if type_str.nil? || type_str.empty?\n\n      # Check for whitespace in simple type names (e.g., "Str ing")\n      if type_str.match?(/^[A-Z][a-z]*\\s+[a-z]+/)\n        @errors << "Line #{line_idx + 1}: Invalid #{context} \'#{type_str}\' - unexpected whitespace in type name"\n        return\n      end\n\n      # Check for trailing operators (e.g., "String |" or "String &")\n      if type_str.match?(/[|&]\\s*$/)\n        @errors << "Line #{line_idx + 1}: Invalid #{context} \'#{type_str}\' - trailing operator"\n        return\n      end\n\n      # Check for leading operators\n      if type_str.match?(/^\\s*[|&]/)\n        @errors << "Line #{line_idx + 1}: Invalid #{context} \'#{type_str}\' - leading operator"\n        return\n      end\n\n      # Check for double operators (e.g., "String | | Integer")\n      if type_str.match?(/[|&]\\s*[|&]/)\n        @errors << "Line #{line_idx + 1}: Invalid #{context} \'#{type_str}\' - consecutive operators"\n        return\n      end\n\n      # Check for unclosed brackets\n      # Note: we need to exclude -> arrow operators when counting < and >\n      angle_balance = count_angle_brackets(type_str)\n      if angle_balance != 0\n        @errors << "Line #{line_idx + 1}: Invalid #{context} \'#{type_str}\' - unbalanced angle brackets"\n        return\n      end\n\n      if type_str.count("[") != type_str.count("]")\n        @errors << "Line #{line_idx + 1}: Invalid #{context} \'#{type_str}\' - unbalanced square brackets"\n        return\n      end\n\n      if type_str.count("(") != type_str.count(")")\n        @errors << "Line #{line_idx + 1}: Invalid #{context} \'#{type_str}\' - unbalanced parentheses"\n        return\n      end\n\n      # Check for empty generic arguments (e.g., "Array<>")\n      if type_str.match?(/<\\s*>/)\n        @errors << "Line #{line_idx + 1}: Invalid #{context} \'#{type_str}\' - empty generic arguments"\n        return\n      end\n\n      # Check for generic without base type (e.g., "<String>")\n      if type_str.match?(/^\\s*</)\n        @errors << "Line #{line_idx + 1}: Invalid #{context} \'#{type_str}\' - missing base type for generic"\n        return\n      end\n\n      # Check for missing arrow target in function type\n      if type_str.match?(/->\\s*$/)\n        @errors << "Line #{line_idx + 1}: Invalid #{context} \'#{type_str}\' - missing return type after ->"\n        return\n      end\n\n      # Check for extra tokens after valid type (e.g., "String something_else")\n      # Use TypeParser to validate\n      result = @type_parser.parse(type_str)\n      return unless result[:success]\n\n      remaining = result[:remaining]&.strip\n      return if remaining.nil? || remaining.empty?\n\n      # Allow RBS-style square bracket generics (e.g., Hash[Symbol, String])\n      # Allow nullable suffix (e.g., String?)\n      # Allow array suffix (e.g., [])\n      return if remaining.start_with?("[") || remaining.start_with?("?") || remaining == "[]"\n\n      @errors << "Line #{line_idx + 1}: Unexpected token after #{context} \'#{type_str}\'"\n    end\n\n    def validate_parameter_types_expression(params_str, line_idx)\n      return if params_str.nil? || params_str.empty?\n\n      # Split parameters handling nested generics\n      params = split_parameters(params_str)\n\n      params.each do |param|\n        param = param.strip\n        next if param.empty?\n\n        # Skip keyword args group: { name: Type, age: Type }\n        next if param.start_with?("{")\n\n        # Skip block parameter: &block or &block: Type\n        next if param.start_with?("&")\n\n        # Skip rest parameter: *args or *args: Type\n        next if param.start_with?("*")\n\n        # Check for param: Type pattern (with optional default value)\n        # Match: name: Type or name: Type = default\n        next unless (match = param.match(/^(\\w+)\\s*:\\s*(.+)$/))\n\n        param_name = match[1]\n        type_and_default = match[2].strip\n\n        if type_and_default.empty?\n          @errors << "Line #{line_idx + 1}: Expected type after colon for parameter \'#{param_name}\'"\n          next\n        end\n\n        # Extract just the type part (before any \'=\' for default value)\n        type_str = extract_type_from_param(type_and_default)\n        next if type_str.nil? || type_str.empty?\n\n        validate_type_expression(type_str, line_idx, "parameter type for \'#{param_name}\'")\n      end\n    end\n\n    # Extract type from "Type = default_value" or just "Type"\n    def extract_type_from_param(type_and_default)\n      # Find the position of \'=\' that\'s not inside parentheses/brackets\n      depth = 0\n      type_and_default.each_char.with_index do |char, i|\n        case char\n        when "(", "<", "["\n          depth += 1\n        when ")", ">", "]"\n          depth -= 1\n        when "="\n          # Make sure it\'s not part of -> operator\n          prev_char = i.positive? ? type_and_default[i - 1] : nil\n          next if %w[- ! = < >].include?(prev_char)\n\n          return type_and_default[0...i].strip if depth.zero?\n        end\n      end\n      type_and_default\n    end\n\n    def split_parameters(params_str)\n      result = []\n      current = ""\n      paren_depth = 0\n      bracket_depth = 0\n      angle_depth = 0\n      brace_depth = 0\n\n      i = 0\n      while i < params_str.length\n        char = params_str[i]\n        next_char = params_str[i + 1]\n        prev_char = i.positive? ? params_str[i - 1] : nil\n\n        case char\n        when "("\n          paren_depth += 1\n          current += char\n        when ")"\n          paren_depth -= 1\n          current += char\n        when "["\n          bracket_depth += 1\n          current += char\n        when "]"\n          bracket_depth -= 1\n          current += char\n        when "<"\n          # Only count as generic if it\'s not part of operator like <=, <=>\n          if next_char != "=" && next_char != ">"\n            angle_depth += 1\n          end\n          current += char\n        when ">"\n          # Only count as closing generic if we\'re inside a generic (angle_depth > 0)\n          # and it\'s not part of -> operator\n          if angle_depth.positive? && prev_char != "-"\n            angle_depth -= 1\n          end\n          current += char\n        when "{"\n          brace_depth += 1\n          current += char\n        when "}"\n          brace_depth -= 1\n          current += char\n        when ","\n          if paren_depth.zero? && bracket_depth.zero? && angle_depth.zero? && brace_depth.zero?\n            result << current.strip\n            current = ""\n          else\n            current += char\n          end\n        else\n          current += char\n        end\n        i += 1\n      end\n\n      result << current.strip unless current.empty?\n      result\n    end\n\n    def check_type_validation\n      @lines.each_with_index do |line, idx|\n        next unless line.match?(/^\\s*def\\s+/)\n\n        # Extract types from function definition - now handle complex types\n        match = line.match(/def\\s+\\w+\\s*\\((.*?)\\)\\s*(?::\\s*(.+?))?$/)\n        next unless match\n\n        params_str = match[1]\n        return_type = match[2]&.strip\n\n        # Check return type if it\'s a simple type name\n        if return_type&.match?(/^\\w+$/) && !(VALID_TYPES.include?(return_type) || @type_aliases.key?(return_type) || @interfaces.key?(return_type))\n          @errors << "Line #{idx + 1}: Unknown return type \'#{return_type}\'"\n        end\n\n        # Check parameter types\n        check_parameter_types(params_str, idx)\n      end\n    end\n\n    def check_parameter_types(params_str, line_idx)\n      return if params_str.nil? || params_str.empty?\n\n      params = split_parameters(params_str)\n      params.each do |param|\n        param = param.strip\n        match = param.match(/^(\\w+)(?::\\s*(.+))?$/)\n        next unless match\n\n        param_type = match[2]&.strip\n        next unless param_type\n\n        # Only check simple type names against VALID_TYPES\n        next unless param_type.match?(/^\\w+$/)\n        next if VALID_TYPES.include?(param_type) || @type_aliases.key?(param_type) || @interfaces.key?(param_type)\n\n        @errors << "Line #{line_idx + 1}: Unknown parameter type \'#{param_type}\'"\n      end\n    end\n\n    def check_duplicate_definitions\n      current_class = nil\n      class_methods = {} # { class_name => { method_name => line_number } }\n\n      @lines.each_with_index do |line, idx|\n        # Track class context\n        if line.match?(/^\\s*class\\s+(\\w+)/)\n          current_class = line.match(/class\\s+(\\w+)/)[1]\n          class_methods[current_class] ||= {}\n        elsif line.match?(/^\\s*end\\s*$/) && current_class\n          # Simple heuristic: top-level \'end\' closes current class\n          # This is imperfect but handles most cases\n          current_class = nil if line.match?(/^end\\s*$/)\n        end\n\n        # Use unicode-aware pattern for function names (supports Korean, etc.)\n        next unless line.match?(/^\\s*def\\s+#{IDENTIFIER_PATTERN}/)\n\n        func_name = line.match(/def\\s+(#{IDENTIFIER_PATTERN})/)[1]\n\n        if current_class\n          # Method inside a class - check within class scope\n          methods = class_methods[current_class]\n          if methods[func_name]\n            @errors << "Line #{idx + 1}: Function \'#{func_name}\' is already defined at line #{methods[func_name]}"\n          else\n            methods[func_name] = idx + 1\n          end\n        elsif @functions[func_name]\n          # Top-level function - check global scope\n          @errors << "Line #{idx + 1}: Function \'#{func_name}\' is already defined at line #{@functions[func_name]}"\n        else\n          @functions[func_name] = idx + 1\n        end\n      end\n    end\n\n    # Count angle brackets excluding those in -> arrow operators\n    # Returns the balance (positive if more <, negative if more >)\n    def count_angle_brackets(type_str)\n      balance = 0\n      i = 0\n      while i < type_str.length\n        char = type_str[i]\n        prev_char = i.positive? ? type_str[i - 1] : nil\n        next_char = type_str[i + 1]\n\n        case char\n        when "<"\n          # Skip if it\'s part of <= or <>\n          balance += 1 unless %w[= >].include?(next_char)\n        when ">"\n          # Skip if it\'s part of -> arrow operator\n          balance -= 1 unless prev_char == "-"\n        end\n        i += 1\n      end\n      balance\n    end\n  end\nend\n',"lib/t_ruby/error_reporter.rb":"# frozen_string_literal: true\n\nmodule TRuby\n  class ErrorReporter\n    attr_reader :diagnostics\n\n    def initialize(formatter: nil)\n      @diagnostics = []\n      @formatter = formatter || DiagnosticFormatter.new\n      @source_cache = {}\n    end\n\n    def add(diagnostic)\n      @diagnostics << diagnostic\n    end\n\n    def add_type_check_error(error, file:, source: nil)\n      source ||= load_source(file)\n      add(Diagnostic.from_type_check_error(error, file: file, source: source))\n    end\n\n    def add_parse_error(error, file:, source: nil)\n      source ||= load_source(file)\n      add(Diagnostic.from_parse_error(error, file: file, source: source))\n    end\n\n    def add_scan_error(error, file:, source: nil)\n      source ||= load_source(file)\n      add(Diagnostic.from_scan_error(error, file: file, source: source))\n    end\n\n    def has_errors?\n      @diagnostics.any? { |d| d.severity == Diagnostic::SEVERITY_ERROR }\n    end\n\n    def error_count\n      @diagnostics.count { |d| d.severity == Diagnostic::SEVERITY_ERROR }\n    end\n\n    def report\n      @formatter.format_all(@diagnostics)\n    end\n\n    def clear\n      @diagnostics.clear\n      @source_cache.clear\n    end\n\n    private\n\n    def load_source(file)\n      return nil unless file && File.exist?(file)\n\n      @source_cache[file] ||= File.read(file)\n    end\n  end\nend\n","lib/t_ruby/generic_type_parser.rb":'# frozen_string_literal: true\n\nmodule TRuby\n  class GenericTypeParser\n    def initialize(type_string)\n      @type_string = type_string.strip\n    end\n\n    def parse\n      if @type_string.include?("<") && @type_string.include?(">")\n        parse_generic\n      else\n        { type: :simple, value: @type_string }\n      end\n    end\n\n    private\n\n    def parse_generic\n      # Match: BaseName<Params>\n      match = @type_string.match(/^(\\w+)<(.+)>$/)\n      return { type: :simple, value: @type_string } unless match\n\n      base_name = match[1]\n      params_str = match[2]\n\n      # Parse parameters, handling nested generics\n      params = parse_params(params_str)\n\n      {\n        type: :generic,\n        base: base_name,\n        params: params,\n      }\n    end\n\n    def parse_params(params_str)\n      # Simple comma-based splitting (doesn\'t handle nested generics fully)\n      # For nested generics like Array<Array<String>>, we need careful parsing\n      params = []\n      current = ""\n      depth = 0\n\n      params_str.each_char do |char|\n        case char\n        when "<"\n          depth += 1\n          current += char\n        when ">"\n          depth -= 1\n          current += char\n        when ","\n          if depth.zero?\n            params << current.strip\n            current = ""\n          else\n            current += char\n          end\n        else\n          current += char\n        end\n      end\n\n      params << current.strip if current.length.positive?\n      params\n    end\n  end\nend\n',"lib/t_ruby/heredoc_detector.rb":'# frozen_string_literal: true\n\nmodule TRuby\n  # Detects regions that should be skipped during parsing:\n  # - Heredoc content\n  # - Block comments (=begin/=end)\n  class HeredocDetector\n    # Heredoc start patterns:\n    # <<IDENTIFIER, <<-IDENTIFIER, <<~IDENTIFIER\n    # <<\'IDENTIFIER\', <<"IDENTIFIER"\n    HEREDOC_START_PATTERN = /<<([~-])?([\'"]?)(\\w+)\\2/\n\n    # Detect all skippable ranges in lines (heredocs and block comments)\n    # @param lines [Array<String>] source lines\n    # @return [Array<Range>] content ranges to skip (0-indexed)\n    def self.detect(lines)\n      ranges = []\n      i = 0\n\n      while i < lines.length\n        line = lines[i]\n\n        # Check for =begin block comment\n        if line.strip == "=begin"\n          start_line = i\n          i += 1\n\n          # Find =end\n          while i < lines.length\n            break if lines[i].strip == "=end"\n\n            i += 1\n          end\n\n          # Range covers from =begin to =end (inclusive)\n          ranges << (start_line..i) if i < lines.length\n        # Check for heredoc\n        elsif (match = line.match(HEREDOC_START_PATTERN))\n          delimiter = match[3]\n          squiggly = match[1] == "~"\n          start_line = i\n          i += 1\n\n          # Find closing delimiter\n          while i < lines.length\n            # For squiggly heredoc or dash heredoc, delimiter can be indented\n            # For regular heredoc, delimiter must be at line start\n            if squiggly || match[1] == "-"\n              break if lines[i].strip == delimiter\n            elsif lines[i].chomp == delimiter\n              break\n            end\n            i += 1\n          end\n\n          # Range covers content lines (after start, up to and including end delimiter)\n          ranges << ((start_line + 1)..i) if i < lines.length\n        end\n\n        i += 1\n      end\n\n      ranges\n    end\n\n    # Check if a line index is inside any skippable region\n    # @param line_index [Integer] line index to check\n    # @param heredoc_ranges [Array<Range>] ranges from detect()\n    # @return [Boolean]\n    def self.inside_heredoc?(line_index, heredoc_ranges)\n      heredoc_ranges.any? { |range| range.include?(line_index) }\n    end\n  end\nend\n',"lib/t_ruby/intersection_type_parser.rb":'# frozen_string_literal: true\n\nmodule TRuby\n  class IntersectionTypeParser\n    def initialize(type_string)\n      @type_string = type_string.strip\n    end\n\n    def parse\n      if @type_string.include?("&")\n        parse_intersection\n      else\n        { type: :simple, value: @type_string }\n      end\n    end\n\n    private\n\n    def parse_intersection\n      members = @type_string.split("&").map(&:strip).compact\n\n      {\n        type: :intersection,\n        members: members,\n        has_duplicates: members.length != members.uniq.length,\n        unique_members: members.uniq,\n      }\n    end\n  end\nend\n',"lib/t_ruby/ir.rb":'# frozen_string_literal: true\n\nmodule TRuby\n  module IR\n    # Base class for all IR nodes\n    class Node\n      attr_accessor :location, :type_info, :metadata\n\n      def initialize(location: nil)\n        @location = location\n        @type_info = nil\n        @metadata = {}\n      end\n\n      def accept(visitor)\n        visitor.visit(self)\n      end\n\n      def children\n        []\n      end\n\n      def transform(&block)\n        block.call(self)\n      end\n    end\n\n    # Program - root node containing all top-level declarations\n    class Program < Node\n      attr_accessor :declarations, :source_file\n\n      def initialize(declarations: [], source_file: nil, **opts)\n        super(**opts)\n        @declarations = declarations\n        @source_file = source_file\n      end\n\n      def children\n        @declarations\n      end\n    end\n\n    # Type alias declaration: type Name = Definition\n    class TypeAlias < Node\n      attr_accessor :name, :definition, :type_params\n\n      def initialize(name:, definition:, type_params: [], **opts)\n        super(**opts)\n        @name = name\n        @definition = definition\n        @type_params = type_params\n      end\n    end\n\n    # Interface declaration\n    class Interface < Node\n      attr_accessor :name, :members, :extends, :type_params\n\n      def initialize(name:, members: [], extends: [], type_params: [], **opts)\n        super(**opts)\n        @name = name\n        @members = members\n        @extends = extends\n        @type_params = type_params\n      end\n\n      def children\n        @members\n      end\n    end\n\n    # Interface member (method signature)\n    class InterfaceMember < Node\n      attr_accessor :name, :type_signature, :optional\n\n      def initialize(name:, type_signature:, optional: false, **opts)\n        super(**opts)\n        @name = name\n        @type_signature = type_signature\n        @optional = optional\n      end\n    end\n\n    # Class declaration\n    class ClassDecl < Node\n      attr_accessor :name, :superclass, :implements, :type_params, :body, :instance_vars\n\n      def initialize(name:, superclass: nil, implements: [], type_params: [], body: [], instance_vars: [], **opts)\n        super(**opts)\n        @name = name\n        @superclass = superclass\n        @implements = implements\n        @type_params = type_params\n        @body = body\n        @instance_vars = instance_vars\n      end\n\n      def children\n        @body\n      end\n    end\n\n    # Instance variable declaration\n    class InstanceVariable < Node\n      attr_accessor :name, :type_annotation\n\n      def initialize(name:, type_annotation: nil, **opts)\n        super(**opts)\n        @name = name\n        @type_annotation = type_annotation\n      end\n    end\n\n    # Module declaration\n    class ModuleDecl < Node\n      attr_accessor :name, :body\n\n      def initialize(name:, body: [], **opts)\n        super(**opts)\n        @name = name\n        @body = body\n      end\n\n      def children\n        @body\n      end\n    end\n\n    # Method definition\n    class MethodDef < Node\n      attr_accessor :name, :params, :return_type, :body, :visibility, :type_params\n\n      def initialize(name:, params: [], return_type: nil, body: nil, visibility: :public, type_params: [], **opts)\n        super(**opts)\n        @name = name\n        @params = params\n        @return_type = return_type\n        @body = body\n        @visibility = visibility\n        @type_params = type_params\n      end\n\n      def children\n        [@body].compact\n      end\n    end\n\n    # Method parameter\n    class Parameter < Node\n      attr_accessor :name, :type_annotation, :default_value, :kind, :interface_ref\n\n      # kind: :required, :optional, :rest, :keyrest, :block, :keyword\n      # :keyword - \ud0a4\uc6cc\ub4dc \uc778\uc790 (\uad6c\uc870\ubd84\ud574): { name: String } \u2192 def foo(name:)\n      # :keyrest - \ub354\ube14 \uc2a4\ud50c\ub7ab: **opts: Type \u2192 def foo(**opts)\n      # interface_ref - interface \ucc38\uc870 \ud0c0\uc785 (\uc608: }: UserParams \ubd80\ubd84)\n      def initialize(name:, type_annotation: nil, default_value: nil, kind: :required, interface_ref: nil, **opts)\n        super(**opts)\n        @name = name\n        @type_annotation = type_annotation\n        @default_value = default_value\n        @kind = kind\n        @interface_ref = interface_ref\n      end\n    end\n\n    # Block of statements\n    class Block < Node\n      attr_accessor :statements\n\n      def initialize(statements: [], **opts)\n        super(**opts)\n        @statements = statements\n      end\n\n      def children\n        @statements\n      end\n    end\n\n    # Variable assignment\n    class Assignment < Node\n      attr_accessor :target, :value, :type_annotation\n\n      def initialize(target:, value:, type_annotation: nil, **opts)\n        super(**opts)\n        @target = target\n        @value = value\n        @type_annotation = type_annotation\n      end\n\n      def children\n        [@value]\n      end\n    end\n\n    # Variable reference\n    class VariableRef < Node\n      attr_accessor :name, :scope\n\n      # scope: :local, :instance, :class, :global\n      def initialize(name:, scope: :local, **opts)\n        super(**opts)\n        @name = name\n        @scope = scope\n      end\n    end\n\n    # Method call\n    class MethodCall < Node\n      attr_accessor :receiver, :method_name, :arguments, :block, :type_args\n\n      def initialize(method_name:, receiver: nil, arguments: [], block: nil, type_args: [], **opts)\n        super(**opts)\n        @receiver = receiver\n        @method_name = method_name\n        @arguments = arguments\n        @block = block\n        @type_args = type_args\n      end\n\n      def children\n        ([@receiver, @block] + @arguments).compact\n      end\n    end\n\n    # Literal values\n    class Literal < Node\n      attr_accessor :value, :literal_type\n\n      def initialize(value:, literal_type:, **opts)\n        super(**opts)\n        @value = value\n        @literal_type = literal_type\n      end\n    end\n\n    # Interpolated string (string with #{...} expressions)\n    class InterpolatedString < Node\n      attr_accessor :parts\n\n      def initialize(parts: [], **opts)\n        super(**opts)\n        @parts = parts\n      end\n\n      def children\n        @parts\n      end\n    end\n\n    # Array literal\n    class ArrayLiteral < Node\n      attr_accessor :elements, :element_type\n\n      def initialize(elements: [], element_type: nil, **opts)\n        super(**opts)\n        @elements = elements\n        @element_type = element_type\n      end\n\n      def children\n        @elements\n      end\n    end\n\n    # Hash literal\n    class HashLiteral < Node\n      attr_accessor :pairs, :key_type, :value_type\n\n      def initialize(pairs: [], key_type: nil, value_type: nil, **opts)\n        super(**opts)\n        @pairs = pairs\n        @key_type = key_type\n        @value_type = value_type\n      end\n    end\n\n    # Hash pair (key => value)\n    class HashPair < Node\n      attr_accessor :key, :value\n\n      def initialize(key:, value:, **opts)\n        super(**opts)\n        @key = key\n        @value = value\n      end\n\n      def children\n        [@key, @value]\n      end\n    end\n\n    # Conditional (if/unless)\n    class Conditional < Node\n      attr_accessor :condition, :then_branch, :else_branch, :kind\n\n      # kind: :if, :unless, :ternary\n      def initialize(condition:, then_branch:, else_branch: nil, kind: :if, **opts)\n        super(**opts)\n        @condition = condition\n        @then_branch = then_branch\n        @else_branch = else_branch\n        @kind = kind\n      end\n\n      def children\n        [@condition, @then_branch, @else_branch].compact\n      end\n    end\n\n    # Case/when expression\n    class CaseExpr < Node\n      attr_accessor :subject, :when_clauses, :else_clause\n\n      def initialize(subject: nil, when_clauses: [], else_clause: nil, **opts)\n        super(**opts)\n        @subject = subject\n        @when_clauses = when_clauses\n        @else_clause = else_clause\n      end\n\n      def children\n        ([@subject, @else_clause] + @when_clauses).compact\n      end\n    end\n\n    # When clause\n    class WhenClause < Node\n      attr_accessor :patterns, :body\n\n      def initialize(patterns:, body:, **opts)\n        super(**opts)\n        @patterns = patterns\n        @body = body\n      end\n\n      def children\n        [@body] + @patterns\n      end\n    end\n\n    # Loop constructs\n    class Loop < Node\n      attr_accessor :kind, :condition, :body\n\n      # kind: :while, :until, :loop\n      def initialize(kind:, body:, condition: nil, **opts)\n        super(**opts)\n        @kind = kind\n        @condition = condition\n        @body = body\n      end\n\n      def children\n        [@condition, @body].compact\n      end\n    end\n\n    # For loop / each iteration\n    class ForLoop < Node\n      attr_accessor :variable, :iterable, :body\n\n      def initialize(variable:, iterable:, body:, **opts)\n        super(**opts)\n        @variable = variable\n        @iterable = iterable\n        @body = body\n      end\n\n      def children\n        [@iterable, @body]\n      end\n    end\n\n    # Return statement\n    class Return < Node\n      attr_accessor :value\n\n      def initialize(value: nil, **opts)\n        super(**opts)\n        @value = value\n      end\n\n      def children\n        [@value].compact\n      end\n    end\n\n    # Binary operation\n    class BinaryOp < Node\n      attr_accessor :operator, :left, :right\n\n      def initialize(operator:, left:, right:, **opts)\n        super(**opts)\n        @operator = operator\n        @left = left\n        @right = right\n      end\n\n      def children\n        [@left, @right]\n      end\n    end\n\n    # Unary operation\n    class UnaryOp < Node\n      attr_accessor :operator, :operand\n\n      def initialize(operator:, operand:, **opts)\n        super(**opts)\n        @operator = operator\n        @operand = operand\n      end\n\n      def children\n        [@operand]\n      end\n    end\n\n    # Type cast / assertion\n    class TypeCast < Node\n      attr_accessor :expression, :target_type, :kind\n\n      # kind: :as, :assert\n      def initialize(expression:, target_type:, kind: :as, **opts)\n        super(**opts)\n        @expression = expression\n        @target_type = target_type\n        @kind = kind\n      end\n\n      def children\n        [@expression]\n      end\n    end\n\n    # Type guard (is_a?, respond_to?)\n    class TypeGuard < Node\n      attr_accessor :expression, :type_check, :narrowed_type\n\n      def initialize(expression:, type_check:, narrowed_type: nil, **opts)\n        super(**opts)\n        @expression = expression\n        @type_check = type_check\n        @narrowed_type = narrowed_type\n      end\n\n      def children\n        [@expression]\n      end\n    end\n\n    # Lambda/Proc definition\n    class Lambda < Node\n      attr_accessor :params, :body, :return_type\n\n      def initialize(body:, params: [], return_type: nil, **opts)\n        super(**opts)\n        @params = params\n        @body = body\n        @return_type = return_type\n      end\n\n      def children\n        [@body]\n      end\n    end\n\n    # Begin/rescue/ensure block\n    class BeginBlock < Node\n      attr_accessor :body, :rescue_clauses, :else_clause, :ensure_clause\n\n      def initialize(body:, rescue_clauses: [], else_clause: nil, ensure_clause: nil, **opts)\n        super(**opts)\n        @body = body\n        @rescue_clauses = rescue_clauses\n        @else_clause = else_clause\n        @ensure_clause = ensure_clause\n      end\n\n      def children\n        [@body, @else_clause, @ensure_clause].compact + @rescue_clauses\n      end\n    end\n\n    # Rescue clause\n    class RescueClause < Node\n      attr_accessor :exception_types, :variable, :body\n\n      def initialize(body:, exception_types: [], variable: nil, **opts)\n        super(**opts)\n        @exception_types = exception_types\n        @variable = variable\n        @body = body\n      end\n\n      def children\n        [@body]\n      end\n    end\n\n    # Raw Ruby code (for passthrough)\n    class RawCode < Node\n      attr_accessor :code\n\n      def initialize(code:, **opts)\n        super(**opts)\n        @code = code\n      end\n    end\n\n    #==========================================================================\n    # Type Representation Nodes\n    #==========================================================================\n\n    # Base type node\n    class TypeNode < Node\n      def to_rbs\n        raise NotImplementedError\n      end\n\n      def to_trb\n        raise NotImplementedError\n      end\n    end\n\n    # Simple type (String, Integer, etc.)\n    class SimpleType < TypeNode\n      attr_accessor :name\n\n      def initialize(name:, **opts)\n        super(**opts)\n        @name = name\n      end\n\n      def to_rbs\n        @name\n      end\n\n      def to_trb\n        @name\n      end\n    end\n\n    # Generic type (Array<String>, Map<K, V>)\n    class GenericType < TypeNode\n      attr_accessor :base, :type_args\n\n      def initialize(base:, type_args: [], **opts)\n        super(**opts)\n        @base = base\n        @type_args = type_args\n      end\n\n      def to_rbs\n        "#{@base}[#{@type_args.map(&:to_rbs).join(", ")}]"\n      end\n\n      def to_trb\n        "#{@base}<#{@type_args.map(&:to_trb).join(", ")}>"\n      end\n    end\n\n    # Union type (String | Integer | nil)\n    class UnionType < TypeNode\n      attr_accessor :types\n\n      def initialize(types: [], **opts)\n        super(**opts)\n        @types = types\n      end\n\n      def to_rbs\n        @types.map(&:to_rbs).join(" | ")\n      end\n\n      def to_trb\n        @types.map(&:to_trb).join(" | ")\n      end\n    end\n\n    # Intersection type (Readable & Writable)\n    class IntersectionType < TypeNode\n      attr_accessor :types\n\n      def initialize(types: [], **opts)\n        super(**opts)\n        @types = types\n      end\n\n      def to_rbs\n        @types.map(&:to_rbs).join(" & ")\n      end\n\n      def to_trb\n        @types.map(&:to_trb).join(" & ")\n      end\n    end\n\n    # Function/Proc type ((String, Integer) -> Boolean)\n    class FunctionType < TypeNode\n      attr_accessor :param_types, :return_type\n\n      def initialize(return_type:, param_types: [], **opts)\n        super(**opts)\n        @param_types = param_types\n        @return_type = return_type\n      end\n\n      def to_rbs\n        params = @param_types.map(&:to_rbs).join(", ")\n        "^(#{params}) -> #{@return_type.to_rbs}"\n      end\n\n      def to_trb\n        params = @param_types.map(&:to_trb).join(", ")\n        "(#{params}) -> #{@return_type.to_trb}"\n      end\n    end\n\n    # Tuple type ([String, Integer, Boolean])\n    class TupleType < TypeNode\n      attr_accessor :element_types\n\n      def initialize(element_types: [], **opts)\n        super(**opts)\n        @element_types = element_types\n      end\n\n      def to_rbs\n        "[#{@element_types.map(&:to_rbs).join(", ")}]"\n      end\n\n      def to_trb\n        "[#{@element_types.map(&:to_trb).join(", ")}]"\n      end\n    end\n\n    # Nullable type (String?)\n    class NullableType < TypeNode\n      attr_accessor :inner_type\n\n      def initialize(inner_type:, **opts)\n        super(**opts)\n        @inner_type = inner_type\n      end\n\n      def to_rbs\n        inner_rbs = @inner_type.to_rbs\n        # Simple types can use ? suffix, complex types need (Type | nil) form\n        if @inner_type.is_a?(SimpleType)\n          "#{inner_rbs}?"\n        else\n          "(#{inner_rbs} | nil)"\n        end\n      end\n\n      def to_trb\n        "#{@inner_type.to_trb}?"\n      end\n    end\n\n    # Literal type (literal value as type)\n    class LiteralType < TypeNode\n      attr_accessor :value\n\n      def initialize(value:, **opts)\n        super(**opts)\n        @value = value\n      end\n\n      def to_rbs\n        @value.inspect\n      end\n\n      def to_trb\n        @value.inspect\n      end\n    end\n\n    # Hash literal type: { key: Type, key2: Type }\n    class HashLiteralType < TypeNode\n      attr_accessor :fields # Array of { name: String, type: TypeNode }\n\n      def initialize(fields:, **opts)\n        super(**opts)\n        @fields = fields\n      end\n\n      def to_rbs\n        # Hash literal types in RBS are represented as Hash[Symbol, untyped] or specific record types\n        "Hash[Symbol, untyped]"\n      end\n\n      def to_trb\n        field_strs = @fields.map { |f| "#{f[:name]}: #{f[:type].to_trb}" }\n        "{ #{field_strs.join(", ")} }"\n      end\n    end\n\n    #==========================================================================\n    # Visitor Pattern\n    #==========================================================================\n\n    class Visitor\n      def visit(node)\n        method_name = "visit_#{node.class.name.split("::").last.gsub(/([A-Z])/, \'_\\1\').downcase.sub(/^_/, "")}"\n        if respond_to?(method_name)\n          send(method_name, node)\n        else\n          visit_default(node)\n        end\n      end\n\n      def visit_default(node)\n        node.children.each { |child| visit(child) }\n      end\n\n      def visit_children(node)\n        node.children.each { |child| visit(child) }\n      end\n    end\n\n    #==========================================================================\n    # IR Builder - Converts parsed AST to IR\n    #==========================================================================\n\n    class Builder\n      def initialize\n        @type_registry = {}\n      end\n\n      # Build IR from parser output\n      def build(parse_result, source: nil)\n        # Build type aliases\n        declarations = (parse_result[:type_aliases] || []).map do |alias_info|\n          build_type_alias(alias_info)\n        end\n\n        # Build interfaces\n        (parse_result[:interfaces] || []).each do |interface_info|\n          declarations << build_interface(interface_info)\n        end\n\n        # Build classes\n        (parse_result[:classes] || []).each do |class_info|\n          declarations << build_class(class_info)\n        end\n\n        # Build functions/methods\n        (parse_result[:functions] || []).each do |func_info|\n          declarations << build_method(func_info)\n        end\n\n        Program.new(declarations: declarations, source_file: source)\n      end\n\n      # Build from source code\n      def build_from_source(source)\n        parser = Parser.new(source)\n        result = parser.parse\n        build(result, source: source)\n      end\n\n      private\n\n      def build_type_alias(info)\n        TypeAlias.new(\n          name: info[:name],\n          definition: parse_type(info[:definition])\n        )\n      end\n\n      def build_interface(info)\n        members = (info[:members] || []).map do |member|\n          InterfaceMember.new(\n            name: member[:name],\n            type_signature: parse_type(member[:type])\n          )\n        end\n\n        Interface.new(\n          name: info[:name],\n          members: members\n        )\n      end\n\n      def build_class(info)\n        # Build methods\n        methods = (info[:methods] || []).map do |method_info|\n          build_method(method_info)\n        end\n\n        # Build instance variables\n        instance_vars = (info[:instance_vars] || []).map do |ivar|\n          InstanceVariable.new(\n            name: ivar[:name],\n            type_annotation: ivar[:type] ? parse_type(ivar[:type]) : nil\n          )\n        end\n\n        ClassDecl.new(\n          name: info[:name],\n          superclass: info[:superclass],\n          body: methods,\n          instance_vars: instance_vars\n        )\n      end\n\n      def build_method(info)\n        params = (info[:params] || []).map do |param|\n          Parameter.new(\n            name: param[:name],\n            type_annotation: param[:type] ? parse_type(param[:type]) : nil\n          )\n        end\n\n        # \ubcf8\ubb38 IR\uc774 \uc788\uc73c\uba74 \uc0ac\uc6a9 (BodyParser\uc5d0\uc11c \ud30c\uc2f1\ub428)\n        body = info[:body_ir]\n\n        # Build location string from line/column info\n        location = info[:line] && info[:column] ? "#{info[:line]}:#{info[:column]}" : nil\n\n        MethodDef.new(\n          name: info[:name],\n          params: params,\n          return_type: info[:return_type] ? parse_type(info[:return_type]) : nil,\n          body: body,\n          visibility: info[:visibility] || :public,\n          location: location\n        )\n      end\n\n      def parse_type(type_str)\n        return nil unless type_str\n\n        type_str = type_str.strip\n        return nil if type_str.empty?\n\n        # Use ParserCombinator::TypeParser for all type parsing\n        # Supports: simple types, generics, array shorthand, union, intersection, function types\n        @type_parser ||= TRuby::ParserCombinator::TypeParser.new\n        result = @type_parser.parse(type_str)\n        return result[:type] if result[:success]\n\n        # Fallback for unparseable types - return as SimpleType\n        SimpleType.new(name: type_str)\n      end\n    end\n\n    #==========================================================================\n    # Code Generator - Converts IR to Ruby code\n    #==========================================================================\n\n    class CodeGenerator < Visitor\n      attr_reader :output\n\n      def initialize\n        @output = []\n        @indent = 0\n      end\n\n      def generate(program)\n        @output = []\n        visit(program)\n        @output.join("\\n")\n      end\n\n      def visit_program(node)\n        node.declarations.each do |decl|\n          visit(decl)\n          @output << ""\n        end\n      end\n\n      def visit_type_alias(node)\n        # Type aliases are erased in Ruby output\n        emit_comment("type #{node.name} = #{node.definition.to_trb}")\n      end\n\n      def visit_interface(node)\n        # Interfaces are erased in Ruby output\n        emit_comment("interface #{node.name}")\n        node.members.each do |member|\n          emit_comment("  #{member.name}: #{member.type_signature.to_trb}")\n        end\n        emit_comment("end")\n      end\n\n      def visit_method_def(node)\n        params_str = node.params.map(&:name).join(", ")\n        emit("def #{node.name}(#{params_str})")\n        @indent += 1\n\n        if node.body\n          visit(node.body)\n        end\n\n        @indent -= 1\n        emit("end")\n      end\n\n      def visit_block(node)\n        node.statements.each { |stmt| visit(stmt) }\n      end\n\n      def visit_assignment(node)\n        emit("#{node.target} = #{generate_expression(node.value)}")\n      end\n\n      def visit_return(node)\n        if node.value\n          emit("return #{generate_expression(node.value)}")\n        else\n          emit("return")\n        end\n      end\n\n      def visit_conditional(node)\n        keyword = node.kind == :unless ? "unless" : "if"\n        emit("#{keyword} #{generate_expression(node.condition)}")\n        @indent += 1\n        visit(node.then_branch) if node.then_branch\n        @indent -= 1\n\n        if node.else_branch\n          emit("else")\n          @indent += 1\n          visit(node.else_branch)\n          @indent -= 1\n        end\n\n        emit("end")\n      end\n\n      def visit_raw_code(node)\n        node.code.each_line do |line|\n          emit(line.rstrip)\n        end\n      end\n\n      private\n\n      def emit(text)\n        @output << (("  " * @indent) + text)\n      end\n\n      def emit_comment(text)\n        emit("# #{text}")\n      end\n\n      def generate_expression(node)\n        case node\n        when Literal\n          node.value.inspect\n        when VariableRef\n          node.name\n        when MethodCall\n          args = node.arguments.map { |a| generate_expression(a) }.join(", ")\n          if node.receiver\n            "#{generate_expression(node.receiver)}.#{node.method_name}(#{args})"\n          else\n            "#{node.method_name}(#{args})"\n          end\n        when BinaryOp\n          "(#{generate_expression(node.left)} #{node.operator} #{generate_expression(node.right)})"\n        when UnaryOp\n          "#{node.operator}#{generate_expression(node.operand)}"\n        else\n          node.to_s\n        end\n      end\n    end\n\n    #==========================================================================\n    # RBS Generator - Converts IR to RBS type definitions\n    #==========================================================================\n\n    class RBSGenerator < Visitor\n      attr_reader :output\n\n      def initialize(enable_inference: true)\n        @output = []\n        @indent = 0\n        @enable_inference = enable_inference\n        @inferrer = TRuby::ASTTypeInferrer.new if enable_inference\n        @class_env = nil # \ud604\uc7ac \ud074\ub798\uc2a4\uc758 \ud0c0\uc785 \ud658\uacbd\n      end\n\n      def generate(program)\n        @output = []\n        visit(program)\n        @output.join("\\n")\n      end\n\n      def visit_program(node)\n        node.declarations.each do |decl|\n          visit(decl)\n          @output << ""\n        end\n      end\n\n      def visit_type_alias(node)\n        emit("type #{node.name} = #{node.definition.to_rbs}")\n      end\n\n      def visit_interface(node)\n        emit("interface _#{node.name}")\n        @indent += 1\n\n        node.members.each do |member|\n          visit(member)\n        end\n\n        @indent -= 1\n        emit("end")\n      end\n\n      def visit_interface_member(node)\n        emit("def #{node.name}: #{node.type_signature.to_rbs}")\n      end\n\n      def visit_method_def(node)\n        params = node.params.map do |param|\n          type = param.type_annotation&.to_rbs || "untyped"\n          "#{param.name}: #{type}"\n        end.join(", ")\n\n        # \ubc18\ud658 \ud0c0\uc785: \uba85\uc2dc\uc801 \ud0c0\uc785 > \ucd94\ub860\ub41c \ud0c0\uc785 > untyped\n        return_type = node.return_type&.to_rbs\n\n        # initialize \uba54\uc11c\ub4dc\ub294 \ud2b9\ubcc4 \ucc98\ub9ac: \uba85\uc2dc\uc801 \ud0c0\uc785\uc774 \uc5c6\uc73c\uba74 void\n        # Ruby\uc5d0\uc11c initialize\ub294 \uc0dd\uc131\uc790\uc774\uba70, \uc2e4\uc81c \uc778\uc2a4\ud134\uc2a4 \uc0dd\uc131\uc740 Class.new\uac00 \ub2f4\ub2f9\n        if node.name == "initialize" && return_type.nil?\n          return_type = "void"\n        elsif return_type.nil? && @enable_inference && @inferrer && node.body\n          # \uba85\uc2dc\uc801 \ubc18\ud658 \ud0c0\uc785\uc774 \uc5c6\uc73c\uba74 \ucd94\ub860 \uc2dc\ub3c4\n          inferred = @inferrer.infer_method_return_type(node, @class_env)\n          return_type = inferred if inferred && inferred != "untyped"\n        end\n\n        return_type ||= "untyped"\n        visibility_prefix = format_visibility(node.visibility)\n        emit("#{visibility_prefix}def #{node.name}: (#{params}) -> #{return_type}")\n      end\n\n      def visit_class_decl(node)\n        emit("class #{node.name}")\n        @indent += 1\n\n        # \ud074\ub798\uc2a4 \ud0c0\uc785 \ud658\uacbd \uc0dd\uc131\n        @class_env = TRuby::TypeEnv.new if @enable_inference\n\n        # \uc778\uc2a4\ud134\uc2a4 \ubcc0\uc218 \ud0c0\uc785 \ub4f1\ub85d\n        (node.instance_vars || []).each do |ivar|\n          if @class_env && ivar.type_annotation\n            @class_env.define_instance_var("@#{ivar.name}", ivar.type_annotation.to_rbs)\n          end\n\n          # Emit instance variables first\n          visit_instance_variable(ivar)\n        end\n\n        # Add blank line between ivars and methods if both exist\n        @output << "" if node.instance_vars&.any? && node.body&.any?\n\n        # Emit methods\n        node.body.each { |member| visit(member) }\n\n        @class_env = nil\n        @indent -= 1\n        emit("end")\n      end\n\n      def visit_instance_variable(node)\n        type = node.type_annotation&.to_rbs || "untyped"\n        emit("@#{node.name}: #{type}")\n      end\n\n      private\n\n      def emit(text)\n        @output << (("  " * @indent) + text)\n      end\n\n      def format_visibility(visibility)\n        # RBS only supports private visibility, not protected\n        # See: https://github.com/ruby/rbs/issues/579\n        case visibility\n        when :private\n          "private "\n        else\n          ""\n        end\n      end\n    end\n\n    #==========================================================================\n    # Optimization Passes\n    #==========================================================================\n\n    module Passes\n      # Base class for optimization passes\n      class Pass\n        attr_reader :name, :changes_made\n\n        def initialize(name)\n          @name = name\n          @changes_made = 0\n        end\n\n        def run(program)\n          @changes_made = 0\n          transform(program)\n          { program: program, changes: @changes_made }\n        end\n\n        def transform(node)\n          raise NotImplementedError\n        end\n      end\n\n      # Dead code elimination\n      class DeadCodeElimination < Pass\n        def initialize\n          super("dead_code_elimination")\n        end\n\n        def transform(node)\n          case node\n          when Program\n            node.declarations = node.declarations.map { |d| transform(d) }.compact\n          when Block\n            node.statements = eliminate_dead_statements(node.statements)\n            node.statements.each { |stmt| transform(stmt) }\n          when MethodDef\n            transform(node.body) if node.body\n          end\n\n          node\n        end\n\n        private\n\n        def eliminate_dead_statements(statements)\n          result = []\n          found_return = false\n\n          statements.each do |stmt|\n            if found_return\n              @changes_made += 1\n              next\n            end\n\n            result << stmt\n            found_return = true if stmt.is_a?(Return)\n          end\n\n          result\n        end\n      end\n\n      # Constant folding\n      class ConstantFolding < Pass\n        def initialize\n          super("constant_folding")\n        end\n\n        def transform(node)\n          case node\n          when Program\n            node.declarations.each { |d| transform(d) }\n          when MethodDef\n            transform(node.body) if node.body\n          when Block\n            node.statements = node.statements.map { |s| fold_constants(s) }\n          when BinaryOp\n            fold_binary_op(node)\n          end\n\n          node\n        end\n\n        private\n\n        def fold_constants(node)\n          case node\n          when BinaryOp\n            fold_binary_op(node)\n          when Assignment\n            node.value = fold_constants(node.value)\n            node\n          when Return\n            node.value = fold_constants(node.value) if node.value\n            node\n          else\n            node\n          end\n        end\n\n        def fold_binary_op(node)\n          return node unless node.is_a?(BinaryOp)\n\n          left = fold_constants(node.left)\n          right = fold_constants(node.right)\n\n          if left.is_a?(Literal) && right.is_a?(Literal)\n            result = evaluate_op(node.operator, left.value, right.value)\n            if result\n              @changes_made += 1\n              return Literal.new(value: result, literal_type: result.class.to_s.downcase.to_sym)\n            end\n          end\n\n          node.left = left\n          node.right = right\n          node\n        end\n\n        def evaluate_op(op, left, right)\n          return nil unless left.is_a?(Numeric) && right.is_a?(Numeric)\n\n          case op\n          when "+" then left + right\n          when "-" then left - right\n          when "*" then left * right\n          when "/" then right.zero? ? nil : left / right\n          when "%" then right.zero? ? nil : left % right\n          when "**" then left**right\n          end\n        rescue StandardError\n          nil\n        end\n      end\n\n      # Type annotation cleanup\n      class TypeAnnotationCleanup < Pass\n        def initialize\n          super("type_annotation_cleanup")\n        end\n\n        def transform(node)\n          case node\n          when Program\n            node.declarations.each { |d| transform(d) }\n          when MethodDef\n            # Remove redundant type annotations\n            node.params.each do |param|\n              if param.type_annotation && redundant_annotation?(param)\n                param.type_annotation = nil\n                @changes_made += 1\n              end\n            end\n          end\n\n          node\n        end\n\n        private\n\n        def redundant_annotation?(_param)\n          # Consider annotation redundant if it matches the default/inferred type\n          false\n        end\n      end\n\n      # Unused declaration removal\n      class UnusedDeclarationRemoval < Pass\n        def initialize\n          super("unused_declaration_removal")\n        end\n\n        def transform(node)\n          return node unless node.is_a?(Program)\n\n          used_types = collect_used_types(node)\n\n          node.declarations = node.declarations.select do |decl|\n            case decl\n            when TypeAlias\n              if used_types.include?(decl.name)\n                true\n              else\n                @changes_made += 1\n                false\n              end\n            else\n              true\n            end\n          end\n\n          node\n        end\n\n        private\n\n        def collect_used_types(program)\n          used = Set.new\n\n          program.declarations.each do |decl|\n            case decl\n            when MethodDef\n              collect_types_from_method(decl, used)\n            when Interface\n              decl.members.each do |member|\n                collect_types_from_type(member.type_signature, used)\n              end\n            end\n          end\n\n          used\n        end\n\n        def collect_types_from_method(method, used)\n          method.params.each do |param|\n            collect_types_from_type(param.type_annotation, used) if param.type_annotation\n          end\n          collect_types_from_type(method.return_type, used) if method.return_type\n        end\n\n        def collect_types_from_type(type_node, used)\n          case type_node\n          when SimpleType\n            used.add(type_node.name)\n          when GenericType\n            used.add(type_node.base)\n            type_node.type_args.each { |arg| collect_types_from_type(arg, used) }\n          when UnionType, IntersectionType\n            type_node.types.each { |t| collect_types_from_type(t, used) }\n          when NullableType\n            collect_types_from_type(type_node.inner_type, used)\n          when FunctionType\n            type_node.param_types.each { |t| collect_types_from_type(t, used) }\n            collect_types_from_type(type_node.return_type, used)\n          end\n        end\n      end\n    end\n\n    #==========================================================================\n    # Optimizer - Runs optimization passes\n    #==========================================================================\n\n    class Optimizer\n      DEFAULT_PASSES = [\n        Passes::DeadCodeElimination,\n        Passes::ConstantFolding,\n        Passes::TypeAnnotationCleanup,\n        Passes::UnusedDeclarationRemoval,\n      ].freeze\n\n      attr_reader :passes, :stats\n\n      def initialize(passes: DEFAULT_PASSES)\n        @passes = passes.map(&:new)\n        @stats = {}\n      end\n\n      def optimize(program, max_iterations: 10)\n        @stats = { iterations: 0, total_changes: 0, pass_stats: {} }\n\n        max_iterations.times do |i|\n          @stats[:iterations] = i + 1\n          changes_this_iteration = 0\n\n          @passes.each do |pass|\n            result = pass.run(program)\n            program = result[:program]\n            changes_this_iteration += result[:changes]\n\n            @stats[:pass_stats][pass.name] ||= 0\n            @stats[:pass_stats][pass.name] += result[:changes]\n          end\n\n          @stats[:total_changes] += changes_this_iteration\n          break if changes_this_iteration.zero?\n        end\n\n        { program: program, stats: @stats }\n      end\n    end\n  end\nend\n',"lib/t_ruby/lsp_server.rb":'# frozen_string_literal: true\n\nrequire "json"\n\nmodule TRuby\n  # LSP (Language Server Protocol) Server for T-Ruby\n  # Provides IDE integration with autocomplete, diagnostics, and navigation\n  class LSPServer\n    VERSION = "0.1.0"\n\n    # LSP Error codes\n    module ErrorCodes\n      PARSE_ERROR = -32_700\n      INVALID_REQUEST = -32_600\n      METHOD_NOT_FOUND = -32_601\n      INVALID_PARAMS = -32_602\n      INTERNAL_ERROR = -32_603\n      SERVER_NOT_INITIALIZED = -32_002\n      UNKNOWN_ERROR_CODE = -32_001\n    end\n\n    # LSP Completion item kinds\n    module CompletionItemKind\n      TEXT = 1\n      METHOD = 2\n      FUNCTION = 3\n      CONSTRUCTOR = 4\n      FIELD = 5\n      VARIABLE = 6\n      CLASS = 7\n      INTERFACE = 8\n      MODULE = 9\n      PROPERTY = 10\n      UNIT = 11\n      VALUE = 12\n      ENUM = 13\n      KEYWORD = 14\n      SNIPPET = 15\n      COLOR = 16\n      FILE = 17\n      REFERENCE = 18\n      FOLDER = 19\n      ENUM_MEMBER = 20\n      CONSTANT = 21\n      STRUCT = 22\n      EVENT = 23\n      OPERATOR = 24\n      TYPE_PARAMETER = 25\n    end\n\n    # LSP Diagnostic severity\n    module DiagnosticSeverity\n      ERROR = 1\n      WARNING = 2\n      INFORMATION = 3\n      HINT = 4\n    end\n\n    # Semantic Token Types (LSP 3.16+)\n    module SemanticTokenTypes\n      NAMESPACE = 0\n      TYPE = 1\n      CLASS = 2\n      ENUM = 3\n      INTERFACE = 4\n      STRUCT = 5\n      TYPE_PARAMETER = 6\n      PARAMETER = 7\n      VARIABLE = 8\n      PROPERTY = 9\n      ENUM_MEMBER = 10\n      EVENT = 11\n      FUNCTION = 12\n      METHOD = 13\n      MACRO = 14\n      KEYWORD = 15\n      MODIFIER = 16\n      COMMENT = 17\n      STRING = 18\n      NUMBER = 19\n      REGEXP = 20\n      OPERATOR = 21\n    end\n\n    # Semantic Token Modifiers (bit flags)\n    module SemanticTokenModifiers\n      DECLARATION = 0x01\n      DEFINITION = 0x02\n      READONLY = 0x04\n      STATIC = 0x08\n      DEPRECATED = 0x10\n      ABSTRACT = 0x20\n      ASYNC = 0x40\n      MODIFICATION = 0x80\n      DOCUMENTATION = 0x100\n      DEFAULT_LIBRARY = 0x200\n    end\n\n    # Token type names for capability registration\n    SEMANTIC_TOKEN_TYPES = %w[\n      namespace type class enum interface struct typeParameter\n      parameter variable property enumMember event function method\n      macro keyword modifier comment string number regexp operator\n    ].freeze\n\n    # Token modifier names\n    SEMANTIC_TOKEN_MODIFIERS = %w[\n      declaration definition readonly static deprecated\n      abstract async modification documentation defaultLibrary\n    ].freeze\n\n    # Built-in types for completion\n    BUILT_IN_TYPES = %w[String Integer Boolean Array Hash Symbol void nil].freeze\n\n    # Type keywords for completion\n    TYPE_KEYWORDS = %w[type interface def end].freeze\n\n    def initialize(input: $stdin, output: $stdout)\n      @input = input\n      @output = output\n      @documents = {}\n      @initialized = false\n      @shutdown_requested = false\n      @type_alias_registry = TypeAliasRegistry.new\n      # Use Compiler for unified diagnostics (same as CLI)\n      @compiler = Compiler.new\n    end\n\n    # Main run loop for the LSP server\n    def run\n      loop do\n        message = read_message\n        break if message.nil?\n\n        response = handle_message(message)\n        send_response(response) if response\n      end\n    end\n\n    # Read a single LSP message from input\n    def read_message\n      # Read headers\n      headers = {}\n      loop do\n        line = @input.gets\n        return nil if line.nil?\n\n        line = line.strip\n        break if line.empty?\n\n        if line =~ /^([^:]+):\\s*(.+)$/\n          headers[Regexp.last_match(1)] = Regexp.last_match(2)\n        end\n      end\n\n      content_length = headers["Content-Length"]&.to_i\n      return nil unless content_length&.positive?\n\n      # Read content\n      content = @input.read(content_length)\n      return nil if content.nil?\n\n      JSON.parse(content)\n    rescue JSON::ParserError => e\n      { "error" => "Parse error: #{e.message}" }\n    end\n\n    # Send a response message\n    def send_response(response)\n      return if response.nil?\n\n      content = JSON.generate(response)\n      message = "Content-Length: #{content.bytesize}\\r\\n\\r\\n#{content}"\n      @output.write(message)\n      @output.flush\n    end\n\n    # Send a notification (no response expected)\n    def send_notification(method, params)\n      notification = {\n        "jsonrpc" => "2.0",\n        "method" => method,\n        "params" => params,\n      }\n      send_response(notification)\n    end\n\n    # Handle an incoming message\n    def handle_message(message)\n      return error_response(nil, ErrorCodes::PARSE_ERROR, "Parse error") if message["error"]\n\n      method = message["method"]\n      params = message["params"] || {}\n      id = message["id"]\n\n      # Check if server is initialized for non-init methods\n      if !@initialized && method != "initialize" && method != "exit"\n        return error_response(id, ErrorCodes::SERVER_NOT_INITIALIZED, "Server not initialized")\n      end\n\n      result = dispatch_method(method, params, id)\n\n      # For notifications (no id), don\'t send a response\n      return nil if id.nil?\n\n      if result.is_a?(Hash) && result[:error]\n        error_response(id, result[:error][:code], result[:error][:message])\n      else\n        success_response(id, result)\n      end\n    end\n\n    private\n\n    def dispatch_method(method, params, _id)\n      case method\n      when "initialize"\n        handle_initialize(params)\n      when "initialized"\n        handle_initialized(params)\n      when "shutdown"\n        handle_shutdown\n      when "exit"\n        handle_exit\n      when "textDocument/didOpen"\n        handle_did_open(params)\n      when "textDocument/didChange"\n        handle_did_change(params)\n      when "textDocument/didClose"\n        handle_did_close(params)\n      when "textDocument/completion"\n        handle_completion(params)\n      when "textDocument/hover"\n        handle_hover(params)\n      when "textDocument/definition"\n        handle_definition(params)\n      when "textDocument/semanticTokens/full"\n        handle_semantic_tokens_full(params)\n      when "textDocument/diagnostic"\n        handle_diagnostic(params)\n      else\n        { error: { code: ErrorCodes::METHOD_NOT_FOUND, message: "Method not found: #{method}" } }\n      end\n    end\n\n    # === LSP Lifecycle Methods ===\n\n    def handle_initialize(params)\n      @initialized = true\n      @root_uri = params["rootUri"]\n      @workspace_folders = params["workspaceFolders"]\n\n      {\n        "capabilities" => {\n          "textDocumentSync" => {\n            "openClose" => true,\n            "change" => 1, # Full sync\n            "save" => { "includeText" => true },\n          },\n          "completionProvider" => {\n            "triggerCharacters" => [":", "<", "|", "&"],\n            "resolveProvider" => false,\n          },\n          "hoverProvider" => true,\n          "definitionProvider" => true,\n          "diagnosticProvider" => {\n            "interFileDependencies" => false,\n            "workspaceDiagnostics" => false,\n          },\n          "semanticTokensProvider" => {\n            "legend" => {\n              "tokenTypes" => SEMANTIC_TOKEN_TYPES,\n              "tokenModifiers" => SEMANTIC_TOKEN_MODIFIERS,\n            },\n            "full" => true,\n            "range" => false,\n          },\n        },\n        "serverInfo" => {\n          "name" => "t-ruby-lsp",\n          "version" => VERSION,\n        },\n      }\n    end\n\n    def handle_initialized(_params)\n      # Server is now fully initialized\n      nil\n    end\n\n    def handle_shutdown\n      @shutdown_requested = true\n      nil\n    end\n\n    def handle_exit\n      exit(@shutdown_requested ? 0 : 1)\n    end\n\n    # === Document Synchronization ===\n\n    def handle_did_open(params)\n      text_document = params["textDocument"]\n      uri = text_document["uri"]\n      text = text_document["text"]\n\n      @documents[uri] = {\n        text: text,\n        version: text_document["version"],\n      }\n\n      # Parse and send diagnostics\n      publish_diagnostics(uri, text)\n      nil\n    end\n\n    def handle_did_change(params)\n      text_document = params["textDocument"]\n      uri = text_document["uri"]\n      changes = params["contentChanges"]\n\n      # For full sync, take the last change\n      if changes && !changes.empty?\n        @documents[uri] = {\n          text: changes.last["text"],\n          version: text_document["version"],\n        }\n\n        # Re-parse and send diagnostics\n        publish_diagnostics(uri, changes.last["text"])\n      end\n      nil\n    end\n\n    def handle_did_close(params)\n      uri = params["textDocument"]["uri"]\n      @documents.delete(uri)\n\n      # Clear diagnostics\n      send_notification("textDocument/publishDiagnostics", {\n                          "uri" => uri,\n                          "diagnostics" => [],\n                        })\n      nil\n    end\n\n    # === Diagnostics ===\n\n    # Handle pull-based diagnostics (LSP 3.17+)\n    def handle_diagnostic(params)\n      uri = params.dig("textDocument", "uri")\n      return { "kind" => "full", "items" => [] } unless uri\n\n      doc = @documents[uri]\n      return { "kind" => "full", "items" => [] } unless doc\n\n      text = doc[:text]\n      return { "kind" => "full", "items" => [] } unless text\n\n      diagnostics = analyze_document(text)\n      { "kind" => "full", "items" => diagnostics }\n    end\n\n    def publish_diagnostics(uri, text)\n      diagnostics = analyze_document(text)\n\n      send_notification("textDocument/publishDiagnostics", {\n                          "uri" => uri,\n                          "diagnostics" => diagnostics,\n                        })\n    end\n\n    def analyze_document(text, uri: nil)\n      # Use unified Compiler.analyze for diagnostics\n      # This ensures CLI and LSP show the same errors\n      file_path = uri ? uri_to_path(uri) : "<source>"\n      compiler_diagnostics = @compiler.analyze(text, file: file_path)\n\n      # Convert TRuby::Diagnostic objects to LSP diagnostic format\n      compiler_diagnostics.map { |d| diagnostic_to_lsp(d) }\n    end\n\n    # Convert TRuby::Diagnostic to LSP diagnostic format\n    def diagnostic_to_lsp(diagnostic)\n      # LSP uses 0-based line numbers\n      line = (diagnostic.line || 1) - 1\n      line = 0 if line.negative?\n\n      col = (diagnostic.column || 1) - 1\n      col = 0 if col.negative?\n\n      end_col = diagnostic.end_column ? diagnostic.end_column - 1 : col + 1\n\n      severity = case diagnostic.severity\n                 when :error then DiagnosticSeverity::ERROR\n                 when :warning then DiagnosticSeverity::WARNING\n                 when :info then DiagnosticSeverity::INFORMATION\n                 else DiagnosticSeverity::ERROR\n                 end\n\n      lsp_diag = {\n        "range" => {\n          "start" => { "line" => line, "character" => col },\n          "end" => { "line" => line, "character" => end_col },\n        },\n        "severity" => severity,\n        "source" => "t-ruby",\n        "message" => diagnostic.message,\n      }\n\n      # Add error code if available\n      lsp_diag["code"] = diagnostic.code if diagnostic.code\n\n      lsp_diag\n    end\n\n    def uri_to_path(uri)\n      # Convert file:// URI to filesystem path\n      return uri unless uri.start_with?("file://")\n\n      uri.sub(%r{^file://}, "")\n    end\n\n    def create_diagnostic(line, message, severity)\n      {\n        "range" => {\n          "start" => { "line" => line, "character" => 0 },\n          "end" => { "line" => line, "character" => 1000 },\n        },\n        "severity" => severity,\n        "source" => "t-ruby",\n        "message" => message,\n      }\n    end\n\n    # === Completion ===\n\n    def handle_completion(params)\n      uri = params["textDocument"]["uri"]\n      position = params["position"]\n\n      document = @documents[uri]\n      return { "items" => [] } unless document\n\n      text = document[:text]\n      lines = text.split("\\n")\n      line = lines[position["line"]] || ""\n      char_pos = position["character"]\n\n      # Get the text before cursor\n      prefix = line[0...char_pos] || ""\n\n      completions = []\n\n      # Context-aware completion\n      case prefix\n      when /:\\s*$/\n        # After colon - suggest types\n        completions.concat(type_completions)\n      when /\\|\\s*$/\n        # After pipe - suggest types for union\n        completions.concat(type_completions)\n      when /&\\s*$/\n        # After ampersand - suggest types for intersection\n        completions.concat(type_completions)\n      when /<\\s*$/\n        # Inside generic - suggest types\n        completions.concat(type_completions)\n      when /^\\s*$/\n        # Start of line - suggest keywords\n        completions.concat(keyword_completions)\n      when /^\\s*def\\s+\\w*$/\n        # Function definition - no completion needed\n        completions = []\n      when /^\\s*type\\s+\\w*$/\n        # Type alias definition - no completion needed\n        completions = []\n      when /^\\s*interface\\s+\\w*$/\n        # Interface definition - no completion needed\n        completions = []\n      else\n        # Default - suggest all\n        completions.concat(type_completions)\n        completions.concat(keyword_completions)\n      end\n\n      # Add document-specific completions\n      completions.concat(document_type_completions(text))\n\n      { "items" => completions }\n    end\n\n    def type_completions\n      BUILT_IN_TYPES.map do |type|\n        {\n          "label" => type,\n          "kind" => CompletionItemKind::CLASS,\n          "detail" => "Built-in type",\n          "documentation" => "T-Ruby built-in type: #{type}",\n        }\n      end\n    end\n\n    def keyword_completions\n      TYPE_KEYWORDS.map do |keyword|\n        {\n          "label" => keyword,\n          "kind" => CompletionItemKind::KEYWORD,\n          "detail" => "Keyword",\n          "documentation" => keyword_documentation(keyword),\n        }\n      end\n    end\n\n    def keyword_documentation(keyword)\n      case keyword\n      when "type"\n        "Define a type alias: type AliasName = TypeDefinition"\n      when "interface"\n        "Define an interface: interface Name ... end"\n      when "def"\n        "Define a function with type annotations: def name(param: Type): ReturnType"\n      when "end"\n        "End a block (interface, class, method, etc.)"\n      else\n        keyword\n      end\n    end\n\n    def document_type_completions(text)\n      parser = Parser.new(text)\n      result = parser.parse\n\n      # Add type aliases from the document\n      completions = (result[:type_aliases] || []).map do |alias_info|\n        {\n          "label" => alias_info[:name],\n          "kind" => CompletionItemKind::CLASS,\n          "detail" => "Type alias",\n          "documentation" => "type #{alias_info[:name]} = #{alias_info[:definition]}",\n        }\n      end\n\n      # Add interfaces from the document\n      (result[:interfaces] || []).each do |interface_info|\n        completions << {\n          "label" => interface_info[:name],\n          "kind" => CompletionItemKind::INTERFACE,\n          "detail" => "Interface",\n          "documentation" => "interface #{interface_info[:name]}",\n        }\n      end\n\n      completions\n    end\n\n    # === Hover ===\n\n    def handle_hover(params)\n      uri = params["textDocument"]["uri"]\n      position = params["position"]\n\n      document = @documents[uri]\n      return nil unless document\n\n      text = document[:text]\n      lines = text.split("\\n")\n      line = lines[position["line"]] || ""\n      char_pos = position["character"]\n\n      # Find the word at cursor position\n      word = extract_word_at_position(line, char_pos)\n      return nil if word.nil? || word.empty?\n\n      hover_info = get_hover_info(word, text)\n      return nil unless hover_info\n\n      {\n        "contents" => {\n          "kind" => "markdown",\n          "value" => hover_info,\n        },\n        "range" => word_range(position["line"], line, char_pos, word),\n      }\n    end\n\n    def extract_word_at_position(line, char_pos)\n      return nil if char_pos > line.length\n\n      # Find word boundaries\n      start_pos = char_pos\n      end_pos = char_pos\n\n      # Move start back to word start\n      start_pos -= 1 while start_pos.positive? && line[start_pos - 1] =~ /[\\w<>]/\n\n      # Move end forward to word end\n      end_pos += 1 while end_pos < line.length && line[end_pos] =~ /[\\w<>]/\n\n      return nil if start_pos == end_pos\n\n      line[start_pos...end_pos]\n    end\n\n    def word_range(line_num, line, char_pos, word)\n      start_pos = line.index(word) || char_pos\n      end_pos = start_pos + word.length\n\n      {\n        "start" => { "line" => line_num, "character" => start_pos },\n        "end" => { "line" => line_num, "character" => end_pos },\n      }\n    end\n\n    def get_hover_info(word, text)\n      # Check if it\'s a built-in type\n      if BUILT_IN_TYPES.include?(word)\n        return "**#{word}** - Built-in T-Ruby type"\n      end\n\n      # Check if it\'s a type alias\n      parser = Parser.new(text)\n      result = parser.parse\n\n      (result[:type_aliases] || []).each do |alias_info|\n        if alias_info[:name] == word\n          return "**Type Alias**\\n\\n```ruby\\ntype #{alias_info[:name]} = #{alias_info[:definition]}\\n```"\n        end\n      end\n\n      # Check if it\'s an interface\n      (result[:interfaces] || []).each do |interface_info|\n        if interface_info[:name] == word\n          members = interface_info[:members].map { |m| "  #{m[:name]}: #{m[:type]}" }.join("\\n")\n          return "**Interface**\\n\\n```ruby\\ninterface #{interface_info[:name]}\\n#{members}\\nend\\n```"\n        end\n      end\n\n      # Check if it\'s a function\n      (result[:functions] || []).each do |func|\n        next unless func[:name] == word\n\n        params = func[:params].map { |p| "#{p[:name]}: #{p[:type] || "untyped"}" }.join(", ")\n        return_type = func[:return_type] || "void"\n        return "**Function**\\n\\n```ruby\\ndef #{func[:name]}(#{params}): #{return_type}\\n```"\n      end\n\n      nil\n    end\n\n    # === Definition ===\n\n    def handle_definition(params)\n      uri = params["textDocument"]["uri"]\n      position = params["position"]\n\n      document = @documents[uri]\n      return nil unless document\n\n      text = document[:text]\n      lines = text.split("\\n")\n      line = lines[position["line"]] || ""\n      char_pos = position["character"]\n\n      word = extract_word_at_position(line, char_pos)\n      return nil if word.nil? || word.empty?\n\n      # Find definition location\n      location = find_definition(word, text, uri)\n      return nil unless location\n\n      location\n    end\n\n    def find_definition(word, text, uri)\n      lines = text.split("\\n")\n\n      # Search for type alias definition\n      lines.each_with_index do |line, idx|\n        if line.match?(/^\\s*type\\s+#{Regexp.escape(word)}\\s*=/)\n          return {\n            "uri" => uri,\n            "range" => {\n              "start" => { "line" => idx, "character" => 0 },\n              "end" => { "line" => idx, "character" => line.length },\n            },\n          }\n        end\n\n        # Search for interface definition\n        if line.match?(/^\\s*interface\\s+#{Regexp.escape(word)}\\s*$/)\n          return {\n            "uri" => uri,\n            "range" => {\n              "start" => { "line" => idx, "character" => 0 },\n              "end" => { "line" => idx, "character" => line.length },\n            },\n          }\n        end\n\n        # Search for function definition\n        if line.match?(/^\\s*def\\s+#{Regexp.escape(word)}\\s*\\(/)\n          return {\n            "uri" => uri,\n            "range" => {\n              "start" => { "line" => idx, "character" => 0 },\n              "end" => { "line" => idx, "character" => line.length },\n            },\n          }\n        end\n      end\n\n      nil\n    end\n\n    # === Semantic Tokens ===\n\n    def handle_semantic_tokens_full(params)\n      uri = params["textDocument"]["uri"]\n      document = @documents[uri]\n      return { "data" => [] } unless document\n\n      text = document[:text]\n      tokens = generate_semantic_tokens(text)\n\n      { "data" => tokens }\n    end\n\n    def generate_semantic_tokens(text)\n      lines = text.split("\\n")\n\n      # Parse the document to get IR\n      parser = Parser.new(text)\n      parse_result = parser.parse\n      parser.ir_program\n\n      # Collect all tokens from parsing\n      raw_tokens = []\n\n      # Process type aliases\n      (parse_result[:type_aliases] || []).each do |alias_info|\n        lines.each_with_index do |line, line_idx|\n          next unless (match = line.match(/^\\s*type\\s+(#{Regexp.escape(alias_info[:name])})\\s*=/))\n\n          # \'type\' keyword\n          type_pos = line.index("type")\n          raw_tokens << [line_idx, type_pos, 4, SemanticTokenTypes::KEYWORD, SemanticTokenModifiers::DECLARATION]\n\n          # Type name\n          name_pos = match.begin(1)\n          raw_tokens << [line_idx, name_pos, alias_info[:name].length, SemanticTokenTypes::TYPE, SemanticTokenModifiers::DEFINITION]\n\n          # Type definition (after =)\n          add_type_tokens(raw_tokens, line, line_idx, alias_info[:definition])\n        end\n      end\n\n      # Process interfaces\n      (parse_result[:interfaces] || []).each do |interface_info|\n        lines.each_with_index do |line, line_idx|\n          if (match = line.match(/^\\s*interface\\s+(#{Regexp.escape(interface_info[:name])})/))\n            # \'interface\' keyword\n            interface_pos = line.index("interface")\n            raw_tokens << [line_idx, interface_pos, 9, SemanticTokenTypes::KEYWORD, SemanticTokenModifiers::DECLARATION]\n\n            # Interface name\n            name_pos = match.begin(1)\n            raw_tokens << [line_idx, name_pos, interface_info[:name].length, SemanticTokenTypes::INTERFACE, SemanticTokenModifiers::DEFINITION]\n          end\n\n          # Interface members\n          interface_info[:members]&.each do |member|\n            next unless (match = line.match(/^\\s*(#{Regexp.escape(member[:name])})\\s*:\\s*/))\n\n            prop_pos = match.begin(1)\n            raw_tokens << [line_idx, prop_pos, member[:name].length, SemanticTokenTypes::PROPERTY, 0]\n\n            # Member type\n            add_type_tokens(raw_tokens, line, line_idx, member[:type])\n          end\n        end\n      end\n\n      # Process functions\n      (parse_result[:functions] || []).each do |func|\n        lines.each_with_index do |line, line_idx|\n          next unless (match = line.match(/^\\s*def\\s+(#{Regexp.escape(func[:name])})\\s*\\(/))\n\n          # \'def\' keyword\n          def_pos = line.index("def")\n          raw_tokens << [line_idx, def_pos, 3, SemanticTokenTypes::KEYWORD, 0]\n\n          # Function name\n          name_pos = match.begin(1)\n          raw_tokens << [line_idx, name_pos, func[:name].length, SemanticTokenTypes::FUNCTION, SemanticTokenModifiers::DEFINITION]\n\n          # Parameters\n          func[:params]&.each do |param|\n            next unless (param_match = line.match(/\\b(#{Regexp.escape(param[:name])})\\s*(?::\\s*)?/))\n\n            param_pos = param_match.begin(1)\n            raw_tokens << [line_idx, param_pos, param[:name].length, SemanticTokenTypes::PARAMETER, 0]\n\n            # Parameter type if present\n            if param[:type]\n              add_type_tokens(raw_tokens, line, line_idx, param[:type])\n            end\n          end\n\n          # Return type\n          if func[:return_type]\n            add_type_tokens(raw_tokens, line, line_idx, func[:return_type])\n          end\n        end\n      end\n\n      # Process \'end\' keywords\n      lines.each_with_index do |line, line_idx|\n        if (match = line.match(/^\\s*(end)\\s*$/))\n          end_pos = match.begin(1)\n          raw_tokens << [line_idx, end_pos, 3, SemanticTokenTypes::KEYWORD, 0]\n        end\n      end\n\n      # Sort tokens by line, then by character position\n      raw_tokens.sort_by! { |t| [t[0], t[1]] }\n\n      # Convert to delta encoding\n      encode_tokens(raw_tokens)\n    end\n\n    def add_type_tokens(raw_tokens, line, line_idx, type_str)\n      return unless type_str\n\n      # Find position of the type in the line\n      pos = line.index(type_str)\n      return unless pos\n\n      # Handle built-in types\n      if BUILT_IN_TYPES.include?(type_str)\n        raw_tokens << [line_idx, pos, type_str.length, SemanticTokenTypes::TYPE, SemanticTokenModifiers::DEFAULT_LIBRARY]\n        return\n      end\n\n      # Handle generic types like Array<String>\n      if type_str.include?("<")\n        if (match = type_str.match(/^(\\w+)<(.+)>$/))\n          base = match[1]\n          base_pos = line.index(base, pos)\n          if base_pos\n            modifier = BUILT_IN_TYPES.include?(base) ? SemanticTokenModifiers::DEFAULT_LIBRARY : 0\n            raw_tokens << [line_idx, base_pos, base.length, SemanticTokenTypes::TYPE, modifier]\n          end\n          # Recursively process type arguments\n          # (simplified - just mark them as types)\n          args = match[2]\n          args.split(/[,\\s]+/).each do |arg|\n            arg = arg.strip.gsub(/[<>]/, "")\n            next if arg.empty?\n\n            arg_pos = line.index(arg, pos)\n            if arg_pos\n              modifier = BUILT_IN_TYPES.include?(arg) ? SemanticTokenModifiers::DEFAULT_LIBRARY : 0\n              raw_tokens << [line_idx, arg_pos, arg.length, SemanticTokenTypes::TYPE, modifier]\n            end\n          end\n        end\n        return\n      end\n\n      # Handle union types\n      if type_str.include?("|")\n        type_str.split("|").map(&:strip).each do |t|\n          t_pos = line.index(t, pos)\n          if t_pos\n            modifier = BUILT_IN_TYPES.include?(t) ? SemanticTokenModifiers::DEFAULT_LIBRARY : 0\n            raw_tokens << [line_idx, t_pos, t.length, SemanticTokenTypes::TYPE, modifier]\n          end\n        end\n        return\n      end\n\n      # Handle intersection types\n      if type_str.include?("&")\n        type_str.split("&").map(&:strip).each do |t|\n          t_pos = line.index(t, pos)\n          if t_pos\n            modifier = BUILT_IN_TYPES.include?(t) ? SemanticTokenModifiers::DEFAULT_LIBRARY : 0\n            raw_tokens << [line_idx, t_pos, t.length, SemanticTokenTypes::TYPE, modifier]\n          end\n        end\n        return\n      end\n\n      # Simple type\n      raw_tokens << [line_idx, pos, type_str.length, SemanticTokenTypes::TYPE, 0]\n    end\n\n    def encode_tokens(raw_tokens)\n      encoded = []\n      prev_line = 0\n      prev_char = 0\n\n      raw_tokens.each do |token|\n        line, char, length, token_type, modifiers = token\n\n        delta_line = line - prev_line\n        delta_char = delta_line.zero? ? char - prev_char : char\n\n        encoded << delta_line\n        encoded << delta_char\n        encoded << length\n        encoded << token_type\n        encoded << modifiers\n\n        prev_line = line\n        prev_char = char\n      end\n\n      encoded\n    end\n\n    # === Response Helpers ===\n\n    def success_response(id, result)\n      {\n        "jsonrpc" => "2.0",\n        "id" => id,\n        "result" => result,\n      }\n    end\n\n    def error_response(id, code, message)\n      {\n        "jsonrpc" => "2.0",\n        "id" => id,\n        "error" => {\n          "code" => code,\n          "message" => message,\n        },\n      }\n    end\n  end\nend\n',"lib/t_ruby/package_manager.rb":'# frozen_string_literal: true\n\nrequire "json"\nrequire "fileutils"\nrequire "net/http"\nrequire "uri"\nrequire "time"\n\nmodule TRuby\n  # Semantic version parsing and comparison\n  class SemanticVersion\n    include Comparable\n\n    attr_reader :major, :minor, :patch, :prerelease\n\n    VERSION_REGEX = /^(\\d+)\\.(\\d+)\\.(\\d+)(?:-(.+))?$/\n\n    def initialize(version_string)\n      match = VERSION_REGEX.match(version_string.to_s)\n      raise ArgumentError, "Invalid version: #{version_string}" unless match\n\n      @major = match[1].to_i\n      @minor = match[2].to_i\n      @patch = match[3].to_i\n      @prerelease = match[4]\n    end\n\n    def <=>(other)\n      return nil unless other.is_a?(SemanticVersion)\n\n      result = [@major, @minor, @patch] <=> [other.major, other.minor, other.patch]\n      return result unless result.zero?\n\n      # Both have same version, compare prerelease\n      return 0 if @prerelease.nil? && other.prerelease.nil?\n      return 1 if @prerelease.nil? # Release > prerelease\n      return -1 if other.prerelease.nil?\n\n      @prerelease <=> other.prerelease\n    end\n\n    def satisfies?(constraint)\n      VersionConstraint.new(constraint).satisfied_by?(self)\n    end\n\n    def to_s\n      base = "#{@major}.#{@minor}.#{@patch}"\n      @prerelease ? "#{base}-#{@prerelease}" : base\n    end\n\n    def self.parse(str)\n      new(str)\n    rescue ArgumentError\n      nil\n    end\n  end\n\n  # Version constraint (^1.0.0, ~>1.0, >=1.0.0 <2.0.0)\n  class VersionConstraint\n    attr_reader :constraints\n\n    def initialize(constraint_string)\n      @constraints = parse_constraints(constraint_string)\n    end\n\n    def satisfied_by?(version)\n      version = SemanticVersion.new(version) if version.is_a?(String)\n      @constraints.all? { |op, target| check_constraint(version, op, target) }\n    end\n\n    private\n\n    def parse_constraints(str)\n      constraints = []\n      parts = str.split(/\\s+/)\n\n      i = 0\n      while i < parts.length\n        part = parts[i]\n\n        case part\n        when /^\\^(.+)$/ # Caret range: ^1.2.3 means >=1.2.3 <2.0.0\n          version = SemanticVersion.new(Regexp.last_match(1))\n          constraints << [:>=, version]\n          constraints << [:<, SemanticVersion.new("#{version.major + 1}.0.0")]\n        when /^~(.+)$/, /^~>(.+)$/ # Tilde range: ~1.2.3 means >=1.2.3 <1.3.0\n          version = SemanticVersion.new(Regexp.last_match(1))\n          constraints << [:>=, version]\n          constraints << [:<, SemanticVersion.new("#{version.major}.#{version.minor + 1}.0")]\n        when /^>=(.+)$/\n          constraints << [:>=, SemanticVersion.new(Regexp.last_match(1))]\n        when /^<=(.+)$/\n          constraints << [:<=, SemanticVersion.new(Regexp.last_match(1))]\n        when /^>(.+)$/\n          constraints << [:>, SemanticVersion.new(Regexp.last_match(1))]\n        when /^<(.+)$/\n          constraints << [:<, SemanticVersion.new(Regexp.last_match(1))]\n        when /^=(.+)$/, /^(\\d+\\.\\d+\\.\\d+.*)$/\n          constraints << [:==, SemanticVersion.new(Regexp.last_match(1))]\n        when "*"\n          # Match any version\n        end\n\n        i += 1\n      end\n\n      constraints\n    end\n\n    def check_constraint(version, operator, target)\n      version.send(operator, target)\n    end\n  end\n\n  # Package manifest (.trb-manifest.json)\n  class PackageManifest\n    MANIFEST_FILE = ".trb-manifest.json"\n\n    attr_accessor :name, :version, :description, :author, :license, :types, :dependencies, :dev_dependencies,\n                  :repository, :keywords, :main\n\n    def initialize(data = {})\n      @name = data[:name] || data["name"]\n      @version = data[:version] || data["version"] || "0.0.0"\n      @description = data[:description] || data["description"]\n      @author = data[:author] || data["author"]\n      @license = data[:license] || data["license"]\n      @types = data[:types] || data["types"] || "lib/types/**/*.d.trb"\n      @dependencies = data[:dependencies] || data["dependencies"] || {}\n      @dev_dependencies = data[:dev_dependencies] || data["devDependencies"] || {}\n      @repository = data[:repository] || data["repository"]\n      @keywords = data[:keywords] || data["keywords"] || []\n      @main = data[:main] || data["main"]\n    end\n\n    def to_h\n      {\n        name: @name,\n        version: @version,\n        description: @description,\n        author: @author,\n        license: @license,\n        types: @types,\n        dependencies: @dependencies,\n        devDependencies: @dev_dependencies,\n        repository: @repository,\n        keywords: @keywords,\n        main: @main,\n      }.compact\n    end\n\n    def to_json(*_args)\n      JSON.pretty_generate(to_h)\n    end\n\n    def save(path = MANIFEST_FILE)\n      File.write(path, to_json)\n    end\n\n    def self.load(path = MANIFEST_FILE)\n      return nil unless File.exist?(path)\n\n      data = JSON.parse(File.read(path))\n      new(data)\n    rescue JSON::ParserError\n      nil\n    end\n\n    def valid?\n      !@name.nil? && !@name.empty? && !@version.nil?\n    end\n\n    def add_dependency(name, version)\n      @dependencies[name] = version\n    end\n\n    def add_dev_dependency(name, version)\n      @dev_dependencies[name] = version\n    end\n\n    def remove_dependency(name)\n      @dependencies.delete(name)\n    end\n  end\n\n  # Dependency resolver\n  class DependencyResolver\n    attr_reader :resolved, :conflicts\n\n    def initialize(registry = nil)\n      @registry = registry || PackageRegistry.new\n      @resolved = {}\n      @conflicts = []\n      @in_progress = Set.new\n    end\n\n    # Resolve all dependencies for a manifest\n    def resolve(manifest)\n      @resolved = {}\n      @conflicts = []\n\n      manifest.dependencies.each do |name, version_constraint|\n        resolve_package(name, version_constraint)\n      end\n\n      { resolved: @resolved, conflicts: @conflicts }\n    end\n\n    # Check for circular dependencies\n    def check_circular(manifest)\n      visited = Set.new\n      path = []\n\n      check_circular_recursive(manifest.name, manifest.dependencies, visited, path)\n    end\n\n    private\n\n    def resolve_package(name, constraint)\n      return if @resolved.key?(name)\n\n      if @in_progress.include?(name)\n        @conflicts << "Circular dependency detected: #{name}"\n        return\n      end\n\n      @in_progress.add(name)\n\n      # Find matching version\n      available = @registry.get_versions(name)\n      matching = find_matching_version(available, constraint)\n\n      if matching\n        @resolved[name] = matching\n\n        # Resolve transitive dependencies\n        pkg_info = @registry.get_package(name, matching)\n        if pkg_info && pkg_info[:dependencies]\n          pkg_info[:dependencies].each do |dep_name, dep_constraint|\n            resolve_package(dep_name, dep_constraint)\n          end\n        end\n      else\n        @conflicts << "No matching version for #{name} (#{constraint})"\n      end\n\n      @in_progress.delete(name)\n    end\n\n    def find_matching_version(versions, constraint)\n      constraint_obj = VersionConstraint.new(constraint)\n      versions\n        .map { |v| SemanticVersion.parse(v) }\n        .compact\n        .select { |v| constraint_obj.satisfied_by?(v) }\n        .max\n        &.to_s\n    end\n\n    def check_circular_recursive(name, deps, visited, path)\n      return [] if deps.nil? || deps.empty?\n\n      if path.include?(name)\n        cycle_start = path.index(name)\n        return [path[cycle_start..] + [name]]\n      end\n\n      return [] if visited.include?(name)\n\n      visited.add(name)\n      path.push(name)\n\n      cycles = []\n      deps.each_key do |dep_name|\n        pkg = @registry.get_package(dep_name, "*")\n        if pkg\n          cycles.concat(check_circular_recursive(dep_name, pkg[:dependencies] || {}, visited, path.dup))\n        end\n      end\n\n      path.pop\n      cycles\n    end\n  end\n\n  # Remote registry client (RubyGems.org style API)\n  class RemoteRegistry\n    DEFAULT_REGISTRY_URL = "https://rubygems.org/api/v1"\n    TYPE_REGISTRY_URL = "https://types.ruby-lang.org/api/v1" # Hypothetical type registry\n\n    attr_reader :registry_url, :cache_dir\n\n    def initialize(registry_url: nil, cache_dir: nil)\n      @registry_url = registry_url || TYPE_REGISTRY_URL\n      @cache_dir = cache_dir || File.join(Dir.home, ".trb-cache")\n      @http_cache = {}\n      FileUtils.mkdir_p(@cache_dir)\n    end\n\n    # Search for type packages\n    def search(query, page: 1, per_page: 30)\n      uri = URI("#{@registry_url}/search.json")\n      uri.query = URI.encode_www_form(query: query, page: page, per_page: per_page)\n\n      response = fetch_json(uri)\n      return [] unless response\n\n      response.map do |pkg|\n        {\n          name: pkg["name"],\n          version: pkg["version"],\n          downloads: pkg["downloads"],\n          summary: pkg["info"] || pkg["summary"],\n        }\n      end\n    rescue StandardError => e\n      warn "Registry search failed: #{e.message}"\n      []\n    end\n\n    # Get package info\n    def info(name)\n      uri = URI("#{@registry_url}/gems/#{name}.json")\n      response = fetch_json(uri)\n      return nil unless response\n\n      {\n        name: response["name"],\n        version: response["version"],\n        authors: response["authors"],\n        summary: response["info"],\n        homepage: response["homepage_uri"],\n        source_code: response["source_code_uri"],\n        documentation: response["documentation_uri"],\n        licenses: response["licenses"],\n        dependencies: parse_dependencies(response["dependencies"]),\n      }\n    rescue StandardError => e\n      warn "Failed to fetch package info: #{e.message}"\n      nil\n    end\n\n    # Get all versions of a package\n    def versions(name)\n      uri = URI("#{@registry_url}/versions/#{name}.json")\n      response = fetch_json(uri)\n      return [] unless response\n\n      response.map do |v|\n        {\n          number: v["number"],\n          created_at: v["created_at"],\n          prerelease: v["prerelease"],\n          sha: v["sha"],\n        }\n      end\n    rescue StandardError => e\n      warn "Failed to fetch versions: #{e.message}"\n      []\n    end\n\n    # Download package\n    def download(name, version, target_dir = nil)\n      target = target_dir || File.join(@cache_dir, name, version)\n      FileUtils.mkdir_p(target)\n\n      # Download from registry\n      uri = URI("#{@registry_url}/gems/#{name}-#{version}.gem")\n\n      gem_path = File.join(target, "#{name}-#{version}.gem")\n      download_file(uri, gem_path)\n\n      # Extract type definitions\n      extract_types(gem_path, target)\n\n      target\n    rescue StandardError => e\n      warn "Download failed: #{e.message}"\n      nil\n    end\n\n    # Push package to registry\n    def push(gem_path, api_key:)\n      uri = URI("#{@registry_url}/gems")\n\n      request = Net::HTTP::Post.new(uri)\n      request["Authorization"] = api_key\n      request["Content-Type"] = "application/octet-stream"\n      request.body = File.binread(gem_path)\n\n      response = send_request(uri, request)\n\n      case response\n      when Net::HTTPSuccess\n        { success: true, message: response.body }\n      else\n        { success: false, message: response.body }\n      end\n    rescue StandardError => e\n      { success: false, message: e.message }\n    end\n\n    # Yank (unpublish) a version\n    def yank(name, version, api_key:)\n      uri = URI("#{@registry_url}/gems/yank")\n\n      request = Net::HTTP::Delete.new(uri)\n      request["Authorization"] = api_key\n      request.set_form_data(gem_name: name, version: version)\n\n      response = send_request(uri, request)\n\n      case response\n      when Net::HTTPSuccess\n        { success: true }\n      else\n        { success: false, message: response.body }\n      end\n    rescue StandardError => e\n      { success: false, message: e.message }\n    end\n\n    # Get API key info\n    def api_key_info(api_key)\n      uri = URI("#{@registry_url}/api_key.json")\n\n      request = Net::HTTP::Get.new(uri)\n      request["Authorization"] = api_key\n\n      response = send_request(uri, request)\n\n      case response\n      when Net::HTTPSuccess\n        JSON.parse(response.body)\n      end\n    rescue StandardError\n      nil\n    end\n\n    private\n\n    def fetch_json(uri)\n      cached = @http_cache[uri.to_s]\n      if cached && Time.now - cached[:time] < 300 # 5 min cache\n        return cached[:data]\n      end\n\n      response = Net::HTTP.get_response(uri)\n      return nil unless response.is_a?(Net::HTTPSuccess)\n\n      data = JSON.parse(response.body)\n      @http_cache[uri.to_s] = { data: data, time: Time.now }\n      data\n    rescue JSON::ParserError\n      nil\n    end\n\n    def download_file(uri, path)\n      Net::HTTP.start(uri.host, uri.port, use_ssl: uri.scheme == "https") do |http|\n        request = Net::HTTP::Get.new(uri)\n        http.request(request) do |response|\n          File.open(path, "wb") do |file|\n            response.read_body { |chunk| file.write(chunk) }\n          end\n        end\n      end\n    end\n\n    def send_request(uri, request)\n      Net::HTTP.start(uri.host, uri.port, use_ssl: uri.scheme == "https") do |http|\n        http.request(request)\n      end\n    end\n\n    def parse_dependencies(deps)\n      return {} unless deps\n\n      result = {}\n      (deps["runtime"] || []).each do |dep|\n        result[dep["name"]] = dep["requirements"]\n      end\n      result\n    end\n\n    def extract_types(_gem_path, target_dir)\n      # In a real implementation, would extract .d.trb files from gem\n      # For now, just create marker\n      File.write(File.join(target_dir, ".extracted"), Time.now.iso8601)\n    end\n  end\n\n  # Package registry (local or remote)\n  class PackageRegistry\n    attr_reader :packages, :local_path, :remote\n\n    def initialize(local_path: nil, remote_url: nil)\n      @local_path = local_path || ".trb-packages"\n      @remote_url = remote_url\n      @packages = {}\n      @remote = RemoteRegistry.new(registry_url: remote_url) if remote_url\n      FileUtils.mkdir_p(@local_path) if @local_path\n    end\n\n    # Register a package\n    def register(manifest)\n      @packages[manifest.name] ||= {}\n      @packages[manifest.name][manifest.version] = {\n        dependencies: manifest.dependencies,\n        types: manifest.types,\n      }\n    end\n\n    # Get available versions\n    def get_versions(name)\n      @packages[name]&.keys || []\n    end\n\n    # Get specific package info\n    def get_package(name, version)\n      return nil unless @packages[name]\n\n      if version == "*"\n        latest = get_versions(name).map { |v| SemanticVersion.parse(v) }.compact.max\n        return nil unless latest\n\n        version = latest.to_s\n      end\n\n      @packages[name][version]\n    end\n\n    # Load package from local directory\n    def load_local(package_dir)\n      manifest_path = File.join(package_dir, PackageManifest::MANIFEST_FILE)\n      return nil unless File.exist?(manifest_path)\n\n      manifest = PackageManifest.load(manifest_path)\n      register(manifest) if manifest&.valid?\n      manifest\n    end\n\n    # Install package to local cache\n    def install(name, version, target_dir = nil)\n      target = target_dir || File.join(@local_path, name, version)\n      FileUtils.mkdir_p(target)\n\n      pkg = get_package(name, version)\n      return nil unless pkg\n\n      # Copy type definitions\n      pkg[:types] || "**/*.d.trb"\n      # In real implementation, would download from registry\n\n      { name: name, version: version, path: target }\n    end\n\n    # Search packages by keyword\n    def search(keyword)\n      @packages.select do |name, versions|\n        name.include?(keyword) ||\n          versions.values.any? { |v| v[:keywords]&.include?(keyword) }\n      end.keys\n    end\n  end\n\n  # Package manager main class\n  class PackageManager\n    attr_reader :manifest, :registry, :resolver\n\n    def initialize(project_dir: ".")\n      @project_dir = project_dir\n      @manifest = PackageManifest.load(File.join(project_dir, PackageManifest::MANIFEST_FILE))\n      @registry = PackageRegistry.new(local_path: File.join(project_dir, ".trb-packages"))\n      @resolver = DependencyResolver.new(@registry)\n    end\n\n    # Initialize a new package\n    def init(name: nil)\n      @manifest = PackageManifest.new(\n        name: name || File.basename(@project_dir),\n        version: "0.1.0",\n        types: "lib/types/**/*.d.trb"\n      )\n      @manifest.save(File.join(@project_dir, PackageManifest::MANIFEST_FILE))\n      @manifest\n    end\n\n    # Add a dependency\n    def add(name, version = "*", dev: false)\n      ensure_manifest!\n\n      if dev\n        @manifest.add_dev_dependency(name, version)\n      else\n        @manifest.add_dependency(name, version)\n      end\n\n      @manifest.save(File.join(@project_dir, PackageManifest::MANIFEST_FILE))\n\n      # Resolve and install\n      install\n    end\n\n    # Remove a dependency\n    def remove(name)\n      ensure_manifest!\n      @manifest.remove_dependency(name)\n      @manifest.save(File.join(@project_dir, PackageManifest::MANIFEST_FILE))\n    end\n\n    # Install all dependencies\n    def install\n      ensure_manifest!\n\n      result = @resolver.resolve(@manifest)\n\n      if result[:conflicts].any?\n        raise "Dependency conflicts: #{result[:conflicts].join(", ")}"\n      end\n\n      installed = []\n      result[:resolved].each do |name, version|\n        pkg = @registry.install(name, version)\n        installed << pkg if pkg\n      end\n\n      # Generate lockfile\n      generate_lockfile(result[:resolved])\n\n      installed\n    end\n\n    # Update dependencies\n    def update(name = nil)\n      ensure_manifest!\n\n      if name\n        # Update specific package\n        current = @manifest.dependencies[name]\n        if current\n          @manifest.dependencies[name] = "*" # Get latest\n          result = @resolver.resolve(@manifest)\n          if result[:resolved][name]\n            @manifest.dependencies[name] = "^#{result[:resolved][name]}"\n            @manifest.save(File.join(@project_dir, PackageManifest::MANIFEST_FILE))\n          end\n        end\n      else\n        # Update all\n        @manifest.dependencies.each_key do |dep_name|\n          update(dep_name)\n        end\n      end\n\n      install\n    end\n\n    # List installed packages\n    def list\n      lockfile_path = File.join(@project_dir, ".trb-lock.json")\n      return {} unless File.exist?(lockfile_path)\n\n      JSON.parse(File.read(lockfile_path))\n    rescue JSON::ParserError\n      {}\n    end\n\n    # Publish package (stub - would integrate with real registry)\n    def publish\n      ensure_manifest!\n\n      unless @manifest.valid?\n        raise "Invalid manifest: missing name or version"\n      end\n\n      # Validate package\n      validate_package\n\n      # In real implementation, would upload to registry\n      {\n        name: @manifest.name,\n        version: @manifest.version,\n        status: :published,\n      }\n    end\n\n    # Create deprecation notice\n    def deprecate(version, message)\n      ensure_manifest!\n\n      {\n        package: @manifest.name,\n        version: version,\n        deprecated: true,\n        message: message,\n      }\n    end\n\n    private\n\n    def ensure_manifest!\n      unless @manifest\n        raise "No manifest found. Run \'init\' first."\n      end\n    end\n\n    def generate_lockfile(resolved)\n      lockfile = {\n        lockfileVersion: 1,\n        packages: resolved,\n        generatedAt: Time.now.iso8601,\n      }\n\n      File.write(\n        File.join(@project_dir, ".trb-lock.json"),\n        JSON.pretty_generate(lockfile)\n      )\n    end\n\n    def validate_package\n      errors = []\n\n      errors << "Missing package name" unless @manifest.name\n      errors << "Invalid version" unless SemanticVersion.parse(@manifest.version)\n\n      # Check for type files\n      types_pattern = @manifest.types || "**/*.d.trb"\n      types_files = Dir.glob(File.join(@project_dir, types_pattern))\n      errors << "No type definition files found" if types_files.empty?\n\n      raise errors.join(", ") unless errors.empty?\n    end\n  end\nend\n',"lib/t_ruby/parser.rb":'# frozen_string_literal: true\n\nmodule TRuby\n  # Enhanced Parser using Parser Combinator for complex type expressions\n  # Maintains backward compatibility with original Parser interface\n  class Parser\n    # Type names that are recognized as valid\n    VALID_TYPES = %w[String Integer Boolean Array Hash Symbol void nil].freeze\n\n    # Pattern for method/variable names that supports Unicode characters\n    # \\p{L} matches any Unicode letter, \\p{N} matches any Unicode number\n    IDENTIFIER_CHAR = \'[\\p{L}\\p{N}_]\'\n    # Method names can end with ? or !\n    METHOD_NAME_PATTERN = "#{IDENTIFIER_CHAR}+[?!]?".freeze\n    # Visibility modifiers for method definitions\n    VISIBILITY_PATTERN = \'(?:(?:private|protected|public)\\s+)?\'\n\n    # TODO: Replace regex-based parsing with TokenDeclarationParser\n    # See: lib/t_ruby/parser_combinator/token/token_declaration_parser.rb\n\n    attr_reader :source, :ir_program\n\n    def initialize(source, parse_body: true)\n      @source = source\n      @lines = source.split("\\n")\n      @parse_body = parse_body\n      @type_parser = ParserCombinator::TypeParser.new\n      @body_parser = ParserCombinator::TokenBodyParser.new if parse_body\n      @ir_program = nil\n    end\n\n    def parse\n      functions = []\n      type_aliases = []\n      interfaces = []\n      classes = []\n      i = 0\n\n      # Pre-detect heredoc regions to skip\n      heredoc_ranges = HeredocDetector.detect(@lines)\n\n      while i < @lines.length\n        # Skip lines inside heredoc content\n        if HeredocDetector.inside_heredoc?(i, heredoc_ranges)\n          i += 1\n          next\n        end\n\n        line = @lines[i]\n\n        # Match type alias definitions\n        if line.match?(/^\\s*type\\s+\\w+/)\n          alias_info = parse_type_alias(line)\n          type_aliases << alias_info if alias_info\n        end\n\n        # Match interface definitions\n        if line.match?(/^\\s*interface\\s+\\w+/)\n          interface_info, next_i = parse_interface(i)\n          if interface_info\n            interfaces << interface_info\n            i = next_i\n            next\n          end\n        end\n\n        # Match class definitions\n        if line.match?(/^\\s*class\\s+\\w+/)\n          class_info, next_i = parse_class(i)\n          if class_info\n            classes << class_info\n            i = next_i\n            next\n          end\n        end\n\n        # Match function definitions (top-level only, not inside class)\n        if line.match?(/^\\s*#{VISIBILITY_PATTERN}def\\s+#{IDENTIFIER_CHAR}+/)\n          func_info, next_i = parse_function_with_body(i)\n          if func_info\n            functions << func_info\n            i = next_i\n            next\n          end\n        end\n\n        i += 1\n      end\n\n      result = {\n        type: :success,\n        functions: functions,\n        type_aliases: type_aliases,\n        interfaces: interfaces,\n        classes: classes,\n      }\n\n      # Build IR\n      builder = IR::Builder.new\n      @ir_program = builder.build(result, source: @source)\n\n      result\n    rescue Scanner::ScanError => e\n      raise ParseError.new(e.message, line: e.line, column: e.column)\n    end\n\n    # Parse to IR directly (new API)\n    def parse_to_ir\n      parse unless @ir_program\n      @ir_program\n    end\n\n    # Parse a type expression using combinator\n    def parse_type(type_string)\n      result = @type_parser.parse(type_string)\n      result[:success] ? result[:type] : nil\n    end\n\n    private\n\n    # \ucd5c\uc0c1\uc704 \ud568\uc218\ub97c \ubcf8\ubb38\uae4c\uc9c0 \ud3ec\ud568\ud558\uc5ec \ud30c\uc2f1\n    def parse_function_with_body(start_index)\n      line = @lines[start_index]\n      func_info = parse_function_definition(line, line_number: start_index + 1)\n      return [nil, start_index] unless func_info\n\n      # Add location info (1-based line number, column is 1 + indentation)\n      def_indent = line.match(/^(\\s*)/)[1].length\n      func_info[:line] = start_index + 1\n      func_info[:column] = def_indent + 1\n\n      i = start_index + 1\n      body_start = i\n      body_end = i\n\n      # end \ud0a4\uc6cc\ub4dc \ucc3e\uae30\n      while i < @lines.length\n        current_line = @lines[i]\n\n        if current_line.match?(/^\\s*end\\s*$/)\n          end_indent = current_line.match(/^(\\s*)/)[1].length\n          if end_indent <= def_indent\n            body_end = i\n            break\n          end\n        end\n\n        i += 1\n      end\n\n      # \ubcf8\ubb38 \ud30c\uc2f1 (parse_body \uc635\uc158\uc774 \ud65c\uc131\ud654\ub41c \uacbd\uc6b0)\n      if @parse_body && @body_parser && body_start < body_end\n        func_info[:body_ir] = @body_parser.parse(@lines, body_start, body_end)\n        func_info[:body_range] = { start: body_start, end: body_end }\n      end\n\n      [func_info, i]\n    end\n\n    def parse_type_alias(line)\n      match = line.match(/^\\s*type\\s+(\\w+)\\s*=\\s*(.+?)\\s*$/)\n      return nil unless match\n\n      alias_name = match[1]\n      definition = match[2].strip\n\n      # Use combinator for complex type parsing\n      type_result = @type_parser.parse(definition)\n      if type_result[:success]\n        return {\n          name: alias_name,\n          definition: definition,\n          ir_type: type_result[:type],\n        }\n      end\n\n      {\n        name: alias_name,\n        definition: definition,\n      }\n    end\n\n    def parse_function_definition(line, line_number: 1) # rubocop:disable Lint/UnusedMethodArgument\n      # Match methods with or without parentheses\n      # def foo(params): Type   - with params and return type\n      # def foo(): Type         - no params but with return type\n      # def foo(params)         - with params, no return type\n      # def foo                  - no params, no return type\n      # Also supports visibility modifiers: private def, protected def, public def\n\n      match = line.match(/^\\s*(?:(private|protected|public)\\s+)?def\\s+(#{METHOD_NAME_PATTERN})\\s*(?:\\((.*?)\\))?\\s*(?::\\s*(.+?))?\\s*$/)\n      return nil unless match\n\n      visibility = match[1] ? match[1].to_sym : :public\n      function_name = match[2]\n      params_str = match[3] || ""\n      return_type_str = match[4]&.strip\n\n      # Validate return type if present\n      if return_type_str\n        return_type_str = validate_and_extract_type(return_type_str)\n      end\n\n      params = parse_parameters(params_str)\n\n      result = {\n        name: function_name,\n        params: params,\n        return_type: return_type_str,\n        visibility: visibility,\n      }\n\n      # Parse return type with combinator\n      if return_type_str\n        type_result = @type_parser.parse(return_type_str)\n        result[:ir_return_type] = type_result[:type] if type_result[:success]\n      end\n\n      result\n    end\n\n    # Validate type string and return nil if invalid\n    def validate_and_extract_type(type_str)\n      return nil if type_str.nil? || type_str.empty?\n\n      # Check for whitespace in simple type names that would be invalid\n      # Pattern: Capital letter followed by lowercase, then space, then more lowercase\n      # e.g., "Str ing", "Int eger", "Bool ean"\n      if type_str.match?(/^[A-Z][a-z]*\\s+[a-z]+/)\n        return nil\n      end\n\n      # Check for trailing operators\n      return nil if type_str.match?(/[|&]\\s*$/)\n\n      # Check for leading operators\n      return nil if type_str.match?(/^\\s*[|&]/)\n\n      # Check for unbalanced brackets\n      return nil if type_str.count("<") != type_str.count(">")\n      return nil if type_str.count("[") != type_str.count("]")\n      return nil if type_str.count("(") != type_str.count(")")\n\n      # Check for empty generic arguments\n      return nil if type_str.match?(/<\\s*>/)\n\n      type_str\n    end\n\n    def parse_parameters(params_str)\n      return [] if params_str.empty?\n\n      parameters = []\n      param_list = split_params(params_str)\n\n      param_list.each do |param|\n        param = param.strip\n\n        # 1. \ub354\ube14 \uc2a4\ud50c\ub7ab: **name: Type\n        if param.start_with?("**")\n          param_info = parse_double_splat_parameter(param)\n          parameters << param_info if param_info\n        # 2. \ud0a4\uc6cc\ub4dc \uc778\uc790 \uadf8\ub8f9: { ... } \ub610\ub294 { ... }: InterfaceName\n        elsif param.start_with?("{")\n          keyword_params = parse_keyword_args_group(param)\n          parameters.concat(keyword_params) if keyword_params\n        # 3. Hash \ub9ac\ud130\ub7f4: name: { ... }\n        elsif param.match?(/^\\w+:\\s*\\{/)\n          param_info = parse_hash_literal_parameter(param)\n          parameters << param_info if param_info\n        # 4. \uc77c\ubc18 \uc704\uce58 \uc778\uc790: name: Type \ub610\ub294 name: Type = default\n        else\n          param_info = parse_single_parameter(param)\n          parameters << param_info if param_info\n        end\n      end\n\n      parameters\n    end\n\n    def split_params(params_str)\n      # Handle nested generics, braces, brackets\n      result = []\n      current = ""\n      depth = 0\n      brace_depth = 0\n\n      params_str.each_char do |char|\n        case char\n        when "<", "[", "("\n          depth += 1\n          current += char\n        when ">", "]", ")"\n          depth -= 1\n          current += char\n        when "{"\n          brace_depth += 1\n          current += char\n        when "}"\n          brace_depth -= 1\n          current += char\n        when ","\n          if depth.zero? && brace_depth.zero?\n            result << current.strip\n            current = ""\n          else\n            current += char\n          end\n        else\n          current += char\n        end\n      end\n\n      result << current.strip unless current.empty?\n      result\n    end\n\n    # \ub354\ube14 \uc2a4\ud50c\ub7ab \ud30c\ub77c\ubbf8\ud130 \ud30c\uc2f1: **opts: Type\n    def parse_double_splat_parameter(param)\n      # **name: Type\n      match = param.match(/^\\*\\*(\\w+)(?::\\s*(.+?))?$/)\n      return nil unless match\n\n      param_name = match[1]\n      type_str = match[2]&.strip\n\n      result = {\n        name: param_name,\n        type: type_str,\n        kind: :keyrest,\n      }\n\n      if type_str\n        type_result = @type_parser.parse(type_str)\n        result[:ir_type] = type_result[:type] if type_result[:success]\n      end\n\n      result\n    end\n\n    # \ud0a4\uc6cc\ub4dc \uc778\uc790 \uadf8\ub8f9 \ud30c\uc2f1: { name: String, age: Integer = 0 } \ub610\ub294 { name:, age: 0 }: InterfaceName\n    def parse_keyword_args_group(param)\n      # { ... }: InterfaceName \ud615\ud0dc \ud655\uc778\n      # \ub610\ub294 { ... } \ub9cc \uc788\ub294 \ud615\ud0dc (\uc778\ub77c\uc778 \ud0c0\uc785)\n      interface_match = param.match(/^\\{(.+)\\}\\s*:\\s*(\\w+)\\s*$/)\n      inline_match = param.match(/^\\{(.+)\\}\\s*$/) unless interface_match\n\n      if interface_match\n        inner_content = interface_match[1]\n        interface_name = interface_match[2]\n        parse_keyword_args_with_interface(inner_content, interface_name)\n      elsif inline_match\n        inner_content = inline_match[1]\n        parse_keyword_args_inline(inner_content)\n      end\n    end\n\n    # interface \ucc38\uc870 \ud0a4\uc6cc\ub4dc \uc778\uc790 \ud30c\uc2f1: { name:, age: 0 }: UserParams\n    def parse_keyword_args_with_interface(inner_content, interface_name)\n      parameters = []\n      parts = split_keyword_args(inner_content)\n\n      parts.each do |part|\n        part = part.strip\n        next if part.empty?\n\n        # name: default_value \ub610\ub294 name: \ud615\ud0dc\n        next unless part.match?(/^(\\w+):\\s*(.*)$/)\n\n        match = part.match(/^(\\w+):\\s*(.*)$/)\n        param_name = match[1]\n        default_value = match[2].strip\n        default_value = nil if default_value.empty?\n\n        parameters << {\n          name: param_name,\n          type: nil, # interface\uc5d0\uc11c \ud0c0\uc785\uc744 \uac00\uc838\uc634\n          default_value: default_value,\n          kind: :keyword,\n          interface_ref: interface_name,\n        }\n      end\n\n      parameters\n    end\n\n    # \uc778\ub77c\uc778 \ud0c0\uc785 \ud0a4\uc6cc\ub4dc \uc778\uc790 \ud30c\uc2f1: { name: String, age: Integer = 0 }\n    def parse_keyword_args_inline(inner_content)\n      parameters = []\n      parts = split_keyword_args(inner_content)\n\n      parts.each do |part|\n        part = part.strip\n        next if part.empty?\n\n        # name: Type = default \ub610\ub294 name: Type \ud615\ud0dc\n        next unless part.match?(/^(\\w+):\\s*(.+)$/)\n\n        match = part.match(/^(\\w+):\\s*(.+)$/)\n        param_name = match[1]\n        type_and_default = match[2].strip\n\n        # Type = default \ubd84\ub9ac\n        type_str, default_value = split_type_and_default(type_and_default)\n\n        result = {\n          name: param_name,\n          type: type_str,\n          default_value: default_value,\n          kind: :keyword,\n        }\n\n        if type_str\n          type_result = @type_parser.parse(type_str)\n          result[:ir_type] = type_result[:type] if type_result[:success]\n        end\n\n        parameters << result\n      end\n\n      parameters\n    end\n\n    # \ud0a4\uc6cc\ub4dc \uc778\uc790 \ub0b4\ubd80\ub97c \ucf64\ub9c8\ub85c \ubd84\ub9ac (\uc911\ucca9\ub41c \uc81c\ub124\ub9ad/\ubc30\uc5f4/\ud574\uc2dc \uace0\ub824)\n    def split_keyword_args(content)\n      StringUtils.split_by_comma(content)\n    end\n\n    # \ud0c0\uc785\uacfc \uae30\ubcf8\uac12 \ubd84\ub9ac: "String = 0" -> ["String", "0"]\n    def split_type_and_default(type_and_default)\n      StringUtils.split_type_and_default(type_and_default)\n    end\n\n    # Hash \ub9ac\ud130\ub7f4 \ud30c\ub77c\ubbf8\ud130 \ud30c\uc2f1: config: { host: String, port: Integer }\n    def parse_hash_literal_parameter(param)\n      # name: { ... } \ub610\ub294 name: { ... }: InterfaceName\n      match = param.match(/^(\\w+):\\s*(\\{.+\\})(?::\\s*(\\w+))?$/)\n      return nil unless match\n\n      param_name = match[1]\n      hash_type = match[2]\n      interface_name = match[3]\n\n      result = {\n        name: param_name,\n        type: interface_name || hash_type,\n        kind: :required,\n        hash_type_def: hash_type, # \uc6d0\ubcf8 \ud574\uc2dc \ud0c0\uc785 \uc815\uc758 \uc800\uc7a5\n      }\n\n      result[:interface_ref] = interface_name if interface_name\n\n      result\n    end\n\n    def parse_single_parameter(param)\n      # name: Type = default \ub610\ub294 name: Type \ub610\ub294 name\n      # \uae30\ubcf8\uac12\uc774 \uc788\ub294 \uacbd\uc6b0 \uba3c\uc800 \ucc98\ub9ac\n      type_str = nil\n      default_value = nil\n\n      if param.include?(":")\n        match = param.match(/^(\\w+):\\s*(.+)$/)\n        return nil unless match\n\n        param_name = match[1]\n        type_and_default = match[2].strip\n        type_str, default_value = split_type_and_default(type_and_default)\n      else\n        # \ud0c0\uc785 \uc5c6\uc774 \uc774\ub984\ub9cc \uc788\ub294 \uacbd\uc6b0\n        param_name = param.strip\n      end\n\n      result = {\n        name: param_name,\n        type: type_str,\n        default_value: default_value,\n        kind: default_value ? :optional : :required,\n      }\n\n      # Parse type with combinator\n      if type_str\n        type_result = @type_parser.parse(type_str)\n        result[:ir_type] = type_result[:type] if type_result[:success]\n      end\n\n      result\n    end\n\n    def parse_class(start_index)\n      line = @lines[start_index]\n      match = line.match(/^\\s*class\\s+(\\w+)(?:\\s*<\\s*(\\w+))?/)\n      return [nil, start_index] unless match\n\n      class_name = match[1]\n      superclass = match[2]\n      methods = []\n      instance_vars = []\n      i = start_index + 1\n      class_indent = line.match(/^(\\s*)/)[1].length\n      class_end = i\n\n      # \uba3c\uc800 \ud074\ub798\uc2a4\uc758 \ub05d\uc744 \ucc3e\uc74c\n      temp_i = i\n      while temp_i < @lines.length\n        current_line = @lines[temp_i]\n        if current_line.match?(/^\\s*end\\s*$/)\n          end_indent = current_line.match(/^(\\s*)/)[1].length\n          if end_indent <= class_indent\n            class_end = temp_i\n            break\n          end\n        end\n        temp_i += 1\n      end\n\n      while i < class_end\n        current_line = @lines[i]\n\n        # Match method definitions inside class\n        if current_line.match?(/^\\s*#{VISIBILITY_PATTERN}def\\s+#{IDENTIFIER_CHAR}+/)\n          method_info, next_i = parse_method_in_class(i, class_end)\n          if method_info\n            methods << method_info\n            i = next_i\n            next\n          end\n        end\n\n        i += 1\n      end\n\n      # \uba54\uc11c\ub4dc \ubcf8\ubb38\uc5d0\uc11c \uc778\uc2a4\ud134\uc2a4 \ubcc0\uc218 \ucd94\ucd9c\n      methods.each do |method_info|\n        extract_instance_vars_from_body(method_info[:body_ir], instance_vars)\n      end\n\n      # Try to infer instance variable types from initialize parameters\n      init_method = methods.find { |m| m[:name] == "initialize" }\n      if init_method\n        instance_vars.each do |ivar|\n          # Find matching parameter (e.g., @name = name)\n          matching_param = init_method[:params]&.find { |p| p[:name] == ivar[:name] }\n          ivar[:type] = matching_param[:type] if matching_param && matching_param[:type]\n          ivar[:ir_type] = matching_param[:ir_type] if matching_param && matching_param[:ir_type]\n        end\n      end\n\n      [{\n        name: class_name,\n        superclass: superclass,\n        methods: methods,\n        instance_vars: instance_vars,\n      }, class_end,]\n    end\n\n    # \ud074\ub798\uc2a4 \ub0b4\ubd80\uc758 \uba54\uc11c\ub4dc\ub97c \ubcf8\ubb38\uae4c\uc9c0 \ud3ec\ud568\ud558\uc5ec \ud30c\uc2f1\n    def parse_method_in_class(start_index, class_end)\n      line = @lines[start_index]\n      method_info = parse_function_definition(line, line_number: start_index + 1)\n      return [nil, start_index] unless method_info\n\n      # Add location info (1-based line number, column is 1 + indentation)\n      def_indent = line.match(/^(\\s*)/)[1].length\n      method_info[:line] = start_index + 1\n      method_info[:column] = def_indent + 1\n\n      i = start_index + 1\n      body_start = i\n      body_end = i\n\n      # \uba54\uc11c\ub4dc\uc758 end \ud0a4\uc6cc\ub4dc \ucc3e\uae30\n      while i < class_end\n        current_line = @lines[i]\n\n        if current_line.match?(/^\\s*end\\s*$/)\n          end_indent = current_line.match(/^(\\s*)/)[1].length\n          if end_indent <= def_indent\n            body_end = i\n            break\n          end\n        end\n\n        i += 1\n      end\n\n      # \ubcf8\ubb38 \ud30c\uc2f1 (parse_body \uc635\uc158\uc774 \ud65c\uc131\ud654\ub41c \uacbd\uc6b0)\n      if @parse_body && @body_parser && body_start < body_end\n        method_info[:body_ir] = @body_parser.parse(@lines, body_start, body_end)\n        method_info[:body_range] = { start: body_start, end: body_end }\n      end\n\n      [method_info, i]\n    end\n\n    # \ubcf8\ubb38 IR\uc5d0\uc11c \uc778\uc2a4\ud134\uc2a4 \ubcc0\uc218 \ucd94\ucd9c\n    def extract_instance_vars_from_body(body_ir, instance_vars)\n      return unless body_ir.is_a?(IR::Block)\n\n      body_ir.statements.each do |stmt|\n        case stmt\n        when IR::Assignment\n          if stmt.target.start_with?("@") && !stmt.target.start_with?("@@")\n            ivar_name = stmt.target[1..] # @ \uc81c\uac70\n            unless instance_vars.any? { |iv| iv[:name] == ivar_name }\n              instance_vars << { name: ivar_name }\n            end\n          end\n        when IR::Block\n          extract_instance_vars_from_body(stmt, instance_vars)\n        end\n      end\n    end\n\n    def parse_interface(start_index)\n      line = @lines[start_index]\n      match = line.match(/^\\s*interface\\s+([\\w:]+)/)\n      return [nil, start_index] unless match\n\n      interface_name = match[1]\n      members = []\n      i = start_index + 1\n\n      while i < @lines.length\n        current_line = @lines[i]\n        break if current_line.match?(/^\\s*end\\s*$/)\n\n        if current_line.match?(/^\\s*[\\w!?]+\\s*:\\s*/)\n          member_match = current_line.match(/^\\s*([\\w!?]+)\\s*:\\s*(.+?)\\s*$/)\n          if member_match\n            member = {\n              name: member_match[1],\n              type: member_match[2].strip,\n            }\n\n            # Parse member type with combinator\n            type_result = @type_parser.parse(member[:type])\n            member[:ir_type] = type_result[:type] if type_result[:success]\n\n            members << member\n          end\n        end\n\n        i += 1\n      end\n\n      [{ name: interface_name, members: members }, i]\n    end\n  end\nend\n',"lib/t_ruby/parser_combinator/combinators/alternative.rb":"# frozen_string_literal: true\n\nmodule TRuby\n  module ParserCombinator\n    # Alternative: try first, if fails try second\n    class Alternative < Parser\n      def initialize(left, right)\n        @left = left\n        @right = right\n      end\n\n      def parse(input, position = 0)\n        result = @left.parse(input, position)\n        return result if result.success?\n\n        @right.parse(input, position)\n      end\n    end\n  end\nend\n","lib/t_ruby/parser_combinator/combinators/chain_left.rb":"# frozen_string_literal: true\n\nmodule TRuby\n  module ParserCombinator\n    # Chainl: left-associative chain\n    class ChainLeft < Parser\n      def initialize(term, op)\n        @term = term\n        @op = op\n      end\n\n      def parse(input, position = 0)\n        first = @term.parse(input, position)\n        return first if first.failure?\n\n        result = first.value\n        current_pos = first.position\n\n        loop do\n          op_result = @op.parse(input, current_pos)\n          break if op_result.failure?\n\n          term_result = @term.parse(input, op_result.position)\n          break if term_result.failure?\n\n          result = op_result.value.call(result, term_result.value)\n          current_pos = term_result.position\n        end\n\n        ParseResult.success(result, input, current_pos)\n      end\n    end\n  end\nend\n","lib/t_ruby/parser_combinator/combinators/choice.rb":'# frozen_string_literal: true\n\nmodule TRuby\n  module ParserCombinator\n    # Choice: try multiple parsers in order\n    class Choice < Parser\n      def initialize(*parsers)\n        @parsers = parsers\n      end\n\n      def parse(input, position = 0)\n        best_error = nil\n        best_position = position\n\n        @parsers.each do |parser|\n          result = parser.parse(input, position)\n          return result if result.success?\n\n          if result.position >= best_position\n            best_error = result.error\n            best_position = result.position\n          end\n        end\n\n        ParseResult.failure(best_error || "No alternative matched", input, best_position)\n      end\n    end\n  end\nend\n',"lib/t_ruby/parser_combinator/combinators/flat_map.rb":"# frozen_string_literal: true\n\nmodule TRuby\n  module ParserCombinator\n    # FlatMap (bind)\n    class FlatMap < Parser\n      def initialize(parser, func)\n        @parser = parser\n        @func = func\n      end\n\n      def parse(input, position = 0)\n        result = @parser.parse(input, position)\n        return result if result.failure?\n\n        next_parser = @func.call(result.value)\n        next_parser.parse(input, result.position)\n      end\n    end\n  end\nend\n","lib/t_ruby/parser_combinator/combinators/label.rb":'# frozen_string_literal: true\n\nmodule TRuby\n  module ParserCombinator\n    # Label for error messages\n    class Label < Parser\n      def initialize(parser, name)\n        @parser = parser\n        @name = name\n      end\n\n      def parse(input, position = 0)\n        result = @parser.parse(input, position)\n        if result.failure?\n          ParseResult.failure("Expected #{@name}", input, position)\n        else\n          result\n        end\n      end\n    end\n  end\nend\n',"lib/t_ruby/parser_combinator/combinators/lookahead.rb":"# frozen_string_literal: true\n\nmodule TRuby\n  module ParserCombinator\n    # Lookahead: check without consuming\n    class Lookahead < Parser\n      def initialize(parser)\n        @parser = parser\n      end\n\n      def parse(input, position = 0)\n        result = @parser.parse(input, position)\n        if result.success?\n          ParseResult.success(result.value, input, position)\n        else\n          result\n        end\n      end\n    end\n  end\nend\n","lib/t_ruby/parser_combinator/combinators/many.rb":"# frozen_string_literal: true\n\nmodule TRuby\n  module ParserCombinator\n    # Many: zero or more\n    class Many < Parser\n      def initialize(parser)\n        @parser = parser\n      end\n\n      def parse(input, position = 0)\n        results = []\n        current_pos = position\n\n        loop do\n          result = @parser.parse(input, current_pos)\n          break if result.failure?\n\n          results << result.value\n          break if result.position == current_pos # Prevent infinite loop\n\n          current_pos = result.position\n        end\n\n        ParseResult.success(results, input, current_pos)\n      end\n    end\n  end\nend\n","lib/t_ruby/parser_combinator/combinators/many1.rb":"# frozen_string_literal: true\n\nmodule TRuby\n  module ParserCombinator\n    # Many1: one or more\n    class Many1 < Parser\n      def initialize(parser)\n        @parser = parser\n      end\n\n      def parse(input, position = 0)\n        first = @parser.parse(input, position)\n        return first if first.failure?\n\n        results = [first.value]\n        current_pos = first.position\n\n        loop do\n          result = @parser.parse(input, current_pos)\n          break if result.failure?\n\n          results << result.value\n          break if result.position == current_pos\n\n          current_pos = result.position\n        end\n\n        ParseResult.success(results, input, current_pos)\n      end\n    end\n  end\nend\n","lib/t_ruby/parser_combinator/combinators/map.rb":"# frozen_string_literal: true\n\nmodule TRuby\n  module ParserCombinator\n    # Map result\n    class Map < Parser\n      def initialize(parser, func)\n        @parser = parser\n        @func = func\n      end\n\n      def parse(input, position = 0)\n        @parser.parse(input, position).map(&@func)\n      end\n    end\n  end\nend\n","lib/t_ruby/parser_combinator/combinators/not_followed_by.rb":'# frozen_string_literal: true\n\nmodule TRuby\n  module ParserCombinator\n    # Not followed by\n    class NotFollowedBy < Parser\n      def initialize(parser)\n        @parser = parser\n      end\n\n      def parse(input, position = 0)\n        result = @parser.parse(input, position)\n        if result.failure?\n          ParseResult.success(nil, input, position)\n        else\n          ParseResult.failure("Unexpected match", input, position)\n        end\n      end\n    end\n  end\nend\n',"lib/t_ruby/parser_combinator/combinators/optional.rb":"# frozen_string_literal: true\n\nmodule TRuby\n  module ParserCombinator\n    # Optional: zero or one\n    class Optional < Parser\n      def initialize(parser)\n        @parser = parser\n      end\n\n      def parse(input, position = 0)\n        result = @parser.parse(input, position)\n        if result.success?\n          result\n        else\n          ParseResult.success(nil, input, position)\n        end\n      end\n    end\n  end\nend\n","lib/t_ruby/parser_combinator/combinators/sep_by.rb":"# frozen_string_literal: true\n\nmodule TRuby\n  module ParserCombinator\n    # Separated by delimiter\n    class SepBy < Parser\n      def initialize(parser, delimiter)\n        @parser = parser\n        @delimiter = delimiter\n      end\n\n      def parse(input, position = 0)\n        first = @parser.parse(input, position)\n        return ParseResult.success([], input, position) if first.failure?\n\n        results = [first.value]\n        current_pos = first.position\n\n        loop do\n          delim_result = @delimiter.parse(input, current_pos)\n          break if delim_result.failure?\n\n          item_result = @parser.parse(input, delim_result.position)\n          break if item_result.failure?\n\n          results << item_result.value\n          current_pos = item_result.position\n        end\n\n        ParseResult.success(results, input, current_pos)\n      end\n    end\n  end\nend\n","lib/t_ruby/parser_combinator/combinators/sep_by1.rb":"# frozen_string_literal: true\n\nmodule TRuby\n  module ParserCombinator\n    # Separated by 1 (at least one)\n    class SepBy1 < Parser\n      def initialize(parser, delimiter)\n        @parser = parser\n        @delimiter = delimiter\n      end\n\n      def parse(input, position = 0)\n        first = @parser.parse(input, position)\n        return first if first.failure?\n\n        results = [first.value]\n        current_pos = first.position\n\n        loop do\n          delim_result = @delimiter.parse(input, current_pos)\n          break if delim_result.failure?\n\n          item_result = @parser.parse(input, delim_result.position)\n          break if item_result.failure?\n\n          results << item_result.value\n          current_pos = item_result.position\n        end\n\n        ParseResult.success(results, input, current_pos)\n      end\n    end\n  end\nend\n","lib/t_ruby/parser_combinator/combinators/sequence.rb":"# frozen_string_literal: true\n\nmodule TRuby\n  module ParserCombinator\n    # Sequence two parsers\n    class Sequence < Parser\n      def initialize(left, right)\n        @left = left\n        @right = right\n      end\n\n      def parse(input, position = 0)\n        result1 = @left.parse(input, position)\n        return result1 if result1.failure?\n\n        result2 = @right.parse(input, result1.position)\n        return result2 if result2.failure?\n\n        ParseResult.success([result1.value, result2.value], input, result2.position)\n      end\n    end\n  end\nend\n","lib/t_ruby/parser_combinator/combinators/skip_right.rb":"# frozen_string_literal: true\n\nmodule TRuby\n  module ParserCombinator\n    # Skip right: parse both, return left\n    class SkipRight < Parser\n      def initialize(left, right)\n        @left = left\n        @right = right\n      end\n\n      def parse(input, position = 0)\n        result1 = @left.parse(input, position)\n        return result1 if result1.failure?\n\n        result2 = @right.parse(input, result1.position)\n        return result2 if result2.failure?\n\n        ParseResult.success(result1.value, input, result2.position)\n      end\n    end\n  end\nend\n","lib/t_ruby/parser_combinator/declaration_parser.rb":'# frozen_string_literal: true\n\nmodule TRuby\n  module ParserCombinator\n    # Declaration Parser - Parse T-Ruby declarations\n    class DeclarationParser\n      include DSL\n\n      def initialize\n        @type_parser = TypeParser.new\n        build_parsers\n      end\n\n      def parse(input)\n        result = @declaration.parse(input.strip)\n        if result.success?\n          { success: true, declarations: result.value }\n        else\n          { success: false, error: result.error, position: result.position }\n        end\n      end\n\n      def parse_file(input)\n        result = @program.parse(input)\n        if result.success?\n          { success: true, declarations: result.value.compact }\n        else\n          { success: false, error: result.error, position: result.position }\n        end\n      end\n\n      private\n\n      def build_parsers\n        # Type expression (delegate to TypeParser)\n        lazy { parse_type_inline }\n\n        # Keywords\n        kw_type = lexeme(string("type"))\n        kw_interface = lexeme(string("interface"))\n        kw_def = lexeme(string("def"))\n        kw_end = lexeme(string("end"))\n        lexeme(string("class"))\n        lexeme(string("module"))\n\n        # Type alias: type Name = Definition\n        type_alias = (\n          kw_type >>\n          lexeme(identifier) <<\n          lexeme(char("=")) >>\n          regex(/[^\\n]+/).map(&:strip)\n        ).map do |((_, name), definition)|\n          type_result = @type_parser.parse(definition)\n          if type_result[:success]\n            IR::TypeAlias.new(name: name, definition: type_result[:type])\n          end\n        end\n\n        # Interface member: name: Type\n        interface_member = (\n          lexeme(identifier) <<\n          lexeme(char(":")) >>\n          regex(/[^\\n]+/).map(&:strip)\n        ).map do |(name, type_str)|\n          type_result = @type_parser.parse(type_str)\n          if type_result[:success]\n            IR::InterfaceMember.new(name: name, type_signature: type_result[:type])\n          end\n        end\n\n        # Interface: interface Name ... end\n        interface_body = (interface_member << (newline | spaces)).many\n\n        interface_decl = (\n          kw_interface >>\n          lexeme(identifier) <<\n          (newline | spaces) >>\n          interface_body <<\n          kw_end\n        ).map do |((_, name), members)|\n          IR::Interface.new(name: name, members: members.compact)\n        end\n\n        # Parameter: name: Type or name\n        param = (\n          identifier >>\n          (lexeme(char(":")) >> regex(/[^,)]+/).map(&:strip)).optional\n        ).map do |(name, type_str)|\n          type_node = if type_str\n                        type_str_val = type_str.is_a?(Array) ? type_str.last : type_str\n                        result = @type_parser.parse(type_str_val)\n                        result[:success] ? result[:type] : nil\n                      end\n          IR::Parameter.new(name: name, type_annotation: type_node)\n        end\n\n        # Parameters list\n        params_list = (\n          lexeme(char("(")) >>\n          param.sep_by(lexeme(char(","))) <<\n          lexeme(char(")"))\n        ).map { |(_, params)| params }\n\n        # Return type annotation\n        return_type = (\n          lexeme(char(":")) >>\n          regex(/[^\\n]+/).map(&:strip)\n        ).map { |(_, type_str)| type_str }.optional\n\n        # Method definition: def name(params): ReturnType\n        method_def = (\n          kw_def >>\n          identifier >>\n          params_list.optional >>\n          return_type\n        ).map do |(((_, name), params), ret_str)|\n          ret_type = if ret_str\n                       result = @type_parser.parse(ret_str)\n                       result[:success] ? result[:type] : nil\n                     end\n          IR::MethodDef.new(\n            name: name,\n            params: params || [],\n            return_type: ret_type\n          )\n        end\n\n        # Any declaration\n        @declaration = choice(\n          type_alias,\n          interface_decl,\n          method_def\n        )\n\n        # Line (declaration or empty)\n        line = (@declaration << (newline | eof)) | (spaces >> newline).map { nil }\n\n        # Program (multiple declarations)\n        @program = line.many\n      end\n\n      def parse_type_inline\n        Lazy.new { @type_parser.instance_variable_get(:@type_expr) }\n      end\n    end\n  end\nend\n',"lib/t_ruby/parser_combinator/dsl.rb":'# frozen_string_literal: true\n\nmodule TRuby\n  module ParserCombinator\n    # DSL Module - Convenience methods\n    module DSL\n      def literal(str)\n        Literal.new(str)\n      end\n\n      def regex(pattern, description = nil)\n        Regex.new(pattern, description)\n      end\n\n      def satisfy(description = "character", &predicate)\n        Satisfy.new(predicate, description)\n      end\n\n      def char(c)\n        Literal.new(c)\n      end\n\n      def string(str)\n        Literal.new(str)\n      end\n\n      def eof\n        EndOfInput.new\n      end\n\n      def pure(value)\n        Pure.new(value)\n      end\n\n      def fail(message)\n        Fail.new(message)\n      end\n\n      def lazy(&)\n        Lazy.new(&)\n      end\n\n      def choice(*parsers)\n        Choice.new(*parsers)\n      end\n\n      def sequence(*parsers)\n        parsers.reduce { |acc, p| acc >> p }\n      end\n\n      # Common character parsers\n      def digit\n        satisfy("digit") { |c| c =~ /[0-9]/ }\n      end\n\n      def letter\n        satisfy("letter") { |c| c =~ /[a-zA-Z]/ }\n      end\n\n      def alphanumeric\n        satisfy("alphanumeric") { |c| c =~ /[a-zA-Z0-9]/ }\n      end\n\n      def whitespace\n        satisfy("whitespace") { |c| c =~ /\\s/ }\n      end\n\n      def spaces\n        whitespace.many.map(&:join)\n      end\n\n      def spaces1\n        whitespace.many1.map(&:join)\n      end\n\n      def newline\n        char("\\n") | string("\\r\\n")\n      end\n\n      def identifier\n        (letter >> (alphanumeric | char("_")).many).map do |(first, rest)|\n          first + rest.join\n        end\n      end\n\n      def integer\n        (char("-").optional >> digit.many1).map do |(sign, digits)|\n          num = digits.join.to_i\n          sign ? -num : num\n        end\n      end\n\n      def float\n        regex(/-?\\d+\\.\\d+/, "float").map(&:to_f)\n      end\n\n      def quoted_string(quote = \'"\')\n        content = satisfy("string character") { |c| c != quote && c != "\\\\" }\n        escape = (char("\\\\") >> satisfy("escape char")).map { |(_bs, c)| c }\n\n        (char(quote) >> (content | escape).many.map(&:join) << char(quote)).map { |(_, str)| str }\n      end\n\n      # Skip whitespace around parser\n      def lexeme(parser)\n        (spaces >> parser << spaces).map { |(_, val)| val }\n      end\n\n      # Chain for left-associative operators\n      def chainl(term, op)\n        ChainLeft.new(term, op)\n      end\n    end\n  end\nend\n',"lib/t_ruby/parser_combinator/parse_error.rb":'# frozen_string_literal: true\n\nmodule TRuby\n  module ParserCombinator\n    # Error Reporting\n    class ParseError\n      attr_reader :message, :position, :line, :column, :input\n\n      def initialize(message:, position:, input:)\n        @message = message\n        @position = position\n        @input = input\n        @line, @column = calculate_line_column\n      end\n\n      def to_s\n        "Parse error at line #{@line}, column #{@column}: #{@message}"\n      end\n\n      def context(lines_before: 2, lines_after: 1)\n        input_lines = @input.split("\\n")\n        start_line = [@line - lines_before - 1, 0].max\n        end_line = [@line + lines_after - 1, input_lines.length - 1].min\n\n        result = []\n        (start_line..end_line).each do |i|\n          prefix = i == @line - 1 ? ">>> " : "    "\n          result << "#{prefix}#{i + 1}: #{input_lines[i]}"\n\n          if i == @line - 1\n            result << "    #{" " * (@column + @line.to_s.length + 1)}^"\n          end\n        end\n\n        result.join("\\n")\n      end\n\n      private\n\n      def calculate_line_column\n        lines = @input[0...@position].split("\\n", -1)\n        line = lines.length\n        column = lines.last&.length || 0\n        [line, column + 1]\n      end\n    end\n  end\nend\n',"lib/t_ruby/parser_combinator/parse_result.rb":'# frozen_string_literal: true\n\nmodule TRuby\n  module ParserCombinator\n    # Parse result - either success or failure\n    class ParseResult\n      attr_reader :value, :remaining, :position, :error\n\n      def initialize(success:, value: nil, remaining: "", position: 0, error: nil)\n        @success = success\n        @value = value\n        @remaining = remaining\n        @position = position\n        @error = error\n      end\n\n      def success?\n        @success\n      end\n\n      def failure?\n        !@success\n      end\n\n      def self.success(value, remaining, position)\n        new(success: true, value: value, remaining: remaining, position: position)\n      end\n\n      def self.failure(error, remaining, position)\n        new(success: false, error: error, remaining: remaining, position: position)\n      end\n\n      def map\n        return self if failure?\n\n        ParseResult.success(yield(value), remaining, position)\n      end\n\n      def flat_map\n        return self if failure?\n\n        yield(value, remaining, position)\n      end\n    end\n  end\nend\n',"lib/t_ruby/parser_combinator/parser.rb":"# frozen_string_literal: true\n\nmodule TRuby\n  module ParserCombinator\n    # Base parser class for string-based parsing\n    class Parser\n      def parse(input, position = 0)\n        raise NotImplementedError\n      end\n\n      # Combinators as methods\n\n      # Sequence: run this parser, then the other\n      def >>(other)\n        Sequence.new(self, other)\n      end\n\n      # Alternative: try this parser, if it fails try the other\n      def |(other)\n        Alternative.new(self, other)\n      end\n\n      # Map: transform the result\n      def map(&block)\n        Map.new(self, block)\n      end\n\n      # FlatMap: transform with another parser\n      def flat_map(&block)\n        FlatMap.new(self, block)\n      end\n\n      # Many: zero or more repetitions\n      def many\n        Many.new(self)\n      end\n\n      # Many1: one or more repetitions\n      def many1\n        Many1.new(self)\n      end\n\n      # Optional: zero or one\n      def optional\n        Optional.new(self)\n      end\n\n      # Separated by: parse items separated by delimiter\n      def sep_by(delimiter)\n        SepBy.new(self, delimiter)\n      end\n\n      # Separated by 1: at least one item\n      def sep_by1(delimiter)\n        SepBy1.new(self, delimiter)\n      end\n\n      # Between: parse between left and right delimiters\n      def between(left, right)\n        (left >> self << right).map { |(_, val)| val }\n      end\n\n      # Skip right: parse both, keep left result\n      def <<(other)\n        SkipRight.new(self, other)\n      end\n\n      # Label: add a descriptive label for error messages\n      def label(name)\n        Label.new(self, name)\n      end\n\n      # Lookahead: check without consuming\n      def lookahead\n        Lookahead.new(self)\n      end\n\n      # Not: succeed only if parser fails\n      def not_followed_by\n        NotFollowedBy.new(self)\n      end\n    end\n  end\nend\n","lib/t_ruby/parser_combinator/primitives/end_of_input.rb":'# frozen_string_literal: true\n\nmodule TRuby\n  module ParserCombinator\n    # Parse end of input\n    class EndOfInput < Parser\n      def parse(input, position = 0)\n        if position >= input.length\n          ParseResult.success(nil, input, position)\n        else\n          ParseResult.failure("Expected end of input", input, position)\n        end\n      end\n    end\n  end\nend\n',"lib/t_ruby/parser_combinator/primitives/fail.rb":"# frozen_string_literal: true\n\nmodule TRuby\n  module ParserCombinator\n    # Always fail\n    class Fail < Parser\n      def initialize(message)\n        @message = message\n      end\n\n      def parse(input, position = 0)\n        ParseResult.failure(@message, input, position)\n      end\n    end\n  end\nend\n","lib/t_ruby/parser_combinator/primitives/lazy.rb":"# frozen_string_literal: true\n\nmodule TRuby\n  module ParserCombinator\n    # Lazy parser (for recursive grammars)\n    class Lazy < Parser\n      def initialize(&block)\n        @block = block\n        @parser = nil\n      end\n\n      def parse(input, position = 0)\n        @parser ||= @block.call\n        @parser.parse(input, position)\n      end\n    end\n  end\nend\n","lib/t_ruby/parser_combinator/primitives/literal.rb":"# frozen_string_literal: true\n\nmodule TRuby\n  module ParserCombinator\n    # Parse a literal string\n    class Literal < Parser\n      def initialize(string)\n        @string = string\n      end\n\n      def parse(input, position = 0)\n        remaining = input[position..]\n        if remaining&.start_with?(@string)\n          ParseResult.success(@string, input, position + @string.length)\n        else\n          ParseResult.failure(\"Expected '#{@string}'\", input, position)\n        end\n      end\n    end\n  end\nend\n","lib/t_ruby/parser_combinator/primitives/pure.rb":"# frozen_string_literal: true\n\nmodule TRuby\n  module ParserCombinator\n    # Always succeed with a value\n    class Pure < Parser\n      def initialize(value)\n        @value = value\n      end\n\n      def parse(input, position = 0)\n        ParseResult.success(@value, input, position)\n      end\n    end\n  end\nend\n","lib/t_ruby/parser_combinator/primitives/regex.rb":'# frozen_string_literal: true\n\nmodule TRuby\n  module ParserCombinator\n    # Parse using regex\n    class Regex < Parser\n      def initialize(pattern, description = nil)\n        @pattern = pattern.is_a?(Regexp) ? pattern : Regexp.new("^#{pattern}")\n        @description = description || @pattern.inspect\n      end\n\n      def parse(input, position = 0)\n        remaining = input[position..]\n        match = @pattern.match(remaining)\n\n        if match&.begin(0)&.zero?\n          matched = match[0]\n          ParseResult.success(matched, input, position + matched.length)\n        else\n          ParseResult.failure("Expected #{@description}", input, position)\n        end\n      end\n    end\n  end\nend\n',"lib/t_ruby/parser_combinator/primitives/satisfy.rb":'# frozen_string_literal: true\n\nmodule TRuby\n  module ParserCombinator\n    # Parse a single character matching predicate\n    class Satisfy < Parser\n      def initialize(predicate, description = "character")\n        @predicate = predicate\n        @description = description\n      end\n\n      def parse(input, position = 0)\n        if position < input.length && @predicate.call(input[position])\n          ParseResult.success(input[position], input, position + 1)\n        else\n          ParseResult.failure("Expected #{@description}", input, position)\n        end\n      end\n    end\n  end\nend\n',"lib/t_ruby/parser_combinator/token/expression_parser.rb":'# frozen_string_literal: true\n\nrequire "set"\n\nmodule TRuby\n  module ParserCombinator\n    # Expression Parser - Parse expressions into IR nodes\n    # Uses Pratt parser (operator precedence parsing) for correct precedence\n    class ExpressionParser\n      include TokenDSL\n\n      # Operator precedence levels (higher = binds tighter)\n      PRECEDENCE = {\n        or_or: 1,      # ||\n        and_and: 2,    # &&\n        eq_eq: 3,      # ==\n        bang_eq: 3,    # !=\n        lt: 4,         # <\n        gt: 4,         # >\n        lt_eq: 4,      # <=\n        gt_eq: 4,      # >=\n        spaceship: 4,  # <=>\n        pipe: 5,       # | (bitwise or)\n        amp: 6,        # & (bitwise and)\n        plus: 7,       # +\n        minus: 7,      # -\n        star: 8,       # *\n        slash: 8,      # /\n        percent: 8,    # %\n        star_star: 9,  # ** (right-associative)\n      }.freeze\n\n      # Right-associative operators\n      RIGHT_ASSOC = Set.new([:star_star]).freeze\n\n      # Token type to operator symbol mapping\n      OPERATOR_SYMBOLS = {\n        or_or: :"||",\n        and_and: :"&&",\n        eq_eq: :==,\n        bang_eq: :!=,\n        lt: :<,\n        gt: :>,\n        lt_eq: :<=,\n        gt_eq: :>=,\n        spaceship: :<=>,\n        plus: :+,\n        minus: :-,\n        star: :*,\n        slash: :/,\n        percent: :%,\n        star_star: :**,\n        pipe: :|,\n        amp: :&,\n      }.freeze\n\n      def parse_expression(tokens, position = 0)\n        parse_precedence(tokens, position, 0)\n      end\n\n      private\n\n      def parse_precedence(tokens, position, min_precedence)\n        result = parse_unary(tokens, position)\n        return result if result.failure?\n\n        left = result.value\n        pos = result.position\n\n        loop do\n          break if pos >= tokens.length || tokens[pos].type == :eof\n\n          operator_type = tokens[pos].type\n          precedence = PRECEDENCE[operator_type]\n          break unless precedence && precedence >= min_precedence\n\n          pos += 1 # consume operator\n\n          # Handle right associativity\n          next_min = RIGHT_ASSOC.include?(operator_type) ? precedence : precedence + 1\n          right_result = parse_precedence(tokens, pos, next_min)\n          return right_result if right_result.failure?\n\n          right = right_result.value\n          pos = right_result.position\n\n          left = IR::BinaryOp.new(\n            operator: OPERATOR_SYMBOLS[operator_type],\n            left: left,\n            right: right\n          )\n        end\n\n        # \uc0bc\ud56d \uc5f0\uc0b0\uc790: condition ? then_branch : else_branch\n        if pos < tokens.length && tokens[pos].type == :question\n          pos += 1 # consume \'?\'\n\n          then_result = parse_expression(tokens, pos)\n          return then_result if then_result.failure?\n\n          pos = then_result.position\n\n          unless tokens[pos]&.type == :colon\n            return TokenParseResult.failure("Expected \':\' in ternary operator", tokens, pos)\n          end\n\n          pos += 1 # consume \':\'\n\n          else_result = parse_expression(tokens, pos)\n          return else_result if else_result.failure?\n\n          left = IR::Conditional.new(\n            kind: :ternary,\n            condition: left,\n            then_branch: then_result.value,\n            else_branch: else_result.value\n          )\n          pos = else_result.position\n        end\n\n        TokenParseResult.success(left, tokens, pos)\n      end\n\n      def parse_unary(tokens, position)\n        return TokenParseResult.failure("End of input", tokens, position) if position >= tokens.length\n\n        token = tokens[position]\n\n        case token.type\n        when :bang\n          result = parse_unary(tokens, position + 1)\n          return result if result.failure?\n\n          node = IR::UnaryOp.new(operator: :!, operand: result.value)\n          TokenParseResult.success(node, tokens, result.position)\n        when :minus\n          result = parse_unary(tokens, position + 1)\n          return result if result.failure?\n\n          # For negative number literals, we could fold them\n          node = if result.value.is_a?(IR::Literal) && result.value.literal_type == :integer\n                   IR::Literal.new(value: -result.value.value, literal_type: :integer)\n                 elsif result.value.is_a?(IR::Literal) && result.value.literal_type == :float\n                   IR::Literal.new(value: -result.value.value, literal_type: :float)\n                 else\n                   IR::UnaryOp.new(operator: :-, operand: result.value)\n                 end\n          TokenParseResult.success(node, tokens, result.position)\n        else\n          parse_postfix(tokens, position)\n        end\n      end\n\n      def parse_postfix(tokens, position)\n        result = parse_primary(tokens, position)\n        return result if result.failure?\n\n        left = result.value\n        pos = result.position\n\n        loop do\n          break if pos >= tokens.length || tokens[pos].type == :eof\n\n          case tokens[pos].type\n          when :dot\n            # Method call with receiver: obj.method or obj.method(args)\n            pos += 1\n            return TokenParseResult.failure("Expected method name after \'.\'", tokens, pos) if pos >= tokens.length\n\n            method_token = tokens[pos]\n            unless method_token.type == :identifier || keywords.key?(method_token.value)\n              return TokenParseResult.failure("Expected method name", tokens, pos)\n            end\n\n            method_name = method_token.value\n            pos += 1\n\n            # Check for arguments\n            args = []\n            if pos < tokens.length && tokens[pos].type == :lparen\n              args_result = parse_arguments(tokens, pos)\n              return args_result if args_result.failure?\n\n              args = args_result.value\n              pos = args_result.position\n            end\n\n            left = IR::MethodCall.new(\n              receiver: left,\n              method_name: method_name,\n              arguments: args\n            )\n          when :lbracket\n            # Array access: arr[index]\n            pos += 1\n            index_result = parse_expression(tokens, pos)\n            return index_result if index_result.failure?\n\n            pos = index_result.position\n            return TokenParseResult.failure("Expected \']\'", tokens, pos) unless tokens[pos]&.type == :rbracket\n\n            pos += 1\n\n            left = IR::MethodCall.new(\n              receiver: left,\n              method_name: "[]",\n              arguments: [index_result.value]\n            )\n          when :lparen\n            # Function call without explicit receiver (left is identifier -> method call)\n            break unless left.is_a?(IR::VariableRef) && left.scope == :local\n\n            args_result = parse_arguments(tokens, pos)\n            return args_result if args_result.failure?\n\n            left = IR::MethodCall.new(\n              method_name: left.name,\n              arguments: args_result.value\n            )\n            pos = args_result.position\n\n          else\n            break\n          end\n        end\n\n        TokenParseResult.success(left, tokens, pos)\n      end\n\n      def parse_primary(tokens, position)\n        return TokenParseResult.failure("End of input", tokens, position) if position >= tokens.length\n\n        token = tokens[position]\n\n        case token.type\n        when :integer\n          node = IR::Literal.new(value: token.value.to_i, literal_type: :integer)\n          TokenParseResult.success(node, tokens, position + 1)\n\n        when :float\n          node = IR::Literal.new(value: token.value.to_f, literal_type: :float)\n          TokenParseResult.success(node, tokens, position + 1)\n\n        when :string\n          # Remove quotes from string value\n          value = token.value[1..-2]\n          node = IR::Literal.new(value: value, literal_type: :string)\n          TokenParseResult.success(node, tokens, position + 1)\n\n        when :string_start\n          # Interpolated string: string_start, string_content*, string_end\n          parse_interpolated_string(tokens, position)\n\n        when :symbol\n          # Remove : from symbol value\n          value = token.value[1..].to_sym\n          node = IR::Literal.new(value: value, literal_type: :symbol)\n          TokenParseResult.success(node, tokens, position + 1)\n\n        when true\n          node = IR::Literal.new(value: true, literal_type: :boolean)\n          TokenParseResult.success(node, tokens, position + 1)\n\n        when false\n          node = IR::Literal.new(value: false, literal_type: :boolean)\n          TokenParseResult.success(node, tokens, position + 1)\n\n        when :nil\n          node = IR::Literal.new(value: nil, literal_type: :nil)\n          TokenParseResult.success(node, tokens, position + 1)\n\n        when :identifier\n          node = IR::VariableRef.new(name: token.value, scope: :local)\n          TokenParseResult.success(node, tokens, position + 1)\n\n        when :constant\n          node = IR::VariableRef.new(name: token.value, scope: :constant)\n          TokenParseResult.success(node, tokens, position + 1)\n\n        when :ivar\n          node = IR::VariableRef.new(name: token.value, scope: :instance)\n          TokenParseResult.success(node, tokens, position + 1)\n\n        when :cvar\n          node = IR::VariableRef.new(name: token.value, scope: :class)\n          TokenParseResult.success(node, tokens, position + 1)\n\n        when :gvar\n          node = IR::VariableRef.new(name: token.value, scope: :global)\n          TokenParseResult.success(node, tokens, position + 1)\n\n        when :lparen\n          # Parenthesized expression\n          result = parse_expression(tokens, position + 1)\n          return result if result.failure?\n\n          pos = result.position\n          return TokenParseResult.failure("Expected \')\'", tokens, pos) unless tokens[pos]&.type == :rparen\n\n          TokenParseResult.success(result.value, tokens, pos + 1)\n\n        when :lbracket\n          # Array literal\n          parse_array_literal(tokens, position)\n\n        when :lbrace\n          # Hash literal\n          parse_hash_literal(tokens, position)\n\n        else\n          TokenParseResult.failure("Unexpected token: #{token.type}", tokens, position)\n        end\n      end\n\n      def parse_arguments(tokens, position)\n        return TokenParseResult.failure("Expected \'(\'", tokens, position) unless tokens[position]&.type == :lparen\n\n        position += 1\n\n        args = []\n\n        # Empty arguments\n        if tokens[position]&.type == :rparen\n          return TokenParseResult.success(args, tokens, position + 1)\n        end\n\n        # Parse first argument\n        result = parse_argument(tokens, position)\n        return result if result.failure?\n\n        args << result.value\n        position = result.position\n\n        # Parse remaining arguments\n        while tokens[position]&.type == :comma\n          position += 1\n          result = parse_argument(tokens, position)\n          return result if result.failure?\n\n          args << result.value\n          position = result.position\n        end\n\n        return TokenParseResult.failure("Expected \')\'", tokens, position) unless tokens[position]&.type == :rparen\n\n        TokenParseResult.success(args, tokens, position + 1)\n      end\n\n      # Parse a single argument (handles splat, double splat, and keyword arguments)\n      def parse_argument(tokens, position)\n        # Double splat argument: **expr\n        if tokens[position]&.type == :star_star\n          position += 1\n          expr_result = parse_expression(tokens, position)\n          return expr_result if expr_result.failure?\n\n          # Wrap in a splat node (we\'ll use MethodCall with special name for now)\n          node = IR::MethodCall.new(\n            method_name: "**",\n            arguments: [expr_result.value]\n          )\n          return TokenParseResult.success(node, tokens, expr_result.position)\n        end\n\n        # Single splat argument: *expr\n        if tokens[position]&.type == :star\n          position += 1\n          expr_result = parse_expression(tokens, position)\n          return expr_result if expr_result.failure?\n\n          node = IR::MethodCall.new(\n            method_name: "*",\n            arguments: [expr_result.value]\n          )\n          return TokenParseResult.success(node, tokens, expr_result.position)\n        end\n\n        # Keyword argument: name: value\n        if tokens[position]&.type == :identifier && tokens[position + 1]&.type == :colon\n          key_name = tokens[position].value\n          position += 2 # skip identifier and colon\n\n          value_result = parse_expression(tokens, position)\n          return value_result if value_result.failure?\n\n          # Create a hash pair for keyword argument\n          key = IR::Literal.new(value: key_name.to_sym, literal_type: :symbol)\n          node = IR::HashPair.new(key: key, value: value_result.value)\n          return TokenParseResult.success(node, tokens, value_result.position)\n        end\n\n        # Regular expression argument\n        parse_expression(tokens, position)\n      end\n\n      def parse_array_literal(tokens, position)\n        return TokenParseResult.failure("Expected \'[\'", tokens, position) unless tokens[position]&.type == :lbracket\n\n        position += 1\n\n        elements = []\n\n        # Empty array\n        if tokens[position]&.type == :rbracket\n          node = IR::ArrayLiteral.new(elements: elements)\n          return TokenParseResult.success(node, tokens, position + 1)\n        end\n\n        # Parse first element\n        result = parse_expression(tokens, position)\n        return result if result.failure?\n\n        elements << result.value\n        position = result.position\n\n        # Parse remaining elements\n        while tokens[position]&.type == :comma\n          position += 1\n          result = parse_expression(tokens, position)\n          return result if result.failure?\n\n          elements << result.value\n          position = result.position\n        end\n\n        return TokenParseResult.failure("Expected \']\'", tokens, position) unless tokens[position]&.type == :rbracket\n\n        node = IR::ArrayLiteral.new(elements: elements)\n        TokenParseResult.success(node, tokens, position + 1)\n      end\n\n      def parse_hash_literal(tokens, position)\n        return TokenParseResult.failure("Expected \'{\'", tokens, position) unless tokens[position]&.type == :lbrace\n\n        position += 1\n\n        pairs = []\n\n        # Empty hash\n        if tokens[position]&.type == :rbrace\n          node = IR::HashLiteral.new(pairs: pairs)\n          return TokenParseResult.success(node, tokens, position + 1)\n        end\n\n        # Parse first pair\n        pair_result = parse_hash_pair(tokens, position)\n        return pair_result if pair_result.failure?\n\n        pairs << pair_result.value\n        position = pair_result.position\n\n        # Parse remaining pairs\n        while tokens[position]&.type == :comma\n          position += 1\n          pair_result = parse_hash_pair(tokens, position)\n          return pair_result if pair_result.failure?\n\n          pairs << pair_result.value\n          position = pair_result.position\n        end\n\n        return TokenParseResult.failure("Expected \'}\'", tokens, position) unless tokens[position]&.type == :rbrace\n\n        node = IR::HashLiteral.new(pairs: pairs)\n        TokenParseResult.success(node, tokens, position + 1)\n      end\n\n      def parse_hash_pair(tokens, position)\n        # Handle symbol key shorthand: key: value\n        if tokens[position]&.type == :identifier && tokens[position + 1]&.type == :colon\n          key = IR::Literal.new(value: tokens[position].value.to_sym, literal_type: :symbol)\n          position += 2 # skip identifier and colon\n        else\n          # Parse key expression\n          key_result = parse_expression(tokens, position)\n          return key_result if key_result.failure?\n\n          key = key_result.value\n          position = key_result.position\n\n          # Expect => or :\n          return TokenParseResult.failure("Expected \':\' or \'=>\' in hash pair", tokens, position) unless tokens[position]&.type == :colon\n\n          position += 1\n\n        end\n\n        # Parse value expression\n        value_result = parse_expression(tokens, position)\n        return value_result if value_result.failure?\n\n        pair = IR::HashPair.new(key: key, value: value_result.value)\n        TokenParseResult.success(pair, tokens, value_result.position)\n      end\n\n      def parse_interpolated_string(tokens, position)\n        # string_start token contains the opening quote\n        position += 1\n\n        parts = []\n\n        while position < tokens.length\n          token = tokens[position]\n\n          case token.type\n          when :string_content\n            parts << IR::Literal.new(value: token.value, literal_type: :string)\n            position += 1\n          when :interpolation_start\n            # Skip #{ and parse expression\n            position += 1\n            expr_result = parse_expression(tokens, position)\n            return expr_result if expr_result.failure?\n\n            parts << expr_result.value\n            position = expr_result.position\n\n            # Expect interpolation_end (})\n            return TokenParseResult.failure("Expected \'}\'", tokens, position) unless tokens[position]&.type == :interpolation_end\n\n            position += 1\n\n          when :string_end\n            position += 1\n            break\n          else\n            return TokenParseResult.failure("Unexpected token in string: #{token.type}", tokens, position)\n          end\n        end\n\n        # Create interpolated string node\n        node = IR::InterpolatedString.new(parts: parts)\n        TokenParseResult.success(node, tokens, position)\n      end\n\n      def keywords\n        @keywords ||= TRuby::Scanner::KEYWORDS\n      end\n    end\n  end\nend\n',"lib/t_ruby/parser_combinator/token/statement_parser.rb":"# frozen_string_literal: true\n\nmodule TRuby\n  module ParserCombinator\n    # Statement Parser - Parse statements into IR nodes\n    class StatementParser\n      include TokenDSL\n\n      def initialize\n        @expression_parser = ExpressionParser.new\n      end\n\n      def parse_statement(tokens, position = 0)\n        return TokenParseResult.failure(\"End of input\", tokens, position) if position >= tokens.length\n\n        # Skip newlines\n        position = skip_newlines(tokens, position)\n        return TokenParseResult.failure(\"End of input\", tokens, position) if position >= tokens.length\n\n        token = tokens[position]\n\n        case token.type\n        when :return\n          parse_return(tokens, position)\n        when :if\n          parse_if(tokens, position)\n        when :unless\n          parse_unless(tokens, position)\n        when :while\n          parse_while(tokens, position)\n        when :until\n          parse_until(tokens, position)\n        when :case\n          parse_case(tokens, position)\n        when :begin\n          parse_begin(tokens, position)\n        else\n          # Could be assignment or expression\n          parse_assignment_or_expression(tokens, position)\n        end\n      end\n\n      def parse_block(tokens, position = 0)\n        statements = []\n\n        loop do\n          position = skip_newlines(tokens, position)\n          break if position >= tokens.length\n\n          token = tokens[position]\n          break if token.type == :eof\n          break if %i[end else elsif when rescue ensure].include?(token.type)\n\n          result = parse_statement(tokens, position)\n          break if result.failure?\n\n          statements << result.value\n          position = result.position\n        end\n\n        node = IR::Block.new(statements: statements)\n        TokenParseResult.success(node, tokens, position)\n      end\n\n      private\n\n      def skip_newlines(tokens, position)\n        position += 1 while position < tokens.length && %i[newline comment].include?(tokens[position].type)\n        position\n      end\n\n      def parse_return(tokens, position)\n        position += 1 # consume 'return'\n\n        # Check if there's a return value\n        position = skip_newlines_if_not_modifier(tokens, position)\n\n        if position >= tokens.length ||\n           tokens[position].type == :eof ||\n           tokens[position].type == :newline ||\n           end_of_statement?(tokens, position)\n          node = IR::Return.new(value: nil)\n          return TokenParseResult.success(node, tokens, position)\n        end\n\n        # Parse return value expression\n        expr_result = @expression_parser.parse_expression(tokens, position)\n        return expr_result if expr_result.failure?\n\n        # Check for modifier\n        modifier_result = parse_modifier(tokens, expr_result.position, IR::Return.new(value: expr_result.value))\n        return modifier_result if modifier_result.success? && modifier_result.value.is_a?(IR::Conditional)\n\n        node = IR::Return.new(value: expr_result.value)\n        TokenParseResult.success(node, tokens, expr_result.position)\n      end\n\n      def parse_if(tokens, position)\n        position += 1 # consume 'if'\n\n        # Parse condition\n        cond_result = @expression_parser.parse_expression(tokens, position)\n        return cond_result if cond_result.failure?\n\n        position = cond_result.position\n\n        # Skip newline after condition\n        position = skip_newlines(tokens, position)\n\n        # Parse then branch\n        then_result = parse_block(tokens, position)\n        position = then_result.position\n        position = skip_newlines(tokens, position)\n\n        # Check for elsif or else\n        else_branch = nil\n        if position < tokens.length && tokens[position].type == :elsif\n          elsif_result = parse_if(tokens, position) # Reuse if parsing for elsif\n          return elsif_result if elsif_result.failure?\n\n          else_branch = elsif_result.value\n          position = elsif_result.position\n        elsif position < tokens.length && tokens[position].type == :else\n          position += 1 # consume 'else'\n          position = skip_newlines(tokens, position)\n          else_result = parse_block(tokens, position)\n          else_branch = else_result.value\n          position = else_result.position\n          position = skip_newlines(tokens, position)\n        end\n\n        # Expect 'end' (unless it was an elsif chain)\n        if position < tokens.length && tokens[position].type == :end\n          position += 1\n        end\n\n        node = IR::Conditional.new(\n          kind: :if,\n          condition: cond_result.value,\n          then_branch: then_result.value,\n          else_branch: else_branch\n        )\n        TokenParseResult.success(node, tokens, position)\n      end\n\n      def parse_unless(tokens, position)\n        position += 1 # consume 'unless'\n\n        # Parse condition\n        cond_result = @expression_parser.parse_expression(tokens, position)\n        return cond_result if cond_result.failure?\n\n        position = cond_result.position\n\n        # Skip newline\n        position = skip_newlines(tokens, position)\n\n        # Parse then branch\n        then_result = parse_block(tokens, position)\n        position = then_result.position\n        position = skip_newlines(tokens, position)\n\n        # Check for else\n        else_branch = nil\n        if position < tokens.length && tokens[position].type == :else\n          position += 1\n          position = skip_newlines(tokens, position)\n          else_result = parse_block(tokens, position)\n          else_branch = else_result.value\n          position = else_result.position\n          position = skip_newlines(tokens, position)\n        end\n\n        # Expect 'end'\n        if position < tokens.length && tokens[position].type == :end\n          position += 1\n        end\n\n        node = IR::Conditional.new(\n          kind: :unless,\n          condition: cond_result.value,\n          then_branch: then_result.value,\n          else_branch: else_branch\n        )\n        TokenParseResult.success(node, tokens, position)\n      end\n\n      def parse_while(tokens, position)\n        position += 1 # consume 'while'\n\n        # Parse condition\n        cond_result = @expression_parser.parse_expression(tokens, position)\n        return cond_result if cond_result.failure?\n\n        position = cond_result.position\n\n        # Skip newline\n        position = skip_newlines(tokens, position)\n\n        # Parse body\n        body_result = parse_block(tokens, position)\n        position = body_result.position\n        position = skip_newlines(tokens, position)\n\n        # Expect 'end'\n        if position < tokens.length && tokens[position].type == :end\n          position += 1\n        end\n\n        node = IR::Loop.new(\n          kind: :while,\n          condition: cond_result.value,\n          body: body_result.value\n        )\n        TokenParseResult.success(node, tokens, position)\n      end\n\n      def parse_until(tokens, position)\n        position += 1 # consume 'until'\n\n        # Parse condition\n        cond_result = @expression_parser.parse_expression(tokens, position)\n        return cond_result if cond_result.failure?\n\n        position = cond_result.position\n\n        # Skip newline\n        position = skip_newlines(tokens, position)\n\n        # Parse body\n        body_result = parse_block(tokens, position)\n        position = body_result.position\n        position = skip_newlines(tokens, position)\n\n        # Expect 'end'\n        if position < tokens.length && tokens[position].type == :end\n          position += 1\n        end\n\n        node = IR::Loop.new(\n          kind: :until,\n          condition: cond_result.value,\n          body: body_result.value\n        )\n        TokenParseResult.success(node, tokens, position)\n      end\n\n      def parse_case(tokens, position)\n        position += 1 # consume 'case'\n\n        # Parse subject (optional)\n        subject = nil\n        position = skip_newlines(tokens, position)\n\n        if position < tokens.length && tokens[position].type != :when\n          subj_result = @expression_parser.parse_expression(tokens, position)\n          if subj_result.success?\n            subject = subj_result.value\n            position = subj_result.position\n          end\n        end\n\n        position = skip_newlines(tokens, position)\n\n        # Parse when clauses\n        when_clauses = []\n        while position < tokens.length && tokens[position].type == :when\n          when_result = parse_when_clause(tokens, position)\n          return when_result if when_result.failure?\n\n          when_clauses << when_result.value\n          position = when_result.position\n          position = skip_newlines(tokens, position)\n        end\n\n        # Parse else clause\n        else_clause = nil\n        if position < tokens.length && tokens[position].type == :else\n          position += 1\n          position = skip_newlines(tokens, position)\n          else_result = parse_block(tokens, position)\n          else_clause = else_result.value\n          position = else_result.position\n          position = skip_newlines(tokens, position)\n        end\n\n        # Expect 'end'\n        if position < tokens.length && tokens[position].type == :end\n          position += 1\n        end\n\n        node = IR::CaseExpr.new(\n          subject: subject,\n          when_clauses: when_clauses,\n          else_clause: else_clause\n        )\n        TokenParseResult.success(node, tokens, position)\n      end\n\n      def parse_when_clause(tokens, position)\n        position += 1 # consume 'when'\n\n        # Parse patterns (comma-separated)\n        patterns = []\n        loop do\n          pattern_result = @expression_parser.parse_expression(tokens, position)\n          return pattern_result if pattern_result.failure?\n\n          patterns << pattern_result.value\n          position = pattern_result.position\n\n          break unless tokens[position]&.type == :comma\n\n          position += 1\n        end\n\n        position = skip_newlines(tokens, position)\n\n        # Parse body\n        body_result = parse_block(tokens, position)\n        position = body_result.position\n\n        node = IR::WhenClause.new(patterns: patterns, body: body_result.value)\n        TokenParseResult.success(node, tokens, position)\n      end\n\n      def parse_begin(tokens, position)\n        position += 1 # consume 'begin'\n        position = skip_newlines(tokens, position)\n\n        # Parse body\n        body_result = parse_block(tokens, position)\n        position = body_result.position\n        position = skip_newlines(tokens, position)\n\n        # Parse rescue clauses\n        rescue_clauses = []\n        while position < tokens.length && tokens[position].type == :rescue\n          rescue_result = parse_rescue_clause(tokens, position)\n          return rescue_result if rescue_result.failure?\n\n          rescue_clauses << rescue_result.value\n          position = rescue_result.position\n          position = skip_newlines(tokens, position)\n        end\n\n        # Parse else clause (runs if no exception)\n        else_clause = nil\n        if position < tokens.length && tokens[position].type == :else\n          position += 1\n          position = skip_newlines(tokens, position)\n          else_result = parse_block(tokens, position)\n          else_clause = else_result.value\n          position = else_result.position\n          position = skip_newlines(tokens, position)\n        end\n\n        # Parse ensure clause\n        ensure_clause = nil\n        if position < tokens.length && tokens[position].type == :ensure\n          position += 1\n          position = skip_newlines(tokens, position)\n          ensure_result = parse_block(tokens, position)\n          ensure_clause = ensure_result.value\n          position = ensure_result.position\n          position = skip_newlines(tokens, position)\n        end\n\n        # Expect 'end'\n        if position < tokens.length && tokens[position].type == :end\n          position += 1\n        end\n\n        node = IR::BeginBlock.new(\n          body: body_result.value,\n          rescue_clauses: rescue_clauses,\n          else_clause: else_clause,\n          ensure_clause: ensure_clause\n        )\n        TokenParseResult.success(node, tokens, position)\n      end\n\n      def parse_rescue_clause(tokens, position)\n        position += 1 # consume 'rescue'\n\n        exception_types = []\n        variable = nil\n\n        # Check for exception types and variable binding\n        # Format: rescue ExType, ExType2 => var or rescue => var\n        # Parse exception types\n        if position < tokens.length && !%i[newline hash_rocket].include?(tokens[position].type) && (tokens[position].type == :constant)\n          loop do\n            if tokens[position].type == :constant\n              exception_types << tokens[position].value\n              position += 1\n            end\n            break unless tokens[position]&.type == :comma\n\n            position += 1\n          end\n        end\n\n        # Check for => var binding\n        if position < tokens.length && tokens[position].type == :hash_rocket\n          position += 1\n          if tokens[position]&.type == :identifier\n            variable = tokens[position].value\n            position += 1\n          end\n        end\n\n        position = skip_newlines(tokens, position)\n\n        # Parse body\n        body_result = parse_block(tokens, position)\n        position = body_result.position\n\n        node = IR::RescueClause.new(\n          exception_types: exception_types,\n          variable: variable,\n          body: body_result.value\n        )\n        TokenParseResult.success(node, tokens, position)\n      end\n\n      def parse_assignment_or_expression(tokens, position)\n        # Check for typed assignment: name: Type = value\n        if tokens[position].type == :identifier &&\n           tokens[position + 1]&.type == :colon &&\n           tokens[position + 2]&.type == :constant\n          return parse_typed_assignment(tokens, position)\n        end\n\n        # Check for simple assignment patterns\n        if assignable_token?(tokens[position])\n          next_pos = position + 1\n\n          # Simple assignment: x = value\n          if tokens[next_pos]&.type == :eq\n            return parse_simple_assignment(tokens, position)\n          end\n\n          # Compound assignment: x += value, x -= value, etc.\n          if compound_assignment_token?(tokens[next_pos])\n            return parse_compound_assignment(tokens, position)\n          end\n        end\n\n        # Parse as expression\n        expr_result = @expression_parser.parse_expression(tokens, position)\n        return expr_result if expr_result.failure?\n\n        # Check for statement modifiers\n        parse_modifier(tokens, expr_result.position, expr_result.value)\n      end\n\n      def parse_typed_assignment(tokens, position)\n        target = tokens[position].value\n        position += 2 # skip identifier and colon\n\n        # Parse type annotation (simple constant for now)\n        type_annotation = IR::SimpleType.new(name: tokens[position].value)\n        position += 1\n\n        # Expect '='\n        return TokenParseResult.failure(\"Expected '='\", tokens, position) unless tokens[position]&.type == :eq\n\n        position += 1\n\n        # Parse value\n        value_result = @expression_parser.parse_expression(tokens, position)\n        return value_result if value_result.failure?\n\n        node = IR::Assignment.new(\n          target: target,\n          value: value_result.value,\n          type_annotation: type_annotation\n        )\n        TokenParseResult.success(node, tokens, value_result.position)\n      end\n\n      def parse_simple_assignment(tokens, position)\n        target = tokens[position].value\n        position += 2 # skip variable and '='\n\n        # Check for statement expressions (case, if, begin, etc.) as value\n        value_result = case tokens[position]&.type\n                       when :case\n                         parse_case(tokens, position)\n                       when :if\n                         parse_if(tokens, position)\n                       when :unless\n                         parse_unless(tokens, position)\n                       when :begin\n                         parse_begin(tokens, position)\n                       else\n                         @expression_parser.parse_expression(tokens, position)\n                       end\n        return value_result if value_result.failure?\n\n        node = IR::Assignment.new(target: target, value: value_result.value)\n        TokenParseResult.success(node, tokens, value_result.position)\n      end\n\n      def parse_compound_assignment(tokens, position)\n        target = tokens[position].value\n        op_token = tokens[position + 1]\n        position += 2 # skip variable and operator\n\n        # Map compound operator to binary operator\n        op_map = {\n          plus_eq: :+,\n          minus_eq: :-,\n          star_eq: :*,\n          slash_eq: :/,\n          percent_eq: :%,\n        }\n        binary_op = op_map[op_token.type]\n\n        # Parse right-hand side\n        rhs_result = @expression_parser.parse_expression(tokens, position)\n        return rhs_result if rhs_result.failure?\n\n        # Create expanded form: x = x + value\n        target_ref = IR::VariableRef.new(name: target, scope: infer_scope(target))\n        binary_expr = IR::BinaryOp.new(\n          operator: binary_op,\n          left: target_ref,\n          right: rhs_result.value\n        )\n\n        node = IR::Assignment.new(target: target, value: binary_expr)\n\n        # Check for statement modifiers\n        parse_modifier(tokens, rhs_result.position, node)\n      end\n\n      def parse_modifier(tokens, position, statement)\n        return TokenParseResult.success(statement, tokens, position) if position >= tokens.length\n\n        token = tokens[position]\n        case token.type\n        when :if\n          position += 1\n          cond_result = @expression_parser.parse_expression(tokens, position)\n          return cond_result if cond_result.failure?\n\n          then_branch = statement.is_a?(IR::Block) ? statement : IR::Block.new(statements: [statement])\n          node = IR::Conditional.new(\n            kind: :if,\n            condition: cond_result.value,\n            then_branch: then_branch\n          )\n          TokenParseResult.success(node, tokens, cond_result.position)\n\n        when :unless\n          position += 1\n          cond_result = @expression_parser.parse_expression(tokens, position)\n          return cond_result if cond_result.failure?\n\n          then_branch = statement.is_a?(IR::Block) ? statement : IR::Block.new(statements: [statement])\n          node = IR::Conditional.new(\n            kind: :unless,\n            condition: cond_result.value,\n            then_branch: then_branch\n          )\n          TokenParseResult.success(node, tokens, cond_result.position)\n\n        when :while\n          position += 1\n          cond_result = @expression_parser.parse_expression(tokens, position)\n          return cond_result if cond_result.failure?\n\n          body = statement.is_a?(IR::Block) ? statement : IR::Block.new(statements: [statement])\n          node = IR::Loop.new(\n            kind: :while,\n            condition: cond_result.value,\n            body: body\n          )\n          TokenParseResult.success(node, tokens, cond_result.position)\n\n        when :until\n          position += 1\n          cond_result = @expression_parser.parse_expression(tokens, position)\n          return cond_result if cond_result.failure?\n\n          body = statement.is_a?(IR::Block) ? statement : IR::Block.new(statements: [statement])\n          node = IR::Loop.new(\n            kind: :until,\n            condition: cond_result.value,\n            body: body\n          )\n          TokenParseResult.success(node, tokens, cond_result.position)\n\n        else\n          TokenParseResult.success(statement, tokens, position)\n        end\n      end\n\n      def assignable_token?(token)\n        return false unless token\n\n        %i[identifier ivar cvar gvar].include?(token.type)\n      end\n\n      def compound_assignment_token?(token)\n        return false unless token\n\n        %i[plus_eq minus_eq star_eq slash_eq percent_eq].include?(token.type)\n      end\n\n      def end_of_statement?(tokens, position)\n        return true if position >= tokens.length\n\n        %i[newline eof end else elsif when rescue ensure].include?(tokens[position].type)\n      end\n\n      def skip_newlines_if_not_modifier(tokens, position)\n        # Don't skip newlines if next token after newline is a modifier\n        if tokens[position]&.type == :newline\n          next_pos = position + 1\n          next_pos += 1 while next_pos < tokens.length && tokens[next_pos].type == :newline\n          # If next meaningful token is a modifier, return original position\n          if next_pos < tokens.length && %i[if unless while until].include?(tokens[next_pos].type)\n            return position\n          end\n        end\n        skip_newlines(tokens, position)\n      end\n\n      def infer_scope(name)\n        case name[0]\n        when \"@\"\n          name[1] == \"@\" ? :class : :instance\n        when \"$\"\n          :global\n        else\n          :local\n        end\n      end\n    end\n  end\nend\n","lib/t_ruby/parser_combinator/token/token_alternative.rb":"# frozen_string_literal: true\n\nmodule TRuby\n  module ParserCombinator\n    # Alternative: try first, if fails try second\n    class TokenAlternative < TokenParser\n      def initialize(left, right)\n        @left = left\n        @right = right\n      end\n\n      def parse(tokens, position = 0)\n        result = @left.parse(tokens, position)\n        return result if result.success?\n\n        @right.parse(tokens, position)\n      end\n    end\n  end\nend\n","lib/t_ruby/parser_combinator/token/token_body_parser.rb":'# frozen_string_literal: true\n\nmodule TRuby\n  module ParserCombinator\n    # Token-based body parser - replaces regex-based BodyParser\n    # Provides the same interface as BodyParser.parse(lines, start_line, end_line)\n    class TokenBodyParser\n      def initialize\n        @statement_parser = StatementParser.new\n      end\n\n      # Parse method body from lines array\n      # @param lines [Array<String>] source code lines\n      # @param start_line [Integer] starting line index (0-based)\n      # @param end_line [Integer] ending line index (exclusive)\n      # @return [IR::Block] parsed block of statements\n      def parse(lines, start_line, end_line)\n        # Extract the body source\n        body_lines = lines[start_line...end_line]\n        source = body_lines.join("\\n")\n\n        return IR::Block.new(statements: []) if source.strip.empty?\n\n        # Scan and parse\n        scanner = TRuby::Scanner.new(source)\n        tokens = scanner.scan_all\n\n        result = @statement_parser.parse_block(tokens, 0)\n\n        if result.success?\n          result.value\n        else\n          # Fallback to empty block on parse failure\n          IR::Block.new(statements: [])\n        end\n      end\n\n      # Parse a single expression string\n      # @param expr [String] expression to parse\n      # @return [IR::Node] parsed expression node\n      def parse_expression(expr)\n        return nil if expr.nil? || expr.strip.empty?\n\n        scanner = TRuby::Scanner.new(expr)\n        tokens = scanner.scan_all\n\n        expression_parser = ExpressionParser.new\n        result = expression_parser.parse_expression(tokens, 0)\n\n        result.success? ? result.value : IR::RawCode.new(code: expr)\n      end\n    end\n  end\nend\n',"lib/t_ruby/parser_combinator/token/token_declaration_parser.rb":'# frozen_string_literal: true\n\nmodule TRuby\n  module ParserCombinator\n    # Token Declaration Parser - Parse top-level declarations\n    class TokenDeclarationParser\n      include TokenDSL\n\n      # Parse error with location info\n      class ParseError\n        attr_reader :message, :line, :column, :token\n\n        def initialize(message, token: nil)\n          @message = message\n          @token = token\n          @line = token&.line || 1\n          @column = token&.column || 1\n        end\n\n        def to_s\n          "Line #{@line}, Column #{@column}: #{@message}"\n        end\n      end\n\n      attr_reader :errors\n\n      def initialize\n        @statement_parser = StatementParser.new\n        @expression_parser = ExpressionParser.new\n        @errors = []\n      end\n\n      def parse_declaration(tokens, position = 0)\n        return TokenParseResult.failure("End of input", tokens, position) if position >= tokens.length\n\n        position = skip_newlines(tokens, position)\n        return TokenParseResult.failure("End of input", tokens, position) if position >= tokens.length\n\n        token = tokens[position]\n\n        case token.type\n        when :def\n          parse_method_def(tokens, position)\n        when :public, :private, :protected\n          parse_visibility_method(tokens, position)\n        when :class\n          parse_class(tokens, position)\n        when :module\n          parse_module(tokens, position)\n        when :type\n          parse_type_alias(tokens, position)\n        when :interface\n          parse_interface(tokens, position)\n        else\n          TokenParseResult.failure("Expected declaration, got #{token.type}", tokens, position)\n        end\n      end\n\n      def parse_program(tokens, position = 0)\n        declarations = []\n        @errors = []\n\n        loop do\n          position = skip_newlines(tokens, position)\n          break if position >= tokens.length\n          break if tokens[position].type == :eof\n\n          token = tokens[position]\n\n          # Check if this looks like a declaration keyword\n          unless declaration_keyword?(token.type)\n            # Not a declaration - skip to next line (top-level expression is allowed)\n            position = skip_to_next_line(tokens, position)\n            next\n          end\n\n          result = parse_declaration(tokens, position)\n\n          if result.failure?\n            # Collect error and try to recover\n            # Use result.position for accurate error location (where the error actually occurred)\n            error_pos = result.position\n            error_token = tokens[error_pos] if error_pos < tokens.length\n            @errors << ParseError.new(result.error, token: error_token)\n\n            # Try to skip to next declaration (find next \'def\', \'class\', etc.)\n            position = skip_to_next_declaration(tokens, position)\n            next\n          end\n\n          declarations << result.value\n          position = result.position\n        end\n\n        program = IR::Program.new(declarations: declarations)\n        TokenParseResult.success(program, tokens, position)\n      end\n\n      # Check if parsing encountered any errors\n      def has_errors?\n        !@errors.empty?\n      end\n\n      private\n\n      def skip_newlines(tokens, position)\n        position += 1 while position < tokens.length && %i[newline comment].include?(tokens[position].type)\n        position\n      end\n\n      # Check if token type is a declaration keyword\n      def declaration_keyword?(type)\n        %i[def class module type interface public private protected].include?(type)\n      end\n\n      # Skip to the next line (for top-level expressions)\n      def skip_to_next_line(tokens, position)\n        while position < tokens.length\n          break if tokens[position].type == :newline\n\n          position += 1\n        end\n        position += 1 if position < tokens.length # skip the newline itself\n        position\n      end\n\n      # Skip to the next top-level declaration keyword for error recovery\n      def skip_to_next_declaration(tokens, position)\n        declaration_keywords = %i[def class module type interface public private protected]\n\n        # First, skip the current token\n        position += 1\n\n        while position < tokens.length\n          token = tokens[position]\n\n          # Found a declaration keyword at start of line (or after newline)\n          if declaration_keywords.include?(token.type)\n            # Check if this is at start of a logical line\n            prev_token = tokens[position - 1] if position.positive?\n            if prev_token.nil? || prev_token.type == :newline\n              return position\n            end\n          end\n\n          # Skip to next line if we hit newline\n          if token.type == :newline\n            position += 1\n            # Skip comments and blank lines\n            position = skip_newlines(tokens, position)\n            next\n          end\n\n          position += 1\n        end\n\n        position\n      end\n\n      def parse_method_def(tokens, position, visibility: :public)\n        # Capture def token\'s location before consuming\n        def_token = tokens[position]\n        def_line = def_token.line\n        def_column = def_token.column\n\n        position += 1 # consume \'def\'\n\n        # Parse method name (identifier or operator)\n        return TokenParseResult.failure("Expected method name", tokens, position) if position >= tokens.length\n\n        method_name = tokens[position].value\n        position += 1\n\n        # Check for unexpected tokens after method name (indicates space in method name)\n        if position < tokens.length\n          next_token = tokens[position]\n          # After method name, only these are valid: ( : newline end\n          # If we see an identifier, it means there was a space in the method name\n          if next_token.type == :identifier\n            return TokenParseResult.failure(\n              "Unexpected token \'#{next_token.value}\' after method name \'#{method_name}\' - method names cannot contain spaces",\n              tokens,\n              position\n            )\n          end\n        end\n\n        # Parse parameters\n        params = []\n        if position < tokens.length && tokens[position].type == :lparen\n          position += 1 # consume (\n\n          # Parse parameter list\n          unless tokens[position].type == :rparen\n            loop do\n              param_result = parse_parameter(tokens, position)\n              return param_result if param_result.failure?\n\n              # Handle keyword args group which returns an array\n              if param_result.value.is_a?(Array)\n                params.concat(param_result.value)\n              else\n                params << param_result.value\n              end\n              position = param_result.position\n\n              break unless tokens[position]&.type == :comma\n\n              position += 1\n            end\n          end\n\n          return TokenParseResult.failure("Expected \')\'", tokens, position) unless tokens[position]&.type == :rparen\n\n          position += 1\n        end\n\n        # Parse return type\n        return_type = nil\n        if position < tokens.length && tokens[position].type == :colon\n          colon_token = tokens[position]\n\n          # Check: no space allowed before colon (method name or ) must be adjacent to :)\n          prev_token = tokens[position - 1]\n          if prev_token && prev_token.end_pos < colon_token.start_pos\n            return TokenParseResult.failure(\n              "No space allowed before \':\' for return type annotation",\n              tokens,\n              position\n            )\n          end\n\n          position += 1\n\n          # Check: space required after colon before type name\n          if position < tokens.length\n            type_token = tokens[position]\n            if colon_token.end_pos == type_token.start_pos\n              return TokenParseResult.failure(\n                "Space required after \':\' before return type",\n                tokens,\n                position\n              )\n            end\n          end\n\n          type_result = parse_type(tokens, position)\n          return type_result if type_result.failure?\n\n          return_type = type_result.value\n          position = type_result.position\n        elsif position < tokens.length && tokens[position].type == :symbol\n          # Handle case where :TypeName was scanned as a symbol (no space after colon)\n          # In method definition context, this is a syntax error\n          symbol_token = tokens[position]\n          type_name = symbol_token.value[1..] # Remove leading \':\'\n\n          # Only if it looks like a type name (starts with uppercase)\n          if type_name =~ /^[A-Z]/\n            # Check: no space allowed before colon\n            prev_token = tokens[position - 1]\n            if prev_token && prev_token.end_pos < symbol_token.start_pos\n              return TokenParseResult.failure(\n                "No space allowed before \':\' for return type annotation",\n                tokens,\n                position\n              )\n            end\n\n            # Error: space required after colon\n            return TokenParseResult.failure(\n              "Space required after \':\' before return type",\n              tokens,\n              position\n            )\n          end\n        end\n\n        position = skip_newlines(tokens, position)\n\n        # Parse body\n        body_result = @statement_parser.parse_block(tokens, position)\n        position = body_result.position\n        position = skip_newlines(tokens, position)\n\n        # Expect \'end\'\n        if position < tokens.length && tokens[position].type == :end\n          position += 1\n        end\n\n        node = IR::MethodDef.new(\n          name: method_name,\n          params: params,\n          return_type: return_type,\n          body: body_result.value,\n          visibility: visibility,\n          location: "#{def_line}:#{def_column}"\n        )\n        TokenParseResult.success(node, tokens, position)\n      end\n\n      def parse_visibility_method(tokens, position)\n        visibility = tokens[position].type\n        position += 1\n\n        if position < tokens.length && tokens[position].type == :def\n          parse_method_def(tokens, position, visibility: visibility)\n        else\n          TokenParseResult.failure("Expected \'def\' after visibility modifier", tokens, position)\n        end\n      end\n\n      def parse_parameter(tokens, position)\n        return TokenParseResult.failure("Expected parameter", tokens, position) if position >= tokens.length\n\n        # Check for different parameter types\n        case tokens[position].type\n        when :lbrace\n          # Keyword args group: { name: Type, age: Type = default }\n          return parse_keyword_args_group(tokens, position)\n\n        when :star\n          # Splat parameter *args\n          position += 1\n          return TokenParseResult.failure("Expected parameter name after *", tokens, position) if position >= tokens.length\n\n          name = tokens[position].value\n          position += 1\n\n          # Check for type annotation: *args: Type\n          type_annotation = nil\n          if position < tokens.length && tokens[position].type == :colon\n            position += 1\n            type_result = parse_type(tokens, position)\n            return type_result if type_result.failure?\n\n            type_annotation = type_result.value\n            position = type_result.position\n          end\n\n          param = IR::Parameter.new(name: name, kind: :rest, type_annotation: type_annotation)\n          return TokenParseResult.success(param, tokens, position)\n\n        when :star_star\n          # Double splat **opts or **opts: Type\n          position += 1\n          return TokenParseResult.failure("Expected parameter name after **", tokens, position) if position >= tokens.length\n\n          name = tokens[position].value\n          position += 1\n\n          # Check for type annotation: **opts: Type\n          type_annotation = nil\n          if position < tokens.length && tokens[position].type == :colon\n            position += 1\n            type_result = parse_type(tokens, position)\n            return type_result if type_result.failure?\n\n            type_annotation = type_result.value\n            position = type_result.position\n          end\n\n          param = IR::Parameter.new(name: name, kind: :keyrest, type_annotation: type_annotation)\n          return TokenParseResult.success(param, tokens, position)\n\n        when :amp\n          # Block parameter &block or &block: Type\n          position += 1\n          return TokenParseResult.failure("Expected parameter name after &", tokens, position) if position >= tokens.length\n\n          name = tokens[position].value\n          position += 1\n\n          # Check for type annotation: &block: Type\n          type_annotation = nil\n          if position < tokens.length && tokens[position].type == :colon\n            position += 1\n            type_result = parse_type(tokens, position)\n            return type_result if type_result.failure?\n\n            type_annotation = type_result.value\n            position = type_result.position\n          end\n\n          param = IR::Parameter.new(name: name, kind: :block, type_annotation: type_annotation)\n          return TokenParseResult.success(param, tokens, position)\n        end\n\n        # Regular parameter: name or name: Type or name: Type = default\n        name = tokens[position].value\n        position += 1\n\n        type_annotation = nil\n        default_value = nil\n\n        if position < tokens.length && tokens[position].type == :colon\n          position += 1\n\n          # Check if next token is a type (constant/identifier) or a default value\n          if position < tokens.length\n            type_result = parse_type(tokens, position)\n            return type_result if type_result.failure?\n\n            type_annotation = type_result.value\n            position = type_result.position\n          end\n        end\n\n        # Check for default value: = expression\n        if position < tokens.length && tokens[position].type == :eq\n          position += 1\n          # Skip the default value expression (parse until comma, rparen, or newline)\n          position = skip_default_value(tokens, position)\n          default_value = true # Just mark that there\'s a default value\n        end\n\n        kind = default_value ? :optional : :required\n        param = IR::Parameter.new(name: name, type_annotation: type_annotation, default_value: default_value, kind: kind)\n        TokenParseResult.success(param, tokens, position)\n      end\n\n      # Parse keyword args group: { name: Type, age: Type = default } or { name:, age: default }: InterfaceName\n      def parse_keyword_args_group(tokens, position)\n        position += 1 # consume \'{\'\n\n        params = []\n        while position < tokens.length && tokens[position].type != :rbrace\n          # Skip newlines inside braces\n          position = skip_newlines(tokens, position)\n          break if position >= tokens.length || tokens[position].type == :rbrace\n\n          # Parse each keyword arg: name: Type or name: Type = default or name: or name: default\n          return TokenParseResult.failure("Expected parameter name", tokens, position) unless tokens[position].type == :identifier\n\n          name = tokens[position].value\n          position += 1\n\n          type_annotation = nil\n          default_value = nil\n\n          if position < tokens.length && tokens[position].type == :colon\n            position += 1\n\n            # Check what follows the colon\n            if position < tokens.length\n              next_token = tokens[position]\n\n              # If it\'s a type (constant), parse the type\n              if next_token.type == :constant\n                type_result = parse_type(tokens, position)\n                unless type_result.failure?\n                  type_annotation = type_result.value\n                  position = type_result.position\n                end\n              elsif next_token.type != :comma && next_token.type != :rbrace && next_token.type != :newline\n                # Ruby-style default value (without =): name: default_value\n                # e.g., { name:, limit: 10 }: InterfaceName\n                position = skip_default_value_in_braces(tokens, position)\n                default_value = true\n              end\n              # If next_token is comma/rbrace/newline, it\'s shorthand `name:` with no type or default\n            end\n          end\n\n          # Check for default value: = expression (T-Ruby style with equals sign)\n          if position < tokens.length && tokens[position].type == :eq\n            position += 1\n            position = skip_default_value_in_braces(tokens, position)\n            default_value = true\n          end\n\n          params << IR::Parameter.new(name: name, type_annotation: type_annotation, default_value: default_value, kind: :keyword)\n\n          # Skip comma\n          if position < tokens.length && tokens[position].type == :comma\n            position += 1\n          end\n\n          position = skip_newlines(tokens, position)\n        end\n\n        return TokenParseResult.failure("Expected \'}\'", tokens, position) unless position < tokens.length && tokens[position].type == :rbrace\n\n        position += 1 # consume \'}\'\n\n        # Check for interface type annotation: { ... }: InterfaceName\n        interface_type = nil\n        if position < tokens.length && tokens[position].type == :colon\n          position += 1\n          type_result = parse_type(tokens, position)\n          unless type_result.failure?\n            interface_type = type_result.value\n            position = type_result.position\n          end\n        end\n\n        # If there\'s an interface type, set it as interface_ref for each param\n        if interface_type\n          params.each { |p| p.interface_ref = interface_type }\n        end\n\n        # Return the array of keyword params wrapped in a result\n        # We\'ll handle this specially in parse_method_def\n        TokenParseResult.success(params, tokens, position)\n      end\n\n      # Skip a default value expression (until comma, rparen, or newline)\n      def skip_default_value(tokens, position)\n        depth = 0\n        while position < tokens.length\n          token = tokens[position]\n          case token.type\n          when :lparen, :lbracket, :lbrace\n            depth += 1\n          when :rparen\n            return position if depth.zero?\n\n            depth -= 1\n          when :rbracket, :rbrace\n            depth -= 1\n          when :comma\n            return position if depth.zero?\n          when :newline\n            return position if depth.zero?\n          end\n          position += 1\n        end\n        position\n      end\n\n      # Skip a default value expression inside braces (until comma, rbrace, or newline)\n      def skip_default_value_in_braces(tokens, position)\n        depth = 0\n        while position < tokens.length\n          token = tokens[position]\n          case token.type\n          when :lparen, :lbracket\n            depth += 1\n          when :rparen, :rbracket\n            depth -= 1\n          when :lbrace\n            depth += 1\n          when :rbrace\n            return position if depth.zero?\n\n            depth -= 1\n          when :comma\n            return position if depth.zero?\n          when :newline\n            return position if depth.zero?\n          end\n          position += 1\n        end\n        position\n      end\n\n      def parse_class(tokens, position)\n        position += 1 # consume \'class\'\n\n        # Parse class name\n        return TokenParseResult.failure("Expected class name", tokens, position) if position >= tokens.length\n\n        class_name = tokens[position].value\n        position += 1\n\n        # Check for superclass\n        superclass = nil\n        if position < tokens.length && tokens[position].type == :lt\n          position += 1\n          superclass = tokens[position].value\n          position += 1\n        end\n\n        position = skip_newlines(tokens, position)\n\n        # Parse class body (methods and instance variables)\n        body = []\n        instance_vars = []\n\n        loop do\n          position = skip_newlines(tokens, position)\n          break if position >= tokens.length\n          break if tokens[position].type == :end\n\n          if tokens[position].type == :ivar && tokens[position + 1]&.type == :colon\n            # Instance variable declaration: @name: Type\n            ivar_result = parse_instance_var_decl(tokens, position)\n            return ivar_result if ivar_result.failure?\n\n            instance_vars << ivar_result.value\n            position = ivar_result.position\n          elsif %i[def public private protected].include?(tokens[position].type)\n            method_result = parse_declaration(tokens, position)\n            return method_result if method_result.failure?\n\n            body << method_result.value\n            position = method_result.position\n          else\n            break\n          end\n        end\n\n        # Expect \'end\'\n        if position < tokens.length && tokens[position].type == :end\n          position += 1\n        end\n\n        node = IR::ClassDecl.new(\n          name: class_name,\n          superclass: superclass,\n          body: body,\n          instance_vars: instance_vars\n        )\n        TokenParseResult.success(node, tokens, position)\n      end\n\n      def parse_instance_var_decl(tokens, position)\n        # @name: Type\n        name = tokens[position].value[1..] # remove @ prefix\n        position += 2 # skip @name and :\n\n        type_result = parse_type(tokens, position)\n        return type_result if type_result.failure?\n\n        node = IR::InstanceVariable.new(name: name, type_annotation: type_result.value)\n        TokenParseResult.success(node, tokens, type_result.position)\n      end\n\n      def parse_module(tokens, position)\n        position += 1 # consume \'module\'\n\n        # Parse module name\n        return TokenParseResult.failure("Expected module name", tokens, position) if position >= tokens.length\n\n        module_name = tokens[position].value\n        position += 1\n\n        position = skip_newlines(tokens, position)\n\n        # Parse module body\n        body = []\n\n        loop do\n          position = skip_newlines(tokens, position)\n          break if position >= tokens.length\n          break if tokens[position].type == :end\n\n          break unless %i[def public private protected].include?(tokens[position].type)\n\n          method_result = parse_declaration(tokens, position)\n          return method_result if method_result.failure?\n\n          body << method_result.value\n          position = method_result.position\n        end\n\n        # Expect \'end\'\n        if position < tokens.length && tokens[position].type == :end\n          position += 1\n        end\n\n        node = IR::ModuleDecl.new(name: module_name, body: body)\n        TokenParseResult.success(node, tokens, position)\n      end\n\n      def parse_type_alias(tokens, position)\n        position += 1 # consume \'type\'\n\n        # Parse type name\n        return TokenParseResult.failure("Expected type name", tokens, position) if position >= tokens.length\n\n        type_name = tokens[position].value\n        position += 1\n\n        # Expect \'=\'\n        return TokenParseResult.failure("Expected \'=\'", tokens, position) unless tokens[position]&.type == :eq\n\n        position += 1\n\n        # Parse type definition\n        type_result = parse_type(tokens, position)\n        return type_result if type_result.failure?\n\n        node = IR::TypeAlias.new(name: type_name, definition: type_result.value)\n        TokenParseResult.success(node, tokens, type_result.position)\n      end\n\n      def parse_interface(tokens, position)\n        position += 1 # consume \'interface\'\n\n        # Parse interface name\n        return TokenParseResult.failure("Expected interface name", tokens, position) if position >= tokens.length\n\n        interface_name = tokens[position].value\n        position += 1\n\n        position = skip_newlines(tokens, position)\n\n        # Parse interface members\n        members = []\n\n        loop do\n          position = skip_newlines(tokens, position)\n          break if position >= tokens.length\n          break if tokens[position].type == :end\n\n          member_result = parse_interface_member(tokens, position)\n          break if member_result.failure?\n\n          members << member_result.value\n          position = member_result.position\n        end\n\n        # Expect \'end\'\n        if position < tokens.length && tokens[position].type == :end\n          position += 1\n        end\n\n        node = IR::Interface.new(name: interface_name, members: members)\n        TokenParseResult.success(node, tokens, position)\n      end\n\n      def parse_interface_member(tokens, position)\n        # name: Type\n        return TokenParseResult.failure("Expected member name", tokens, position) if position >= tokens.length\n\n        name = tokens[position].value\n        position += 1\n\n        return TokenParseResult.failure("Expected \':\'", tokens, position) unless tokens[position]&.type == :colon\n\n        position += 1\n\n        type_result = parse_type(tokens, position)\n        return type_result if type_result.failure?\n\n        node = IR::InterfaceMember.new(name: name, type_signature: type_result.value)\n        TokenParseResult.success(node, tokens, type_result.position)\n      end\n\n      def parse_type(tokens, position)\n        return TokenParseResult.failure("Expected type", tokens, position) if position >= tokens.length\n\n        # Parse primary type\n        result = parse_primary_type(tokens, position)\n        return result if result.failure?\n\n        type = result.value\n        position = result.position\n\n        # Check for union type\n        types = [type]\n        while position < tokens.length && tokens[position].type == :pipe\n          position += 1\n          next_result = parse_primary_type(tokens, position)\n          return next_result if next_result.failure?\n\n          types << next_result.value\n          position = next_result.position\n        end\n\n        if types.length > 1\n          node = IR::UnionType.new(types: types)\n          TokenParseResult.success(node, tokens, position)\n        else\n          TokenParseResult.success(type, tokens, position)\n        end\n      end\n\n      def parse_primary_type(tokens, position)\n        return TokenParseResult.failure("Expected type", tokens, position) if position >= tokens.length\n\n        # Check for function type: -> ReturnType\n        if tokens[position].type == :arrow\n          position += 1\n          return_result = parse_primary_type(tokens, position)\n          return return_result if return_result.failure?\n\n          node = IR::FunctionType.new(param_types: [], return_type: return_result.value)\n          return TokenParseResult.success(node, tokens, return_result.position)\n        end\n\n        # Check for tuple type: (Type, Type) -> ReturnType\n        # or parenthesized type: (String | Integer)[]\n        if tokens[position].type == :lparen\n          position += 1\n          param_types = []\n\n          unless tokens[position].type == :rparen\n            loop do\n              type_result = parse_type(tokens, position)\n              return type_result if type_result.failure?\n\n              param_types << type_result.value\n              position = type_result.position\n\n              break unless tokens[position]&.type == :comma\n\n              position += 1\n            end\n          end\n\n          return TokenParseResult.failure("Expected \')\'", tokens, position) unless tokens[position]&.type == :rparen\n\n          position += 1\n\n          # Check for function arrow\n          if position < tokens.length && tokens[position].type == :arrow\n            position += 1\n            return_result = parse_primary_type(tokens, position)\n            return return_result if return_result.failure?\n\n            node = IR::FunctionType.new(param_types: param_types, return_type: return_result.value)\n            return TokenParseResult.success(node, tokens, return_result.position)\n          elsif param_types.length == 1\n            # Single type in parentheses: (String | Integer)\n            # Check for postfix operators like [] or ?\n            type = param_types[0]\n            return parse_postfix_type_operators(tokens, position, type)\n          else\n            node = IR::TupleType.new(element_types: param_types)\n            return TokenParseResult.success(node, tokens, position)\n          end\n        end\n\n        # Check for hash literal type: { key: Type, key2: Type }\n        if tokens[position].type == :lbrace\n          return parse_hash_literal_type(tokens, position)\n        end\n\n        # Simple type or generic type\n        type_name = tokens[position].value\n        position += 1\n\n        # Handle type names ending with ? (e.g., "String?" scanned as single token)\n        # This happens because Ruby allows ? in method/identifier names\n        is_nullable_from_name = type_name.end_with?("?")\n        if is_nullable_from_name\n          type_name = type_name.chomp("?")\n        end\n\n        # Check for generic arguments: Type<Args>\n        if position < tokens.length && tokens[position].type == :lt\n          position += 1\n          type_args = []\n\n          loop do\n            arg_result = parse_type(tokens, position)\n            return arg_result if arg_result.failure?\n\n            type_args << arg_result.value\n            position = arg_result.position\n\n            break unless tokens[position]&.type == :comma\n\n            position += 1\n          end\n\n          return TokenParseResult.failure("Expected \'>\'", tokens, position) unless tokens[position]&.type == :gt\n\n          position += 1\n\n          node = IR::GenericType.new(base: type_name, type_args: type_args)\n          # Wrap in NullableType if the original type name ended with ?\n          node = IR::NullableType.new(inner_type: node) if is_nullable_from_name\n          # Apply postfix operators ([] or ?) to generic types too\n          parse_postfix_type_operators(tokens, position, node)\n        else\n          # Simple type - apply postfix operators\n          node = IR::SimpleType.new(name: type_name)\n          # Wrap in NullableType if the original type name ended with ?\n          node = IR::NullableType.new(inner_type: node) if is_nullable_from_name\n          parse_postfix_type_operators(tokens, position, node)\n        end\n      end\n\n      # Parse postfix type operators: [] (array shorthand) and ? (nullable)\n      # Handles patterns like:\n      #   String[]     => Array<String>\n      #   Integer[][]  => Array<Array<Integer>>\n      #   String[]?    => NullableType(Array<String>)\n      #   String?[]    => Array<NullableType(String)>\n      #   (A | B)[]    => Array<UnionType(A, B)>\n      def parse_postfix_type_operators(tokens, position, type)\n        loop do\n          break if position >= tokens.length\n\n          case tokens[position].type\n          when :lbracket\n            # Check for [] (empty brackets for array shorthand)\n            break unless tokens[position + 1]&.type == :rbracket\n\n            position += 2\n            type = IR::GenericType.new(base: "Array", type_args: [type])\n          when :question\n            position += 1\n            type = IR::NullableType.new(inner_type: type)\n          else\n            break\n          end\n        end\n\n        TokenParseResult.success(type, tokens, position)\n      end\n\n      # Parse hash literal type: { key: Type, key2: Type }\n      # Used for typed hash parameters like: def foo(config: { host: String, port: Integer })\n      def parse_hash_literal_type(tokens, position)\n        return TokenParseResult.failure("Expected \'{\'", tokens, position) unless tokens[position]&.type == :lbrace\n\n        position += 1 # consume \'{\'\n\n        fields = []\n        while position < tokens.length && tokens[position].type != :rbrace\n          # Skip newlines inside braces\n          position = skip_newlines(tokens, position)\n          break if position >= tokens.length || tokens[position].type == :rbrace\n\n          # Parse field: name: Type\n          unless tokens[position].type == :identifier\n            return TokenParseResult.failure("Expected field name", tokens, position)\n          end\n\n          field_name = tokens[position].value\n          position += 1\n\n          unless tokens[position]&.type == :colon\n            return TokenParseResult.failure("Expected \':\' after field name", tokens, position)\n          end\n\n          position += 1\n\n          type_result = parse_type(tokens, position)\n          return type_result if type_result.failure?\n\n          fields << { name: field_name, type: type_result.value }\n          position = type_result.position\n\n          # Handle optional default value (skip it for type purposes)\n          if position < tokens.length && tokens[position].type == :eq\n            position += 1\n            position = skip_default_value_in_braces(tokens, position)\n          end\n\n          # Skip comma if present\n          if position < tokens.length && tokens[position].type == :comma\n            position += 1\n          end\n        end\n\n        unless tokens[position]&.type == :rbrace\n          return TokenParseResult.failure("Expected \'}\'", tokens, position)\n        end\n\n        position += 1 # consume \'}\'\n\n        node = IR::HashLiteralType.new(fields: fields)\n        TokenParseResult.success(node, tokens, position)\n      end\n    end\n  end\nend\n',"lib/t_ruby/parser_combinator/token/token_dsl.rb":"# frozen_string_literal: true\n\nmodule TRuby\n  module ParserCombinator\n    # Token DSL Module - Convenience methods for token parsing\n    module TokenDSL\n      def token(type)\n        TokenMatcher.new(type)\n      end\n\n      def keyword(kw)\n        TokenMatcher.new(kw)\n      end\n    end\n  end\nend\n","lib/t_ruby/parser_combinator/token/token_label.rb":'# frozen_string_literal: true\n\nmodule TRuby\n  module ParserCombinator\n    # Label for error messages\n    class TokenLabel < TokenParser\n      def initialize(parser, name)\n        @parser = parser\n        @name = name\n      end\n\n      def parse(tokens, position = 0)\n        result = @parser.parse(tokens, position)\n        if result.failure?\n          TokenParseResult.failure("Expected #{@name}", tokens, position)\n        else\n          result\n        end\n      end\n    end\n  end\nend\n',"lib/t_ruby/parser_combinator/token/token_many.rb":"# frozen_string_literal: true\n\nmodule TRuby\n  module ParserCombinator\n    # Many: zero or more\n    class TokenMany < TokenParser\n      def initialize(parser)\n        @parser = parser\n      end\n\n      def parse(tokens, position = 0)\n        results = []\n        current_pos = position\n\n        loop do\n          result = @parser.parse(tokens, current_pos)\n          break if result.failure?\n\n          results << result.value\n          break if result.position == current_pos # Prevent infinite loop\n\n          current_pos = result.position\n        end\n\n        TokenParseResult.success(results, tokens, current_pos)\n      end\n    end\n  end\nend\n","lib/t_ruby/parser_combinator/token/token_many1.rb":"# frozen_string_literal: true\n\nmodule TRuby\n  module ParserCombinator\n    # Many1: one or more\n    class TokenMany1 < TokenParser\n      def initialize(parser)\n        @parser = parser\n      end\n\n      def parse(tokens, position = 0)\n        first = @parser.parse(tokens, position)\n        return first if first.failure?\n\n        results = [first.value]\n        current_pos = first.position\n\n        loop do\n          result = @parser.parse(tokens, current_pos)\n          break if result.failure?\n\n          results << result.value\n          break if result.position == current_pos\n\n          current_pos = result.position\n        end\n\n        TokenParseResult.success(results, tokens, current_pos)\n      end\n    end\n  end\nend\n","lib/t_ruby/parser_combinator/token/token_map.rb":"# frozen_string_literal: true\n\nmodule TRuby\n  module ParserCombinator\n    # Map result\n    class TokenMap < TokenParser\n      def initialize(parser, func)\n        @parser = parser\n        @func = func\n      end\n\n      def parse(tokens, position = 0)\n        @parser.parse(tokens, position).map(&@func)\n      end\n    end\n  end\nend\n","lib/t_ruby/parser_combinator/token/token_matcher.rb":'# frozen_string_literal: true\n\nmodule TRuby\n  module ParserCombinator\n    # Match a specific token type\n    class TokenMatcher < TokenParser\n      def initialize(token_type)\n        @token_type = token_type\n      end\n\n      def parse(tokens, position = 0)\n        return TokenParseResult.failure("End of input", tokens, position) if position >= tokens.length\n\n        token = tokens[position]\n        return TokenParseResult.failure("End of input", tokens, position) if token.type == :eof\n\n        if token.type == @token_type\n          TokenParseResult.success(token, tokens, position + 1)\n        else\n          TokenParseResult.failure(\n            "Expected :#{@token_type}, got :#{token.type} (#{token.value.inspect})",\n            tokens,\n            position\n          )\n        end\n      end\n    end\n  end\nend\n',"lib/t_ruby/parser_combinator/token/token_optional.rb":"# frozen_string_literal: true\n\nmodule TRuby\n  module ParserCombinator\n    # Optional: zero or one\n    class TokenOptional < TokenParser\n      def initialize(parser)\n        @parser = parser\n      end\n\n      def parse(tokens, position = 0)\n        result = @parser.parse(tokens, position)\n        if result.success?\n          result\n        else\n          TokenParseResult.success(nil, tokens, position)\n        end\n      end\n    end\n  end\nend\n","lib/t_ruby/parser_combinator/token/token_parse_result.rb":"# frozen_string_literal: true\n\nmodule TRuby\n  module ParserCombinator\n    # Token-based parse result\n    class TokenParseResult\n      attr_reader :value, :tokens, :position, :error\n\n      def initialize(success:, value: nil, tokens: [], position: 0, error: nil)\n        @success = success\n        @value = value\n        @tokens = tokens\n        @position = position\n        @error = error\n      end\n\n      def success?\n        @success\n      end\n\n      def failure?\n        !@success\n      end\n\n      def self.success(value, tokens, position)\n        new(success: true, value: value, tokens: tokens, position: position)\n      end\n\n      def self.failure(error, tokens, position)\n        new(success: false, error: error, tokens: tokens, position: position)\n      end\n\n      def map\n        return self if failure?\n\n        TokenParseResult.success(yield(value), tokens, position)\n      end\n    end\n  end\nend\n","lib/t_ruby/parser_combinator/token/token_parser.rb":"# frozen_string_literal: true\n\nmodule TRuby\n  module ParserCombinator\n    # Base class for token parsers\n    class TokenParser\n      def parse(tokens, position = 0)\n        raise NotImplementedError\n      end\n\n      # Sequence: run this parser, then the other\n      def >>(other)\n        TokenSequence.new(self, other)\n      end\n\n      # Alternative: try this parser, if it fails try the other\n      def |(other)\n        TokenAlternative.new(self, other)\n      end\n\n      # Map: transform the result\n      def map(&block)\n        TokenMap.new(self, block)\n      end\n\n      # Many: zero or more repetitions\n      def many\n        TokenMany.new(self)\n      end\n\n      # Many1: one or more repetitions\n      def many1\n        TokenMany1.new(self)\n      end\n\n      # Optional: zero or one\n      def optional\n        TokenOptional.new(self)\n      end\n\n      # Separated by: parse items separated by delimiter\n      def sep_by(delimiter)\n        TokenSepBy.new(self, delimiter)\n      end\n\n      # Separated by 1: at least one item\n      def sep_by1(delimiter)\n        TokenSepBy1.new(self, delimiter)\n      end\n\n      # Skip right: parse both, keep left result\n      def <<(other)\n        TokenSkipRight.new(self, other)\n      end\n\n      # Label: add a descriptive label for error messages\n      def label(name)\n        TokenLabel.new(self, name)\n      end\n    end\n  end\nend\n","lib/t_ruby/parser_combinator/token/token_sep_by.rb":"# frozen_string_literal: true\n\nmodule TRuby\n  module ParserCombinator\n    # Separated by delimiter\n    class TokenSepBy < TokenParser\n      def initialize(parser, delimiter)\n        @parser = parser\n        @delimiter = delimiter\n      end\n\n      def parse(tokens, position = 0)\n        first = @parser.parse(tokens, position)\n        return TokenParseResult.success([], tokens, position) if first.failure?\n\n        results = [first.value]\n        current_pos = first.position\n\n        loop do\n          delim_result = @delimiter.parse(tokens, current_pos)\n          break if delim_result.failure?\n\n          item_result = @parser.parse(tokens, delim_result.position)\n          break if item_result.failure?\n\n          results << item_result.value\n          current_pos = item_result.position\n        end\n\n        TokenParseResult.success(results, tokens, current_pos)\n      end\n    end\n  end\nend\n","lib/t_ruby/parser_combinator/token/token_sep_by1.rb":"# frozen_string_literal: true\n\nmodule TRuby\n  module ParserCombinator\n    # Separated by 1 (at least one)\n    class TokenSepBy1 < TokenParser\n      def initialize(parser, delimiter)\n        @parser = parser\n        @delimiter = delimiter\n      end\n\n      def parse(tokens, position = 0)\n        first = @parser.parse(tokens, position)\n        return first if first.failure?\n\n        results = [first.value]\n        current_pos = first.position\n\n        loop do\n          delim_result = @delimiter.parse(tokens, current_pos)\n          break if delim_result.failure?\n\n          item_result = @parser.parse(tokens, delim_result.position)\n          break if item_result.failure?\n\n          results << item_result.value\n          current_pos = item_result.position\n        end\n\n        TokenParseResult.success(results, tokens, current_pos)\n      end\n    end\n  end\nend\n","lib/t_ruby/parser_combinator/token/token_sequence.rb":"# frozen_string_literal: true\n\nmodule TRuby\n  module ParserCombinator\n    # Sequence two token parsers\n    class TokenSequence < TokenParser\n      def initialize(left, right)\n        @left = left\n        @right = right\n      end\n\n      def parse(tokens, position = 0)\n        result1 = @left.parse(tokens, position)\n        return result1 if result1.failure?\n\n        result2 = @right.parse(tokens, result1.position)\n        return result2 if result2.failure?\n\n        TokenParseResult.success([result1.value, result2.value], tokens, result2.position)\n      end\n    end\n  end\nend\n","lib/t_ruby/parser_combinator/token/token_skip_right.rb":"# frozen_string_literal: true\n\nmodule TRuby\n  module ParserCombinator\n    # Skip right: parse both, return left\n    class TokenSkipRight < TokenParser\n      def initialize(left, right)\n        @left = left\n        @right = right\n      end\n\n      def parse(tokens, position = 0)\n        result1 = @left.parse(tokens, position)\n        return result1 if result1.failure?\n\n        result2 = @right.parse(tokens, result1.position)\n        return result2 if result2.failure?\n\n        TokenParseResult.success(result1.value, tokens, result2.position)\n      end\n    end\n  end\nend\n","lib/t_ruby/parser_combinator/type_parser.rb":'# frozen_string_literal: true\n\nmodule TRuby\n  module ParserCombinator\n    # Type Parser - Parse T-Ruby type expressions\n    class TypeParser\n      include DSL\n\n      def initialize\n        build_parsers\n      end\n\n      def parse(input)\n        result = @type_expr.parse(input.strip)\n        if result.success?\n          { success: true, type: result.value, remaining: input[result.position..] }\n        else\n          { success: false, error: result.error, position: result.position }\n        end\n      end\n\n      private\n\n      def build_parsers\n        # Identifier (type name)\n        type_name = identifier.label("type name")\n\n        # Simple type\n        type_name.map { |name| IR::SimpleType.new(name: name) }\n\n        # Lazy reference for recursive types\n        type_expr = lazy { @type_expr }\n\n        # Generic type arguments: <Type, Type, ...>\n        generic_args = (\n          lexeme(char("<")) >>\n          type_expr.sep_by1(lexeme(char(","))) <<\n          lexeme(char(">"))\n        ).map { |(_, types)| types }\n\n        # Generic type: Base<Args>\n        generic_type = (type_name >> generic_args.optional).map do |(name, args)|\n          if args && !args.empty?\n            IR::GenericType.new(base: name, type_args: args)\n          else\n            IR::SimpleType.new(name: name)\n          end\n        end\n\n        # Nullable type: Type?\n        nullable_suffix = char("?")\n\n        # Parenthesized type\n        paren_type = (lexeme(char("(")) >> type_expr << lexeme(char(")"))).map { |(_, t)| t }\n\n        # Function type: (Params) -> ReturnType\n        param_list = (\n          lexeme(char("(")) >>\n          type_expr.sep_by(lexeme(char(","))) <<\n          lexeme(char(")"))\n        ).map { |(_, params)| params }\n\n        arrow = lexeme(string("->"))\n\n        function_type = (param_list >> arrow >> type_expr).map do |((params, _arrow), ret)|\n          IR::FunctionType.new(param_types: params, return_type: ret)\n        end\n\n        # Tuple type: [Type, Type, ...]\n        tuple_type = (\n          lexeme(char("[")) >>\n          type_expr.sep_by1(lexeme(char(","))) <<\n          lexeme(char("]"))\n        ).map { |(_, types)| IR::TupleType.new(element_types: types) }\n\n        # Primary type (before operators)\n        primary_type = choice(\n          function_type,\n          tuple_type,\n          paren_type,\n          generic_type\n        )\n\n        # Array shorthand suffix: [] (can be repeated for nested arrays)\n        array_suffix = string("[]")\n\n        # Postfix operators: ([] | ?)*\n        # Handles: String[], Integer[][], String[]?, String?[], etc.\n        postfix_op = array_suffix | nullable_suffix\n\n        base_type = (primary_type >> postfix_op.many).map do |(initial_type, ops)|\n          ops.reduce(initial_type) do |type, op|\n            case op\n            when "[]"\n              IR::GenericType.new(base: "Array", type_args: [type])\n            when "?"\n              IR::NullableType.new(inner_type: type)\n            else\n              type\n            end\n          end\n        end\n\n        # Union type: Type | Type | ...\n        union_op = lexeme(char("|"))\n        union_type = base_type.sep_by1(union_op).map do |types|\n          types.length == 1 ? types.first : IR::UnionType.new(types: types)\n        end\n\n        # Intersection type: Type & Type & ...\n        intersection_op = lexeme(char("&"))\n        @type_expr = union_type.sep_by1(intersection_op).map do |types|\n          types.length == 1 ? types.first : IR::IntersectionType.new(types: types)\n        end\n      end\n    end\n  end\nend\n',"lib/t_ruby/parser_combinator.rb":'# frozen_string_literal: true\n\n# Parser Combinator module for T-Ruby\n# Provides both string-based and token-based parsing capabilities\n\nmodule TRuby\n  module ParserCombinator\n    # Base classes\n    require_relative "parser_combinator/parse_result"\n    require_relative "parser_combinator/parser"\n\n    # Primitive parsers\n    require_relative "parser_combinator/primitives/literal"\n    require_relative "parser_combinator/primitives/satisfy"\n    require_relative "parser_combinator/primitives/regex"\n    require_relative "parser_combinator/primitives/end_of_input"\n    require_relative "parser_combinator/primitives/pure"\n    require_relative "parser_combinator/primitives/fail"\n    require_relative "parser_combinator/primitives/lazy"\n\n    # Combinator parsers\n    require_relative "parser_combinator/combinators/sequence"\n    require_relative "parser_combinator/combinators/alternative"\n    require_relative "parser_combinator/combinators/map"\n    require_relative "parser_combinator/combinators/flat_map"\n    require_relative "parser_combinator/combinators/many"\n    require_relative "parser_combinator/combinators/many1"\n    require_relative "parser_combinator/combinators/optional"\n    require_relative "parser_combinator/combinators/sep_by"\n    require_relative "parser_combinator/combinators/sep_by1"\n    require_relative "parser_combinator/combinators/skip_right"\n    require_relative "parser_combinator/combinators/label"\n    require_relative "parser_combinator/combinators/lookahead"\n    require_relative "parser_combinator/combinators/not_followed_by"\n    require_relative "parser_combinator/combinators/choice"\n    require_relative "parser_combinator/combinators/chain_left"\n\n    # DSL module\n    require_relative "parser_combinator/dsl"\n\n    # Token-based parsers\n    require_relative "parser_combinator/token/token_parse_result"\n    require_relative "parser_combinator/token/token_parser"\n    require_relative "parser_combinator/token/token_matcher"\n    require_relative "parser_combinator/token/token_sequence"\n    require_relative "parser_combinator/token/token_alternative"\n    require_relative "parser_combinator/token/token_map"\n    require_relative "parser_combinator/token/token_many"\n    require_relative "parser_combinator/token/token_many1"\n    require_relative "parser_combinator/token/token_optional"\n    require_relative "parser_combinator/token/token_sep_by"\n    require_relative "parser_combinator/token/token_sep_by1"\n    require_relative "parser_combinator/token/token_skip_right"\n    require_relative "parser_combinator/token/token_label"\n    require_relative "parser_combinator/token/token_dsl"\n\n    # High-level parsers\n    require_relative "parser_combinator/token/expression_parser"\n    require_relative "parser_combinator/token/statement_parser"\n    require_relative "parser_combinator/token/token_declaration_parser"\n    require_relative "parser_combinator/token/token_body_parser"\n\n    # Type and declaration parsers (string-based)\n    require_relative "parser_combinator/type_parser"\n    require_relative "parser_combinator/declaration_parser"\n\n    # Error reporting\n    require_relative "parser_combinator/parse_error"\n  end\nend\n',"lib/t_ruby/ruby_version.rb":'# frozen_string_literal: true\n\nmodule TRuby\n  # Error raised when an unsupported Ruby version is detected\n  class UnsupportedRubyVersionError < StandardError; end\n\n  # Value object representing a Ruby version with comparison and feature detection\n  #\n  # @example\n  #   version = RubyVersion.parse("3.4")\n  #   version.supports_it_parameter? # => true\n  #   version >= RubyVersion.parse("3.0") # => true\n  #\n  class RubyVersion\n    include Comparable\n\n    # Supported version range\n    MIN_VERSION = [3, 0].freeze\n    MAX_MAJOR = 4\n\n    # Version string pattern: major.minor or major.minor.patch\n    VERSION_REGEX = /\\A(\\d+)\\.(\\d+)(?:\\.(\\d+))?\\z/\n\n    attr_reader :major, :minor, :patch\n\n    # @param major [Integer] major version number\n    # @param minor [Integer] minor version number\n    # @param patch [Integer] patch version number (default: 0)\n    def initialize(major, minor, patch = 0)\n      @major = major\n      @minor = minor\n      @patch = patch\n    end\n\n    # Parse a version string into a RubyVersion object\n    #\n    # @param version_string [String, Numeric] version string (e.g., "3.4", "3.4.1")\n    # @return [RubyVersion] parsed version object\n    # @raise [ArgumentError] if version format is invalid\n    def self.parse(version_string)\n      str = version_string.to_s\n      match = VERSION_REGEX.match(str)\n\n      raise ArgumentError, "Invalid version: #{version_string}" unless match\n\n      new(match[1].to_i, match[2].to_i, (match[3] || 0).to_i)\n    end\n\n    # Get the current Ruby version from the environment\n    #\n    # @return [RubyVersion] current Ruby version\n    def self.current\n      parse(RUBY_VERSION)\n    end\n\n    # Compare two versions\n    #\n    # @param other [RubyVersion] version to compare with\n    # @return [Integer] -1, 0, or 1\n    def <=>(other)\n      [major, minor, patch] <=> [other.major, other.minor, other.patch]\n    end\n\n    # Convert to string representation\n    #\n    # @return [String] version string (e.g., "3.4" or "3.4.1")\n    def to_s\n      patch.zero? ? "#{major}.#{minor}" : "#{major}.#{minor}.#{patch}"\n    end\n\n    # Check if this version is within the supported range (3.0 ~ 4.x)\n    #\n    # @return [Boolean] true if version is supported\n    def supported?\n      self >= self.class.parse("#{MIN_VERSION[0]}.#{MIN_VERSION[1]}") && major <= MAX_MAJOR\n    end\n\n    # Validate that this version is supported, raising an error if not\n    #\n    # @return [RubyVersion] self if valid\n    # @raise [UnsupportedRubyVersionError] if version is not supported\n    def validate!\n      unless supported?\n        raise UnsupportedRubyVersionError,\n              "Ruby #{self}\ub294 \uc9c0\uc6d0\ub418\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4. \uc9c0\uc6d0 \ubc94\uc704: #{MIN_VERSION.join(".")} ~ #{MAX_MAJOR}.x"\n      end\n\n      self\n    end\n\n    # Check if this version supports the `it` implicit block parameter (Ruby 3.4+)\n    #\n    # @return [Boolean] true if `it` parameter is supported\n    def supports_it_parameter?\n      self >= self.class.parse("3.4")\n    end\n\n    # Check if this version supports anonymous block forwarding `def foo(&) ... end` (Ruby 3.1+)\n    #\n    # @return [Boolean] true if anonymous block forwarding is supported\n    def supports_anonymous_block_forwarding?\n      self >= self.class.parse("3.1")\n    end\n\n    # Check if numbered parameters (_1, _2, etc.) raise NameError (Ruby 4.0+)\n    #\n    # @return [Boolean] true if numbered parameters cause errors\n    def numbered_parameters_raise_error?\n      self >= self.class.parse("4.0")\n    end\n  end\nend\n',"lib/t_ruby/runner.rb":'# frozen_string_literal: true\n\nrequire "thor"\n\nmodule TRuby\n  # Thor-based CLI for t-ruby command\n  # Runs .trb files directly without generating intermediate files\n  class RunnerCLI < Thor\n    def self.exit_on_failure?\n      true\n    end\n\n    # Override Thor\'s default behavior to treat unknown arguments as the file to run\n    def self.start(given_args = ARGV, _config = {})\n      # Handle version flag\n      if given_args.include?("--version") || given_args.include?("-v")\n        new.version\n        return\n      end\n\n      # Handle help flag or no arguments\n      if given_args.empty? || given_args.include?("--help") || given_args.include?("-h")\n        new.help\n        return\n      end\n\n      # Treat first argument as file, rest as script arguments\n      file = given_args.first\n      args = given_args[1..] || []\n\n      runner = Runner.new\n      runner.run_file(file, args)\n    end\n\n    desc "FILE [ARGS...]", "Run a .trb file directly without generating files"\n    def run_file(file, *args)\n      runner = Runner.new\n      runner.run_file(file, args)\n    end\n\n    map %w[--version -v] => :version\n    desc "--version, -v", "Show version"\n    def version\n      puts "t-ruby #{VERSION}"\n    end\n\n    desc "--help, -h", "Show help"\n    def help\n      puts <<~HELP\n        t-ruby v#{VERSION} - Run T-Ruby files directly\n\n        Usage:\n          t-ruby <file.trb>              Run a .trb file directly\n          t-ruby <file.trb> [args...]    Run with arguments passed to the script\n          t-ruby --version, -v           Show version\n          t-ruby --help, -h              Show this help\n\n        Examples:\n          t-ruby hello.trb               Run hello.trb\n          t-ruby server.trb 8080         Run with argument 8080\n          t-ruby script.trb foo bar      Run with multiple arguments\n\n        Notes:\n          - No .rb or .rbs files are generated\n          - Type annotations are stripped at runtime\n          - Arguments after the file are passed to ARGV\n      HELP\n    end\n  end\n\n  # Runner class - executes T-Ruby code directly\n  # Can be used as a library or through RunnerCLI\n  class Runner\n    def initialize(config = nil)\n      @config = config || Config.new\n      @compiler = Compiler.new(@config)\n    end\n\n    # Run a .trb file directly\n    # @param input_path [String] Path to the .trb file\n    # @param argv [Array<String>] Arguments to pass to the script via ARGV\n    def run_file(input_path, argv = [])\n      unless File.exist?(input_path)\n        warn "Error: File not found: #{input_path}"\n        exit 1\n      end\n\n      source = File.read(input_path)\n      result = @compiler.compile_string(source)\n\n      if result[:errors].any?\n        result[:errors].each { |e| warn e }\n        exit 1\n      end\n\n      execute_ruby(result[:ruby], input_path, argv)\n    end\n\n    # Run T-Ruby source code from a string\n    # @param source [String] T-Ruby source code\n    # @param filename [String] Filename for error reporting\n    # @param argv [Array<String>] Arguments to pass via ARGV\n    # @return [Boolean] true if execution succeeded\n    def run_string(source, filename: "(t-ruby)", argv: [])\n      result = @compiler.compile_string(source)\n\n      if result[:errors].any?\n        result[:errors].each { |e| warn e }\n        return false\n      end\n\n      execute_ruby(result[:ruby], filename, argv)\n      true\n    end\n\n    private\n\n    # Execute Ruby code with proper script environment\n    # @param ruby_code [String] Ruby code to execute\n    # @param filename [String] Script filename (for $0 and stack traces)\n    # @param argv [Array<String>] Script arguments\n    def execute_ruby(ruby_code, filename, argv)\n      # Set up script environment\n      ARGV.replace(argv)\n      $0 = filename\n\n      # Execute using eval with filename and line number preserved\n      # This ensures stack traces point to the original .trb file\n      TOPLEVEL_BINDING.eval(ruby_code, filename, 1)\n    end\n  end\nend\n',"lib/t_ruby/runtime_validator.rb":'# frozen_string_literal: true\n\nmodule TRuby\n  # Configuration for runtime validation\n  class ValidationConfig\n    attr_accessor :validate_all, :validate_public_only, :raise_on_error, :log_violations, :strict_mode\n\n    def initialize\n      @validate_all = true\n      @validate_public_only = false\n      @raise_on_error = true\n      @log_violations = false\n      @strict_mode = false\n    end\n  end\n\n  # Generates runtime type validation code\n  class RuntimeValidator\n    attr_reader :config\n\n    # Type mappings for runtime checks\n    TYPE_CHECKS = {\n      "String" => ".is_a?(String)",\n      "Integer" => ".is_a?(Integer)",\n      "Float" => ".is_a?(Float)",\n      "Numeric" => ".is_a?(Numeric)",\n      "Boolean" => " == true || %s == false",\n      "Symbol" => ".is_a?(Symbol)",\n      "Array" => ".is_a?(Array)",\n      "Hash" => ".is_a?(Hash)",\n      "nil" => ".nil?",\n      "Object" => ".is_a?(Object)",\n      "Class" => ".is_a?(Class)",\n      "Module" => ".is_a?(Module)",\n      "Proc" => ".is_a?(Proc)",\n      "Regexp" => ".is_a?(Regexp)",\n      "Range" => ".is_a?(Range)",\n      "Time" => ".is_a?(Time)",\n      "Date" => ".is_a?(Date)",\n      "IO" => ".is_a?(IO)",\n      "File" => ".is_a?(File)",\n    }.freeze\n\n    def initialize(config = nil)\n      @config = config || ValidationConfig.new\n    end\n\n    # Generate validation code for a function\n    def generate_function_validation(function_info)\n      validations = []\n\n      # Parameter validations\n      function_info[:params].each do |param|\n        next unless param[:type]\n\n        validation = generate_param_validation(param[:name], param[:type])\n        validations << validation if validation\n      end\n\n      # Return type validation (if specified)\n      if function_info[:return_type]\n        return_validation = generate_return_validation(function_info[:return_type])\n        validations << return_validation if return_validation\n      end\n\n      validations\n    end\n\n    # Generate validation for a single parameter\n    def generate_param_validation(param_name, type_annotation)\n      check_code = generate_type_check(param_name, type_annotation)\n      return nil unless check_code\n\n      error_message = "TypeError: #{param_name} must be #{type_annotation}, got \\#{#{param_name}.class}"\n\n      if @config.raise_on_error\n        "raise #{error_message.inspect.gsub(\'\\#{\', \'#{\')} unless #{check_code}"\n      else\n        "warn #{error_message.inspect.gsub(\'\\#{\', \'#{\')} unless #{check_code}"\n      end\n    end\n\n    # Generate type check expression\n    def generate_type_check(var_name, type_annotation)\n      # Handle nil type\n      return "#{var_name}.nil?" if type_annotation == "nil"\n\n      # Handle union types\n      if type_annotation.include?("|")\n        return generate_union_check(var_name, type_annotation)\n      end\n\n      # Handle generic types\n      if type_annotation.include?("<")\n        return generate_generic_check(var_name, type_annotation)\n      end\n\n      # Handle intersection types\n      if type_annotation.include?("&")\n        return generate_intersection_check(var_name, type_annotation)\n      end\n\n      # Handle optional types (ending with ?)\n      if type_annotation.end_with?("?")\n        base_type = type_annotation[0..-2]\n        base_check = generate_simple_type_check(var_name, base_type)\n        return "(#{var_name}.nil? || #{base_check})"\n      end\n\n      # Simple type check\n      generate_simple_type_check(var_name, type_annotation)\n    end\n\n    # Generate simple type check\n    def generate_simple_type_check(var_name, type_name)\n      if type_name == "Boolean"\n        "(#{var_name} == true || #{var_name} == false)"\n      elsif TYPE_CHECKS.key?(type_name)\n        "#{var_name}#{TYPE_CHECKS[type_name]}"\n      else\n        # Custom type - use is_a? or respond_to?\n        "#{var_name}.is_a?(#{type_name})"\n      end\n    end\n\n    # Generate union type check\n    def generate_union_check(var_name, union_type)\n      types = union_type.split("|").map(&:strip)\n      checks = types.map { |t| generate_type_check(var_name, t) }\n      "(#{checks.join(" || ")})"\n    end\n\n    # Generate generic type check\n    def generate_generic_check(var_name, generic_type)\n      match = generic_type.match(/^(\\w+)<(.+)>$/)\n      return nil unless match\n\n      container_type = match[1]\n      element_type = match[2]\n\n      case container_type\n      when "Array"\n        "#{var_name}.is_a?(Array) && #{var_name}.all? { |_e| #{generate_type_check("_e", element_type)} }"\n      when "Hash"\n        if element_type.include?(",")\n          key_type, value_type = element_type.split(",").map(&:strip)\n          "#{var_name}.is_a?(Hash) && #{var_name}.all? { |_k, _v| #{generate_type_check("_k",\n                                                                                        key_type)} && #{generate_type_check(\n                                                                                          "_v", value_type\n                                                                                        )} }"\n        else\n          "#{var_name}.is_a?(Hash)"\n        end\n      when "Set"\n        "#{var_name}.is_a?(Set) && #{var_name}.all? { |_e| #{generate_type_check("_e", element_type)} }"\n      else\n        # Generic with unknown container - just check container type\n        "#{var_name}.is_a?(#{container_type})"\n      end\n    end\n\n    # Generate intersection type check\n    def generate_intersection_check(var_name, intersection_type)\n      types = intersection_type.split("&").map(&:strip)\n      checks = types.map { |t| generate_type_check(var_name, t) }\n      "(#{checks.join(" && ")})"\n    end\n\n    # Generate return value validation wrapper\n    def generate_return_validation(return_type)\n      {\n        type: :return,\n        check: generate_type_check("_result", return_type),\n        return_type: return_type,\n      }\n    end\n\n    # Transform source code to include runtime validations\n    def transform(source, parse_result)\n      lines = source.split("\\n")\n      output_lines = []\n      in_function = false\n      current_function = nil\n      function_indent = 0\n\n      parse_result[:functions].each do |func|\n        @function_validations ||= {}\n        @function_validations[func[:name]] = generate_function_validation(func)\n      end\n\n      lines.each_with_index do |line, _idx|\n        # Check for function definition\n        if line.match?(/^\\s*def\\s+(\\w+)/)\n          match = line.match(/^(\\s*)def\\s+(\\w+)/)\n          function_indent = match[1].length\n          function_name = match[2]\n\n          # Add validation code after function definition\n          output_lines << line\n\n          if @function_validations && @function_validations[function_name]\n            validations = @function_validations[function_name]\n            param_validations = validations.select { |v| v.is_a?(String) }\n\n            param_validations.each do |validation|\n              output_lines << "#{" " * (function_indent + 2)}#{validation}"\n            end\n          end\n\n          in_function = true\n          current_function = function_name\n        elsif in_function && line.match?(/^\\s*end\\s*$/)\n          # End of function\n          in_function = false\n          current_function = nil\n          output_lines << line\n        else\n          output_lines << line\n        end\n      end\n\n      output_lines.join("\\n")\n    end\n\n    # Generate a validation module that can be included\n    def generate_validation_module(functions)\n      module_code = <<~RUBY\n        # frozen_string_literal: true\n        # Auto-generated runtime type validation module\n\n        module TRubyValidation\n          class TypeError < StandardError; end\n\n          def self.validate_type(value, expected_type, param_name = "value")\n      RUBY\n\n      module_code += <<~RUBY\n          case expected_type\n          when "String"\n            raise TypeError, "\\#{param_name} must be String, got \\#{value.class}" unless value.is_a?(String)\n          when "Integer"\n            raise TypeError, "\\#{param_name} must be Integer, got \\#{value.class}" unless value.is_a?(Integer)\n          when "Float"\n            raise TypeError, "\\#{param_name} must be Float, got \\#{value.class}" unless value.is_a?(Float)\n          when "Boolean"\n            raise TypeError, "\\#{param_name} must be Boolean, got \\#{value.class}" unless value == true || value == false\n          when "Symbol"\n            raise TypeError, "\\#{param_name} must be Symbol, got \\#{value.class}" unless value.is_a?(Symbol)\n          when "Array"\n            raise TypeError, "\\#{param_name} must be Array, got \\#{value.class}" unless value.is_a?(Array)\n          when "Hash"\n            raise TypeError, "\\#{param_name} must be Hash, got \\#{value.class}" unless value.is_a?(Hash)\n          when "nil"\n            raise TypeError, "\\#{param_name} must be nil, got \\#{value.class}" unless value.nil?\n          else\n            # Custom type check\n            begin\n              type_class = Object.const_get(expected_type)\n              raise TypeError, "\\#{param_name} must be \\#{expected_type}, got \\#{value.class}" unless value.is_a?(type_class)\n            rescue NameError\n              # Unknown type, skip validation\n            end\n          end\n          true\n        end\n      RUBY\n\n      # Generate validation methods for each function\n      functions.each do |func|\n        next if func[:params].empty? && !func[:return_type]\n\n        method_name = "validate_#{func[:name]}_params"\n        param_list = func[:params].map { |p| p[:name] }.join(", ")\n\n        module_code += "\\n  def self.#{method_name}(#{param_list})\\n"\n\n        func[:params].each do |param|\n          next unless param[:type]\n\n          module_code += "    validate_type(#{param[:name]}, #{param[:type].inspect}, #{param[:name].inspect})\\n"\n        end\n\n        module_code += "    true\\n  end\\n"\n      end\n\n      module_code += "end\\n"\n      module_code\n    end\n\n    # Check if validation should be applied based on config\n    def should_validate?(visibility)\n      return true if @config.validate_all\n      return visibility == :public if @config.validate_public_only\n\n      false\n    end\n  end\n\n  # Runtime type error\n  class RuntimeTypeError < StandardError\n    attr_reader :expected_type, :actual_type, :value, :location\n\n    def initialize(message, expected_type: nil, actual_type: nil, value: nil, location: nil)\n      super(message)\n      @expected_type = expected_type\n      @actual_type = actual_type\n      @value = value\n      @location = location\n    end\n  end\n\n  # Mixin for adding runtime validation to classes\n  module RuntimeTypeChecks\n    def self.included(base)\n      base.extend(ClassMethods)\n    end\n\n    module ClassMethods\n      def validate_types!\n        @_validate_types = true\n      end\n\n      def skip_type_validation!\n        @_validate_types = false\n      end\n\n      def type_validation_enabled?\n        @_validate_types != false\n      end\n    end\n\n    private\n\n    def validate_param(value, expected_type, param_name)\n      return true unless self.class.type_validation_enabled?\n\n      validator = RuntimeValidator.new\n      check_code = validator.generate_type_check("value", expected_type)\n\n      # Evaluate the check\n      unless eval(check_code)\n        raise RuntimeTypeError.new(\n          "#{param_name} must be #{expected_type}, got #{value.class}",\n          expected_type: expected_type,\n          actual_type: value.class.to_s,\n          value: value\n        )\n      end\n\n      true\n    end\n\n    def validate_return(value, expected_type)\n      return value unless self.class.type_validation_enabled?\n\n      validator = RuntimeValidator.new\n      check_code = validator.generate_type_check("value", expected_type)\n\n      unless eval(check_code)\n        raise RuntimeTypeError.new(\n          "Return value must be #{expected_type}, got #{value.class}",\n          expected_type: expected_type,\n          actual_type: value.class.to_s,\n          value: value\n        )\n      end\n\n      value\n    end\n  end\nend\n',"lib/t_ruby/scanner.rb":'# frozen_string_literal: true\n\nmodule TRuby\n  # Scanner - T-Ruby \uc18c\uc2a4 \ucf54\ub4dc\ub97c \ud1a0\ud070 \uc2a4\ud2b8\ub9bc\uc73c\ub85c \ubcc0\ud658\n  # TypeScript \ucef4\ud30c\uc77c\ub7ec\uc640 \uc720\uc0ac\ud55c \uad6c\uc870\ub85c, \ud30c\uc11c\uc640 \ubd84\ub9ac\ub418\uc5b4 \uc99d\ubd84 \ud30c\uc2f1\uc744 \uc9c0\uc6d0\n  class Scanner\n    # \ud1a0\ud070 \uad6c\uc870\uccb4\n    Token = Struct.new(:type, :value, :start_pos, :end_pos, :line, :column)\n\n    # \uc2a4\uce94 \uc5d0\ub7ec\n    class ScanError < StandardError\n      attr_reader :line, :column, :position\n\n      def initialize(message, line:, column:, position:)\n        @line = line\n        @column = column\n        @position = position\n        super("#{message} at line #{line}, column #{column}")\n      end\n    end\n\n    # \ud0a4\uc6cc\ub4dc \ub9f5\n    KEYWORDS = {\n      "def" => :def,\n      "end" => :end,\n      "class" => :class,\n      "module" => :module,\n      "if" => :if,\n      "unless" => :unless,\n      "else" => :else,\n      "elsif" => :elsif,\n      "return" => :return,\n      "type" => :type,\n      "interface" => :interface,\n      "public" => :public,\n      "private" => :private,\n      "protected" => :protected,\n      "true" => true,\n      "false" => false,\n      "nil" => :nil,\n      "while" => :while,\n      "until" => :until,\n      "for" => :for,\n      "do" => :do,\n      "begin" => :begin,\n      "rescue" => :rescue,\n      "ensure" => :ensure,\n      "case" => :case,\n      "when" => :when,\n      "then" => :then,\n      "and" => :and,\n      "or" => :or,\n      "not" => :not,\n      "in" => :in,\n      "self" => :self,\n      "super" => :super,\n      "yield" => :yield,\n      "break" => :break,\n      "next" => :next,\n      "redo" => :redo,\n      "retry" => :retry,\n      "raise" => :raise,\n      "alias" => :alias,\n      "defined?" => :defined,\n      "__FILE__" => :__file__,\n      "__LINE__" => :__line__,\n      "__ENCODING__" => :__encoding__,\n    }.freeze\n\n    def initialize(source)\n      @source = source\n      @position = 0\n      @line = 1\n      @column = 1\n      @tokens = []\n      @token_index = 0\n      @scanned = false\n    end\n\n    # \uc804\uccb4 \ud1a0\ud070\ud654 (\uce90\uc2f1\uc6a9)\n    def scan_all\n      return @tokens if @scanned\n\n      @tokens = []\n      @position = 0\n      @line = 1\n      @column = 1\n\n      while @position < @source.length\n        token = scan_token\n        @tokens << token if token\n      end\n\n      @tokens << Token.new(:eof, "", @position, @position, @line, @column)\n      @scanned = true\n      @tokens\n    end\n\n    # \ub2e8\uc77c \ud1a0\ud070 \ubc18\ud658 (\uc2a4\ud2b8\ub9ac\ubc0d\uc6a9)\n    def next_token\n      scan_all unless @scanned\n\n      token = @tokens[@token_index]\n      @token_index += 1 unless token&.type == :eof\n      token || @tokens.last\n    end\n\n    # lookahead\n    def peek(n = 1)\n      scan_all unless @scanned\n\n      if n == 1\n        @tokens[@token_index] || @tokens.last\n      else\n        @tokens[@token_index, n] || [@tokens.last]\n      end\n    end\n\n    # \ud1a0\ud070 \uc778\ub371\uc2a4 \ub9ac\uc14b\n    def reset\n      @token_index = 0\n    end\n\n    private\n\n    def scan_token\n      skip_whitespace\n\n      return nil if @position >= @source.length\n\n      start_pos = @position\n      start_line = @line\n      start_column = @column\n      char = current_char\n\n      case char\n      when "\\n"\n        scan_newline\n      when "#"\n        scan_comment\n      when \'"\'\n        scan_double_quoted_string\n      when "\'"\n        scan_single_quoted_string\n      when ":"\n        scan_colon_or_symbol\n      when "@"\n        scan_instance_or_class_variable\n      when "$"\n        scan_global_variable\n      when /[a-z_\\p{L}]/i\n        scan_identifier_or_keyword\n      when /[0-9]/\n        scan_number\n      when "<"\n        scan_less_than_or_heredoc\n      when ">"\n        scan_greater_than\n      when "="\n        scan_equals\n      when "!"\n        scan_bang\n      when "&"\n        scan_ampersand\n      when "|"\n        scan_pipe\n      when "+"\n        scan_plus\n      when "-"\n        scan_minus_or_arrow\n      when "*"\n        scan_star\n      when "/"\n        scan_slash\n      when "%"\n        scan_percent\n      when "?"\n        advance\n        Token.new(:question, "?", start_pos, @position, start_line, start_column)\n      when "("\n        advance\n        Token.new(:lparen, "(", start_pos, @position, start_line, start_column)\n      when ")"\n        advance\n        Token.new(:rparen, ")", start_pos, @position, start_line, start_column)\n      when "["\n        advance\n        Token.new(:lbracket, "[", start_pos, @position, start_line, start_column)\n      when "]"\n        advance\n        Token.new(:rbracket, "]", start_pos, @position, start_line, start_column)\n      when "{"\n        advance\n        Token.new(:lbrace, "{", start_pos, @position, start_line, start_column)\n      when "}"\n        advance\n        Token.new(:rbrace, "}", start_pos, @position, start_line, start_column)\n      when ","\n        advance\n        Token.new(:comma, ",", start_pos, @position, start_line, start_column)\n      when "."\n        advance\n        Token.new(:dot, ".", start_pos, @position, start_line, start_column)\n      else\n        raise ScanError.new(\n          "Unexpected character \'#{char}\'",\n          line: start_line,\n          column: start_column,\n          position: start_pos\n        )\n      end\n    end\n\n    def scan_newline\n      start_pos = @position\n      start_line = @line\n      start_column = @column\n\n      advance\n      @line += 1\n      @column = 1\n\n      Token.new(:newline, "\\n", start_pos, @position, start_line, start_column)\n    end\n\n    def scan_comment\n      start_pos = @position\n      start_line = @line\n      start_column = @column\n\n      value = ""\n      while @position < @source.length && current_char != "\\n"\n        value += current_char\n        advance\n      end\n\n      Token.new(:comment, value, start_pos, @position, start_line, start_column)\n    end\n\n    def scan_double_quoted_string\n      start_pos = @position\n      start_line = @line\n      start_column = @column\n\n      # \ubcf4\uac04\uc774 \uc788\ub294\uc9c0 \ud655\uc778\uc744 \uc704\ud574 \uba3c\uc800 \uc2a4\uce94\n      advance # skip opening "\n\n      has_interpolation = false\n      temp_pos = @position\n      while temp_pos < @source.length\n        c = @source[temp_pos]\n        break if c == \'"\' && (temp_pos == @position || @source[temp_pos - 1] != "\\\\")\n\n        if c == "#" && temp_pos + 1 < @source.length && @source[temp_pos + 1] == "{"\n          has_interpolation = true\n          break\n        end\n        temp_pos += 1\n      end\n\n      @position = start_pos + 1 # reset to after opening "\n\n      if has_interpolation\n        scan_interpolated_string(start_pos, start_line, start_column)\n      else\n        scan_simple_string(start_pos, start_line, start_column, \'"\')\n      end\n    end\n\n    def scan_interpolated_string(start_pos, start_line, start_column)\n      # string_start \ud1a0\ud070 \ubc18\ud658\n      @tokens << Token.new(:string_start, \'"\', start_pos, start_pos + 1, start_line, start_column)\n\n      content = ""\n      content_start = @position\n      content_line = @line\n      content_column = @column\n\n      while @position < @source.length\n        char = current_char\n\n        if char == \'"\'\n          # \ubb38\uc790\uc5f4 \ub05d\n          if content.length.positive?\n            @tokens << Token.new(:string_content, content, content_start, @position, content_line, content_column)\n          end\n          advance\n          return Token.new(:string_end, \'"\', @position - 1, @position, @line, @column - 1)\n        elsif char == "\\\\" && peek_char\n          # \uc774\uc2a4\ucf00\uc774\ud504 \uc2dc\ud000\uc2a4\n          content += char\n          advance\n          content += current_char if @position < @source.length\n          advance\n        elsif char == "#" && peek_char == "{"\n          # \ubcf4\uac04 \uc2dc\uc791\n          if content.length.positive?\n            @tokens << Token.new(:string_content, content, content_start, @position, content_line, content_column)\n            content = ""\n          end\n\n          interp_start = @position\n          advance # skip #\n          advance # skip {\n          @tokens << Token.new(:interpolation_start, \'#{\', interp_start, @position, @line, @column - 2)\n\n          # \ubcf4\uac04 \ub0b4\ubd80 \ud1a0\ud070 \uc2a4\uce94 (\uc911\ucca9\ub41c {} \uace0\ub824)\n          scan_interpolation_content\n\n          content_start = @position\n          content_line = @line\n          content_column = @column\n        else\n          content += char\n          advance\n        end\n      end\n\n      raise ScanError.new(\n        "Unterminated string",\n        line: start_line,\n        column: start_column,\n        position: start_pos\n      )\n    end\n\n    def scan_interpolation_content\n      depth = 1\n\n      while @position < @source.length && depth.positive?\n        skip_whitespace_in_interpolation\n\n        break if @position >= @source.length\n\n        char = current_char\n\n        if char == "}"\n          depth -= 1\n          if depth.zero?\n            interp_end_pos = @position\n            advance\n            @tokens << Token.new(:interpolation_end, "}", interp_end_pos, @position, @line, @column - 1)\n            return\n          end\n        elsif char == "{"\n          depth += 1\n        end\n\n        # \ubcf4\uac04 \ub0b4\ubd80\uc758 \ud1a0\ud070 \uc2a4\uce94\n        token = scan_token\n        @tokens << token if token\n      end\n    end\n\n    def skip_whitespace_in_interpolation\n      advance while @position < @source.length && current_char =~ /[ \\t]/\n    end\n\n    def scan_simple_string(start_pos, start_line, start_column, quote)\n      value = quote\n\n      while @position < @source.length\n        char = current_char\n\n        if char == quote\n          value += char\n          advance\n          return Token.new(:string, value, start_pos, @position, start_line, start_column)\n        elsif char == "\\\\" && peek_char\n          value += char\n          advance\n          value += current_char\n          advance\n        elsif char == "\\n"\n          raise ScanError.new(\n            "Unterminated string",\n            line: start_line,\n            column: start_column,\n            position: start_pos\n          )\n        else\n          value += char\n          advance\n        end\n      end\n\n      raise ScanError.new(\n        "Unterminated string",\n        line: start_line,\n        column: start_column,\n        position: start_pos\n      )\n    end\n\n    def scan_single_quoted_string\n      start_pos = @position\n      start_line = @line\n      start_column = @column\n\n      advance # skip opening \'\n      scan_simple_string(start_pos, start_line, start_column, "\'")\n    end\n\n    def scan_colon_or_symbol\n      start_pos = @position\n      start_line = @line\n      start_column = @column\n\n      advance # skip :\n\n      # \uc2ec\ubcfc\uc778\uc9c0 \ud655\uc778\n      if @position < @source.length && current_char =~ /[a-zA-Z_]/\n        value = ":"\n        while @position < @source.length && current_char =~ /[a-zA-Z0-9_]/\n          value += current_char\n          advance\n        end\n        Token.new(:symbol, value, start_pos, @position, start_line, start_column)\n      else\n        Token.new(:colon, ":", start_pos, @position, start_line, start_column)\n      end\n    end\n\n    def scan_instance_or_class_variable\n      start_pos = @position\n      start_line = @line\n      start_column = @column\n\n      advance # skip first @\n\n      if current_char == "@"\n        # \ud074\ub798\uc2a4 \ubcc0\uc218\n        advance # skip second @\n        value = "@@"\n        while @position < @source.length && current_char =~ /[a-zA-Z0-9_]/\n          value += current_char\n          advance\n        end\n        Token.new(:cvar, value, start_pos, @position, start_line, start_column)\n      else\n        # \uc778\uc2a4\ud134\uc2a4 \ubcc0\uc218\n        value = "@"\n        while @position < @source.length && current_char =~ /[a-zA-Z0-9_]/\n          value += current_char\n          advance\n        end\n        Token.new(:ivar, value, start_pos, @position, start_line, start_column)\n      end\n    end\n\n    def scan_global_variable\n      start_pos = @position\n      start_line = @line\n      start_column = @column\n\n      value = "$"\n      advance # skip $\n\n      while @position < @source.length && current_char =~ /[a-zA-Z0-9_]/\n        value += current_char\n        advance\n      end\n\n      Token.new(:gvar, value, start_pos, @position, start_line, start_column)\n    end\n\n    def scan_identifier_or_keyword\n      start_pos = @position\n      start_line = @line\n      start_column = @column\n\n      value = ""\n      # Support Unicode letters (\\p{L}) and numbers (\\p{N}) in identifiers\n      while @position < @source.length && current_char =~ /[\\p{L}\\p{N}_]/\n        value += current_char\n        advance\n      end\n\n      # ? \ub610\ub294 ! \uc811\ubbf8\uc0ac \ucc98\ub9ac\n      if @position < @source.length && ["?", "!"].include?(current_char)\n        value += current_char\n        advance\n      end\n\n      # \ud0a4\uc6cc\ub4dc\uc778\uc9c0 \ud655\uc778\n      if KEYWORDS.key?(value)\n        Token.new(KEYWORDS[value], value, start_pos, @position, start_line, start_column)\n      elsif value[0] =~ /\\p{Lu}/ # Unicode uppercase letter\n        Token.new(:constant, value, start_pos, @position, start_line, start_column)\n      else\n        Token.new(:identifier, value, start_pos, @position, start_line, start_column)\n      end\n    end\n\n    def scan_number\n      start_pos = @position\n      start_line = @line\n      start_column = @column\n\n      value = ""\n      while @position < @source.length && current_char =~ /[0-9_]/\n        value += current_char\n        advance\n      end\n\n      # \uc18c\uc218\uc810 \ud655\uc778\n      if @position < @source.length && current_char == "." && peek_char =~ /[0-9]/\n        value += current_char\n        advance\n        while @position < @source.length && current_char =~ /[0-9_]/\n          value += current_char\n          advance\n        end\n        Token.new(:float, value, start_pos, @position, start_line, start_column)\n      else\n        Token.new(:integer, value, start_pos, @position, start_line, start_column)\n      end\n    end\n\n    def scan_less_than_or_heredoc\n      start_pos = @position\n      start_line = @line\n      start_column = @column\n\n      advance # skip <\n\n      if current_char == "<"\n        # heredoc \ub610\ub294 <<\n        advance\n        # heredoc: <<EOF, <<-EOF, <<~EOF \ud615\ud0dc\n        if current_char =~ /[~-]/ || current_char =~ /[A-Z_]/i\n          scan_heredoc(start_pos, start_line, start_column)\n        else\n          # << \uc5f0\uc0b0\uc790? \uc544\ub2c8\uba74 \ub2e4\uc2dc \ub418\ub3cc\ub9ac\uae30\n          @position = start_pos + 1\n          @column = start_column + 1\n          Token.new(:lt, "<", start_pos, @position, start_line, start_column)\n        end\n      elsif current_char == "="\n        advance\n        if current_char == ">"\n          advance\n          Token.new(:spaceship, "<=>", start_pos, @position, start_line, start_column)\n        else\n          Token.new(:lt_eq, "<=", start_pos, @position, start_line, start_column)\n        end\n      else\n        Token.new(:lt, "<", start_pos, @position, start_line, start_column)\n      end\n    end\n\n    def scan_heredoc(start_pos, start_line, start_column)\n      # <<~, <<-, << \ud615\uc2dd \ucc98\ub9ac\n      squiggly = false\n      dash = false\n\n      if current_char == "~"\n        squiggly = true\n        advance\n      elsif current_char == "-"\n        dash = true\n        advance\n      end\n\n      # \uc885\ub8cc \ub9c8\ucee4 \uc77d\uae30\n      delimiter = ""\n      while @position < @source.length && current_char =~ /[A-Za-z0-9_]/\n        delimiter += current_char\n        advance\n      end\n\n      # \ud604\uc7ac \uc904 \ub05d\uae4c\uc9c0 \uc2a4\ud0b5\n      advance while @position < @source.length && current_char != "\\n"\n      advance if @position < @source.length # skip newline\n      @line += 1\n      @column = 1\n\n      # heredoc \ub0b4\uc6a9 \uc218\uc9d1\n      content = ""\n\n      while @position < @source.length\n        line_content = ""\n\n        while @position < @source.length && current_char != "\\n"\n          line_content += current_char\n          advance\n        end\n\n        # \uc885\ub8cc \ub9c8\ucee4 \ud655\uc778\n        stripped = squiggly || dash ? line_content.lstrip : line_content\n        if stripped == delimiter || line_content.strip == delimiter\n          # heredoc \ub05d\n          value = "<<#{if squiggly\n                         "~"\n                       else\n                         (dash ? "-" : "")\n                       end}#{delimiter}\\n#{content}#{delimiter}"\n          return Token.new(:heredoc, value, start_pos, @position, start_line, start_column)\n        end\n\n        content += line_content\n        next unless @position < @source.length\n\n        content += "\\n"\n        advance # skip newline\n        @line += 1\n        @column = 1\n      end\n\n      # \uc885\ub8cc \ub9c8\ucee4\ub97c \ucc3e\uc9c0 \ubabb\ud568\n      raise ScanError.new(\n        "Unterminated heredoc",\n        line: start_line,\n        column: start_column,\n        position: start_pos\n      )\n    end\n\n    def scan_greater_than\n      start_pos = @position\n      start_line = @line\n      start_column = @column\n\n      advance # skip >\n\n      if current_char == "="\n        advance\n        Token.new(:gt_eq, ">=", start_pos, @position, start_line, start_column)\n      else\n        Token.new(:gt, ">", start_pos, @position, start_line, start_column)\n      end\n    end\n\n    def scan_equals\n      start_pos = @position\n      start_line = @line\n      start_column = @column\n\n      advance # skip =\n\n      case current_char\n      when "="\n        advance\n        Token.new(:eq_eq, "==", start_pos, @position, start_line, start_column)\n      when ">"\n        advance\n        Token.new(:hash_rocket, "=>", start_pos, @position, start_line, start_column)\n      else\n        Token.new(:eq, "=", start_pos, @position, start_line, start_column)\n      end\n    end\n\n    def scan_bang\n      start_pos = @position\n      start_line = @line\n      start_column = @column\n\n      advance # skip !\n\n      if current_char == "="\n        advance\n        Token.new(:bang_eq, "!=", start_pos, @position, start_line, start_column)\n      else\n        Token.new(:bang, "!", start_pos, @position, start_line, start_column)\n      end\n    end\n\n    def scan_ampersand\n      start_pos = @position\n      start_line = @line\n      start_column = @column\n\n      advance # skip &\n\n      if current_char == "&"\n        advance\n        Token.new(:and_and, "&&", start_pos, @position, start_line, start_column)\n      else\n        Token.new(:amp, "&", start_pos, @position, start_line, start_column)\n      end\n    end\n\n    def scan_pipe\n      start_pos = @position\n      start_line = @line\n      start_column = @column\n\n      advance # skip |\n\n      if current_char == "|"\n        advance\n        Token.new(:or_or, "||", start_pos, @position, start_line, start_column)\n      else\n        Token.new(:pipe, "|", start_pos, @position, start_line, start_column)\n      end\n    end\n\n    def scan_plus\n      start_pos = @position\n      start_line = @line\n      start_column = @column\n\n      advance # skip +\n\n      if current_char == "="\n        advance\n        Token.new(:plus_eq, "+=", start_pos, @position, start_line, start_column)\n      else\n        Token.new(:plus, "+", start_pos, @position, start_line, start_column)\n      end\n    end\n\n    def scan_minus_or_arrow\n      start_pos = @position\n      start_line = @line\n      start_column = @column\n\n      advance # skip -\n\n      case current_char\n      when ">"\n        advance\n        Token.new(:arrow, "->", start_pos, @position, start_line, start_column)\n      when "="\n        advance\n        Token.new(:minus_eq, "-=", start_pos, @position, start_line, start_column)\n      else\n        Token.new(:minus, "-", start_pos, @position, start_line, start_column)\n      end\n    end\n\n    def scan_star\n      start_pos = @position\n      start_line = @line\n      start_column = @column\n\n      advance # skip *\n\n      case current_char\n      when "*"\n        advance\n        Token.new(:star_star, "**", start_pos, @position, start_line, start_column)\n      when "="\n        advance\n        Token.new(:star_eq, "*=", start_pos, @position, start_line, start_column)\n      else\n        Token.new(:star, "*", start_pos, @position, start_line, start_column)\n      end\n    end\n\n    def scan_slash\n      start_pos = @position\n      start_line = @line\n      start_column = @column\n\n      advance # skip /\n\n      if current_char == "="\n        advance\n        Token.new(:slash_eq, "/=", start_pos, @position, start_line, start_column)\n      elsif regex_context?\n        # \uc815\uaddc\ud45c\ud604\uc2dd \ub9ac\ud130\ub7f4 \uc2a4\uce94\n        scan_regex(start_pos, start_line, start_column)\n      else\n        Token.new(:slash, "/", start_pos, @position, start_line, start_column)\n      end\n    end\n\n    def regex_context?\n      # Check if / followed by whitespace - always division\n      next_char = @source[@position]\n      return false if [" ", "\\t", "\\n"].include?(next_char)\n\n      # Check previous token context\n      return true if @tokens.empty?\n\n      last_token = @tokens.last\n      return true if last_token.nil?\n\n      # After values/expressions - division operator\n      case last_token.type\n      when :identifier, :constant, :integer, :float, :string, :symbol,\n           :rparen, :rbracket, :rbrace, :ivar, :cvar, :gvar, :regex\n        false\n      # After binary operators - could be regex in `a * /pattern/` but safer to treat as division\n      # unless there\'s no space after /\n      when :plus, :minus, :star, :slash, :percent, :star_star,\n           :lt, :gt, :lt_eq, :gt_eq, :eq_eq, :bang_eq, :spaceship,\n           :and_and, :or_or, :amp, :pipe, :caret\n        # Already checked no whitespace after /, so this could be regex\n        true\n      # After keywords that expect expression - regex context\n      when :kw_if, :kw_unless, :kw_when, :kw_case, :kw_while, :kw_until,\n           :kw_and, :kw_or, :kw_not, :kw_return, :kw_yield\n        true\n      # After opening brackets/parens, comma, equals - regex context\n      when :lparen, :lbracket, :lbrace, :comma, :eq, :colon, :semicolon,\n           :plus_eq, :minus_eq, :star_eq, :slash_eq, :percent_eq,\n           :and_eq, :or_eq, :caret_eq, :arrow\n        true\n      else\n        false\n      end\n    end\n\n    def scan_regex(start_pos, start_line, start_column)\n      value = "/"\n\n      while @position < @source.length\n        char = current_char\n\n        case char\n        when "/"\n          value += char\n          advance\n          # \ud50c\ub798\uadf8 \uc2a4\uce94 (i, m, x, o \ub4f1)\n          while @position < @source.length && current_char =~ /[imxo]/\n            value += current_char\n            advance\n          end\n          return Token.new(:regex, value, start_pos, @position, start_line, start_column)\n        when "\\\\"\n          # \uc774\uc2a4\ucf00\uc774\ud504 \uc2dc\ud000\uc2a4\n          value += char\n          advance\n          if @position < @source.length\n            value += current_char\n            advance\n          end\n        when "\\n"\n          raise ScanError.new(\n            "Unterminated regex",\n            line: start_line,\n            column: start_column,\n            position: start_pos\n          )\n        else\n          value += char\n          advance\n        end\n      end\n\n      raise ScanError.new(\n        "Unterminated regex",\n        line: start_line,\n        column: start_column,\n        position: start_pos\n      )\n    end\n\n    def scan_percent\n      start_pos = @position\n      start_line = @line\n      start_column = @column\n\n      advance # skip %\n\n      if current_char == "="\n        advance\n        Token.new(:percent_eq, "%=", start_pos, @position, start_line, start_column)\n      else\n        Token.new(:percent, "%", start_pos, @position, start_line, start_column)\n      end\n    end\n\n    def skip_whitespace\n      advance while @position < @source.length && current_char =~ /[ \\t\\r]/\n    end\n\n    def current_char\n      @source[@position]\n    end\n\n    def peek_char\n      @source[@position + 1]\n    end\n\n    def advance\n      @column += 1\n      @position += 1\n    end\n  end\nend\n',"lib/t_ruby/smt_solver.rb":'# frozen_string_literal: true\n\nmodule TRuby\n  module SMT\n    #==========================================================================\n    # Logical Formulas\n    #==========================================================================\n\n    # Base class for all formulas\n    class Formula\n      def &(other)\n        And.new(self, other)\n      end\n\n      def |(other)\n        Or.new(self, other)\n      end\n\n      def !\n        Not.new(self)\n      end\n\n      def implies(other)\n        Implies.new(self, other)\n      end\n\n      def iff(other)\n        Iff.new(self, other)\n      end\n\n      def free_variables\n        raise NotImplementedError\n      end\n\n      def substitute(bindings)\n        raise NotImplementedError\n      end\n\n      def simplify\n        self\n      end\n\n      def to_cnf\n        raise NotImplementedError\n      end\n    end\n\n    # Boolean constant\n    class BoolConst < Formula\n      attr_reader :value\n\n      def initialize(value)\n        @value = value\n      end\n\n      def free_variables\n        Set.new\n      end\n\n      def substitute(_bindings)\n        self\n      end\n\n      def simplify\n        self\n      end\n\n      def to_cnf\n        @value ? [[]] : [[]]\n      end\n\n      def ==(other)\n        other.is_a?(BoolConst) && other.value == @value\n      end\n\n      def to_s\n        @value.to_s\n      end\n    end\n\n    TRUE = BoolConst.new(true)\n    FALSE = BoolConst.new(false)\n\n    # Propositional variable\n    class Variable < Formula\n      attr_reader :name\n\n      def initialize(name)\n        @name = name.to_s\n      end\n\n      def free_variables\n        Set.new([@name])\n      end\n\n      def substitute(bindings)\n        bindings[@name] || self\n      end\n\n      def to_cnf\n        [[@name]]\n      end\n\n      def ==(other)\n        other.is_a?(Variable) && other.name == @name\n      end\n\n      def hash\n        @name.hash\n      end\n\n      def eql?(other)\n        self == other\n      end\n\n      def to_s\n        @name\n      end\n    end\n\n    # Negation\n    class Not < Formula\n      attr_reader :operand\n\n      def initialize(operand)\n        @operand = operand\n      end\n\n      def free_variables\n        @operand.free_variables\n      end\n\n      def substitute(bindings)\n        Not.new(@operand.substitute(bindings))\n      end\n\n      def simplify\n        inner = @operand.simplify\n        case inner\n        when BoolConst\n          BoolConst.new(!inner.value)\n        when Not\n          inner.operand\n        else\n          Not.new(inner)\n        end\n      end\n\n      def to_cnf\n        case @operand\n        when Variable\n          [["!#{@operand.name}"]]\n        when Not\n          @operand.operand.to_cnf\n        when And\n          # De Morgan: !(A & B) = !A | !B\n          Or.new(Not.new(@operand.left), Not.new(@operand.right)).to_cnf\n        when Or\n          # De Morgan: !(A | B) = !A & !B\n          And.new(Not.new(@operand.left), Not.new(@operand.right)).to_cnf\n        else\n          [["!#{@operand}"]]\n        end\n      end\n\n      def ==(other)\n        other.is_a?(Not) && other.operand == @operand\n      end\n\n      def to_s\n        "!#{@operand}"\n      end\n    end\n\n    # Conjunction\n    class And < Formula\n      attr_reader :left, :right\n\n      def initialize(left, right)\n        @left = left\n        @right = right\n      end\n\n      def free_variables\n        @left.free_variables | @right.free_variables\n      end\n\n      def substitute(bindings)\n        And.new(@left.substitute(bindings), @right.substitute(bindings))\n      end\n\n      def simplify\n        l = @left.simplify\n        r = @right.simplify\n\n        return FALSE if l == FALSE || r == FALSE\n        return r if l == TRUE\n        return l if r == TRUE\n        return l if l == r\n\n        And.new(l, r)\n      end\n\n      def to_cnf\n        @left.to_cnf + @right.to_cnf\n      end\n\n      def ==(other)\n        other.is_a?(And) && other.left == @left && other.right == @right\n      end\n\n      def to_s\n        "(#{@left} && #{@right})"\n      end\n    end\n\n    # Disjunction\n    class Or < Formula\n      attr_reader :left, :right\n\n      def initialize(left, right)\n        @left = left\n        @right = right\n      end\n\n      def free_variables\n        @left.free_variables | @right.free_variables\n      end\n\n      def substitute(bindings)\n        Or.new(@left.substitute(bindings), @right.substitute(bindings))\n      end\n\n      def simplify\n        l = @left.simplify\n        r = @right.simplify\n\n        return TRUE if l == TRUE || r == TRUE\n        return r if l == FALSE\n        return l if r == FALSE\n        return l if l == r\n\n        Or.new(l, r)\n      end\n\n      def to_cnf\n        left_cnf = @left.to_cnf\n        right_cnf = @right.to_cnf\n\n        # Distribute: (A & B) | C = (A | C) & (B | C)\n        result = []\n        left_cnf.each do |left_clause|\n          right_cnf.each do |right_clause|\n            result << (left_clause + right_clause).uniq\n          end\n        end\n        result\n      end\n\n      def ==(other)\n        other.is_a?(Or) && other.left == @left && other.right == @right\n      end\n\n      def to_s\n        "(#{@left} || #{@right})"\n      end\n    end\n\n    # Implication\n    class Implies < Formula\n      attr_reader :antecedent, :consequent\n\n      def initialize(antecedent, consequent)\n        @antecedent = antecedent\n        @consequent = consequent\n      end\n\n      def free_variables\n        @antecedent.free_variables | @consequent.free_variables\n      end\n\n      def substitute(bindings)\n        Implies.new(@antecedent.substitute(bindings), @consequent.substitute(bindings))\n      end\n\n      def simplify\n        # A -> B = !A | B\n        Or.new(Not.new(@antecedent), @consequent).simplify\n      end\n\n      def to_cnf\n        # A -> B = !A | B\n        Or.new(Not.new(@antecedent), @consequent).to_cnf\n      end\n\n      def ==(other)\n        other.is_a?(Implies) && other.antecedent == @antecedent && other.consequent == @consequent\n      end\n\n      def to_s\n        "(#{@antecedent} -> #{@consequent})"\n      end\n    end\n\n    # Biconditional\n    class Iff < Formula\n      attr_reader :left, :right\n\n      def initialize(left, right)\n        @left = left\n        @right = right\n      end\n\n      def free_variables\n        @left.free_variables | @right.free_variables\n      end\n\n      def substitute(bindings)\n        Iff.new(@left.substitute(bindings), @right.substitute(bindings))\n      end\n\n      def simplify\n        # A <-> B = (A -> B) & (B -> A)\n        And.new(Implies.new(@left, @right), Implies.new(@right, @left)).simplify\n      end\n\n      def to_cnf\n        And.new(Implies.new(@left, @right), Implies.new(@right, @left)).to_cnf\n      end\n\n      def ==(other)\n        other.is_a?(Iff) && other.left == @left && other.right == @right\n      end\n\n      def to_s\n        "(#{@left} <-> #{@right})"\n      end\n    end\n\n    #==========================================================================\n    # Type Constraints\n    #==========================================================================\n\n    # Type variable\n    class TypeVar < Formula\n      attr_reader :name, :bounds\n\n      def initialize(name, bounds: nil)\n        @name = name.to_s\n        @bounds = bounds # { upper: Type, lower: Type }\n      end\n\n      def free_variables\n        Set.new([@name])\n      end\n\n      def substitute(bindings)\n        bindings[@name] || self\n      end\n\n      def to_cnf\n        [[@name]]\n      end\n\n      def ==(other)\n        other.is_a?(TypeVar) && other.name == @name\n      end\n\n      def hash\n        @name.hash\n      end\n\n      def eql?(other)\n        self == other\n      end\n\n      def to_s\n        @name\n      end\n    end\n\n    # Subtype constraint: A <: B (A is subtype of B)\n    class Subtype < Formula\n      attr_reader :subtype, :supertype\n\n      def initialize(subtype, supertype)\n        @subtype = subtype\n        @supertype = supertype\n      end\n\n      def free_variables\n        vars = Set.new\n        vars.add(@subtype.name) if @subtype.is_a?(TypeVar)\n        vars.add(@supertype.name) if @supertype.is_a?(TypeVar)\n        vars\n      end\n\n      def substitute(bindings)\n        sub = @subtype.is_a?(TypeVar) ? (bindings[@subtype.name] || @subtype) : @subtype\n        sup = @supertype.is_a?(TypeVar) ? (bindings[@supertype.name] || @supertype) : @supertype\n        Subtype.new(sub, sup)\n      end\n\n      def simplify\n        self\n      end\n\n      def to_cnf\n        [["#{@subtype}<:#{@supertype}"]]\n      end\n\n      def ==(other)\n        other.is_a?(Subtype) && other.subtype == @subtype && other.supertype == @supertype\n      end\n\n      def to_s\n        "#{@subtype} <: #{@supertype}"\n      end\n    end\n\n    # Type equality: A = B\n    class TypeEqual < Formula\n      attr_reader :left, :right\n\n      def initialize(left, right)\n        @left = left\n        @right = right\n      end\n\n      def free_variables\n        vars = Set.new\n        vars.add(@left.name) if @left.is_a?(TypeVar)\n        vars.add(@right.name) if @right.is_a?(TypeVar)\n        vars\n      end\n\n      def substitute(bindings)\n        l = @left.is_a?(TypeVar) ? (bindings[@left.name] || @left) : @left\n        r = @right.is_a?(TypeVar) ? (bindings[@right.name] || @right) : @right\n        TypeEqual.new(l, r)\n      end\n\n      def simplify\n        return TRUE if @left == @right\n\n        self\n      end\n\n      def to_cnf\n        [["#{@left}=#{@right}"]]\n      end\n\n      def ==(other)\n        other.is_a?(TypeEqual) && other.left == @left && other.right == @right\n      end\n\n      def to_s\n        "#{@left} = #{@right}"\n      end\n    end\n\n    # Instance constraint: T has property P\n    class HasProperty < Formula\n      attr_reader :type_var, :property, :property_type\n\n      def initialize(type_var, property, property_type)\n        @type_var = type_var\n        @property = property\n        @property_type = property_type\n      end\n\n      def free_variables\n        vars = Set.new\n        vars.add(@type_var.name) if @type_var.is_a?(TypeVar)\n        vars.add(@property_type.name) if @property_type.is_a?(TypeVar)\n        vars\n      end\n\n      def substitute(bindings)\n        tv = @type_var.is_a?(TypeVar) ? (bindings[@type_var.name] || @type_var) : @type_var\n        pt = @property_type.is_a?(TypeVar) ? (bindings[@property_type.name] || @property_type) : @property_type\n        HasProperty.new(tv, @property, pt)\n      end\n\n      def to_cnf\n        [["#{@type_var}.#{@property}:#{@property_type}"]]\n      end\n\n      def to_s\n        "#{@type_var} has #{@property}: #{@property_type}"\n      end\n    end\n\n    #==========================================================================\n    # Concrete Types for Solver\n    #==========================================================================\n\n    class ConcreteType\n      attr_reader :name\n\n      def initialize(name)\n        @name = name\n      end\n\n      def ==(other)\n        other.is_a?(ConcreteType) && other.name == @name\n      end\n\n      def hash\n        @name.hash\n      end\n\n      def eql?(other)\n        self == other\n      end\n\n      def to_s\n        @name\n      end\n    end\n\n    #==========================================================================\n    # SAT Solver (DPLL Algorithm)\n    #==========================================================================\n\n    class SATSolver\n      attr_reader :assignments, :conflicts\n\n      def initialize\n        @assignments = {}\n        @conflicts = []\n      end\n\n      # Solve CNF formula\n      def solve(cnf)\n        @assignments = {}\n        @conflicts = []\n\n        dpll(cnf.dup, {})\n      end\n\n      private\n\n      def dpll(clauses, assignment)\n        # Unit propagation\n        loop do\n          unit = find_unit_clause(clauses)\n          break unless unit\n\n          var, value = parse_literal(unit)\n          assignment[var] = value\n          clauses = propagate(clauses, var, value)\n\n          return nil if clauses.any?(&:empty?) # Conflict\n        end\n\n        # All clauses satisfied\n        return assignment if clauses.empty?\n\n        # Check for empty clause (conflict)\n        return nil if clauses.any?(&:empty?)\n\n        # Choose variable\n        var = choose_variable(clauses)\n        return assignment unless var\n\n        # Try true\n        result = dpll(propagate(clauses.dup, var, true), assignment.merge(var => true))\n        return result if result\n\n        # Try false\n        dpll(propagate(clauses.dup, var, false), assignment.merge(var => false))\n      end\n\n      def find_unit_clause(clauses)\n        clauses.each do |clause|\n          return clause.first if clause.length == 1\n        end\n        nil\n      end\n\n      def parse_literal(literal)\n        if literal.start_with?("!")\n          [literal[1..], false]\n        else\n          [literal, true]\n        end\n      end\n\n      def propagate(clauses, var, value)\n        result = []\n\n        clauses.each do |clause|\n          # If clause contains literal with matching polarity, clause is satisfied\n          satisfied = clause.any? do |lit|\n            lit_var, lit_value = parse_literal(lit)\n            lit_var == var && lit_value == value\n          end\n\n          next if satisfied\n\n          # Remove literals with opposite polarity\n          new_clause = clause.reject do |lit|\n            lit_var, lit_value = parse_literal(lit)\n            lit_var == var && lit_value != value\n          end\n\n          result << new_clause\n        end\n\n        result\n      end\n\n      def choose_variable(clauses)\n        # VSIDS-like heuristic: choose most frequent variable\n        counts = Hash.new(0)\n\n        clauses.each do |clause|\n          clause.each do |lit|\n            var, = parse_literal(lit)\n            counts[var] += 1\n          end\n        end\n\n        counts.max_by { |_, v| v }&.first\n      end\n    end\n\n    #==========================================================================\n    # Type Constraint Solver\n    #==========================================================================\n\n    class ConstraintSolver\n      attr_reader :constraints, :solution, :errors\n\n      # Type hierarchy (built-in)\n      TYPE_HIERARCHY = {\n        "Integer" => %w[Numeric Object],\n        "Float" => %w[Numeric Object],\n        "Numeric" => ["Object"],\n        "String" => ["Object"],\n        "Array" => %w[Enumerable Object],\n        "Hash" => %w[Enumerable Object],\n        "Enumerable" => ["Object"],\n        "Boolean" => ["Object"],\n        "Symbol" => ["Object"],\n        "nil" => ["Object"],\n        "Object" => [],\n      }.freeze\n\n      def initialize\n        @constraints = []\n        @solution = {}\n        @errors = []\n        @type_vars = {}\n      end\n\n      # Create a new type variable\n      def fresh_var(prefix = "T")\n        name = "#{prefix}#{@type_vars.length}"\n        var = TypeVar.new(name)\n        @type_vars[name] = var\n        var\n      end\n\n      # Add constraint\n      def add_constraint(constraint)\n        @constraints << constraint\n      end\n\n      # Add subtype constraint\n      def add_subtype(sub, sup)\n        add_constraint(Subtype.new(sub, sup))\n      end\n\n      # Add equality constraint\n      def add_equal(left, right)\n        add_constraint(TypeEqual.new(left, right))\n      end\n\n      # Solve all constraints\n      def solve\n        @solution = {}\n        @errors = []\n\n        # Phase 1: Unification\n        unified = unify_constraints\n\n        # Phase 2: Subtype checking\n        check_subtypes(unified) if @errors.empty?\n\n        # Phase 3: Instantiation\n        instantiate_remaining if @errors.empty?\n\n        {\n          success: @errors.empty?,\n          solution: @solution,\n          errors: @errors,\n        }\n      end\n\n      # Check if type A is subtype of type B\n      def subtype?(sub, sup)\n        return true if sub == sup\n        return true if sup.to_s == "Object"\n        return true if sub.to_s == "nil" # nil is subtype of everything (nullable)\n\n        sub_name = sub.is_a?(ConcreteType) ? sub.name : sub.to_s\n        sup_name = sup.is_a?(ConcreteType) ? sup.name : sup.to_s\n\n        # Check type hierarchy\n        ancestors = TYPE_HIERARCHY[sub_name] || []\n        return true if ancestors.include?(sup_name)\n\n        # Check transitive closure\n        ancestors.any? { |a| subtype?(ConcreteType.new(a), sup) }\n      end\n\n      # Infer type from constraints\n      def infer(var)\n        @solution[var.name] || @solution[var.to_s]\n      end\n\n      private\n\n      def unify_constraints\n        worklist = @constraints.dup\n\n        while (constraint = worklist.shift)\n          case constraint\n          when TypeEqual\n            result = unify(constraint.left, constraint.right)\n            if result\n              # Apply substitution to remaining constraints\n              worklist = worklist.map { |c| c.substitute(result) }\n              @solution.merge!(result)\n            else\n              @errors << "Cannot unify #{constraint.left} with #{constraint.right}"\n            end\n          end\n        end\n\n        @constraints.reject { |c| c.is_a?(TypeEqual) }\n      end\n\n      def unify(left, right)\n        return {} if left == right\n\n        # If left is type variable, bind it\n        if left.is_a?(TypeVar)\n          return nil if occurs_check(left, right)\n\n          return { left.name => right }\n        end\n\n        # If right is type variable, bind it\n        if right.is_a?(TypeVar)\n          return nil if occurs_check(right, left)\n\n          return { right.name => left }\n        end\n\n        # Both are concrete types\n        if left.is_a?(ConcreteType) && right.is_a?(ConcreteType)\n          return {} if left.name == right.name\n\n          return nil\n        end\n\n        nil\n      end\n\n      def occurs_check(var, type)\n        return false unless type.respond_to?(:free_variables)\n\n        type.free_variables.include?(var.name)\n      end\n\n      def check_subtypes(remaining_constraints)\n        remaining_constraints.each do |constraint|\n          case constraint\n          when Subtype\n            sub = resolve_type(constraint.subtype)\n            sup = resolve_type(constraint.supertype)\n\n            # Skip if either is still a TypeVar (unresolved)\n            next if sub.is_a?(TypeVar) || sup.is_a?(TypeVar)\n\n            unless subtype?(sub, sup)\n              @errors << "Type #{sub} is not a subtype of #{sup}"\n            end\n          end\n        end\n      end\n\n      def resolve_type(type)\n        case type\n        when TypeVar\n          @solution[type.name] || type\n        when ConcreteType\n          type\n        else\n          ConcreteType.new(type.to_s)\n        end\n      end\n\n      def instantiate_remaining\n        @type_vars.each_key do |name|\n          next if @solution[name]\n\n          # Default to Object if no constraints\n          @solution[name] = ConcreteType.new("Object")\n        end\n      end\n    end\n\n    #==========================================================================\n    # Type Inference Engine using SMT\n    #==========================================================================\n\n    class TypeInferenceEngine\n      attr_reader :solver, :type_env\n\n      def initialize\n        @solver = ConstraintSolver.new\n        @type_env = {} # Variable name -> Type\n      end\n\n      # Infer types for a method\n      def infer_method(method_ir)\n        param_types = {}\n\n        # Create type variables for parameters without annotations\n        method_ir.params.each do |param|\n          param_types[param.name] = if param.type_annotation\n                                      type_from_ir(param.type_annotation)\n                                    else\n                                      @solver.fresh_var("P_#{param.name}")\n                                    end\n          @type_env[param.name] = param_types[param.name]\n        end\n\n        # Create type variable for return type if not annotated\n        return_type = if method_ir.return_type\n                        type_from_ir(method_ir.return_type)\n                      else\n                        @solver.fresh_var("R_#{method_ir.name}")\n                      end\n\n        # Analyze body to generate constraints\n        if method_ir.body\n          infer_body(method_ir.body, return_type)\n        end\n\n        # Solve constraints\n        result = @solver.solve\n\n        if result[:success]\n          # Build inferred signature\n          inferred_params = param_types.transform_values do |type|\n            resolve_type(type, result[:solution])\n          end\n\n          inferred_return = resolve_type(return_type, result[:solution])\n\n          {\n            success: true,\n            params: inferred_params,\n            return_type: inferred_return,\n          }\n        else\n          {\n            success: false,\n            errors: result[:errors],\n          }\n        end\n      end\n\n      # Generate constraints from method body\n      def infer_body(body_ir, expected_return)\n        case body_ir\n        when IR::Block\n          body_ir.statements.each do |stmt|\n            infer_statement(stmt, expected_return)\n          end\n        when IR::Return\n          if body_ir.value\n            value_type = infer_expression(body_ir.value)\n            @solver.add_subtype(value_type, expected_return)\n          end\n        end\n      end\n\n      # Infer statement\n      def infer_statement(stmt, expected_return)\n        case stmt\n        when IR::Assignment\n          value_type = infer_expression(stmt.value)\n          @type_env[stmt.target] = value_type\n\n          if stmt.type_annotation\n            annotated = type_from_ir(stmt.type_annotation)\n            @solver.add_subtype(value_type, annotated)\n          end\n        when IR::Return\n          if stmt.value\n            value_type = infer_expression(stmt.value)\n            @solver.add_subtype(value_type, expected_return)\n          end\n        when IR::Conditional\n          infer_expression(stmt.condition)\n          infer_body(stmt.then_branch, expected_return) if stmt.then_branch\n          infer_body(stmt.else_branch, expected_return) if stmt.else_branch\n        end\n      end\n\n      # Infer expression type\n      def infer_expression(expr)\n        case expr\n        when IR::Literal\n          ConcreteType.new(literal_type(expr.literal_type))\n        when IR::VariableRef\n          @type_env[expr.name] || @solver.fresh_var("V_#{expr.name}")\n        when IR::MethodCall\n          infer_method_call(expr)\n        when IR::BinaryOp\n          infer_binary_op(expr)\n        when IR::ArrayLiteral\n          infer_array_literal(expr)\n        else\n          @solver.fresh_var("E")\n        end\n      end\n\n      private\n\n      def type_from_ir(ir_type)\n        case ir_type\n        when IR::SimpleType\n          ConcreteType.new(ir_type.name)\n        when IR::GenericType\n          # Simplified: just use base type for now\n          ConcreteType.new(ir_type.base)\n        when IR::UnionType\n          # Create fresh var with union constraint\n          @solver.fresh_var("U")\n        when IR::NullableType\n          # T | nil\n          @solver.fresh_var("N")\n        else\n          @solver.fresh_var("T")\n        end\n      end\n\n      def resolve_type(type, solution)\n        case type\n        when TypeVar\n          resolved = solution[type.name]\n          resolved ? resolve_type(resolved, solution) : "Object"\n        when ConcreteType\n          type.name\n        else\n          type.to_s\n        end\n      end\n\n      def literal_type(lit_type)\n        case lit_type\n        when :string then "String"\n        when :integer then "Integer"\n        when :float then "Float"\n        when :boolean then "Boolean"\n        when :symbol then "Symbol"\n        when :nil then "nil"\n        when :array then "Array"\n        when :hash then "Hash"\n        else "Object"\n        end\n      end\n\n      def infer_method_call(call)\n        # Get receiver type\n        receiver_type = if call.receiver\n                          infer_expression(call.receiver)\n                        else\n                          @type_env["self"] || ConcreteType.new("Object")\n                        end\n\n        # Look up method return type\n        return_type = lookup_method_type(receiver_type, call.method_name)\n        return_type || @solver.fresh_var("M_#{call.method_name}")\n      end\n\n      def lookup_method_type(_receiver, method)\n        # Built-in method types\n        method_types = {\n          "to_s" => ConcreteType.new("String"),\n          "to_i" => ConcreteType.new("Integer"),\n          "to_f" => ConcreteType.new("Float"),\n          "length" => ConcreteType.new("Integer"),\n          "size" => ConcreteType.new("Integer"),\n          "empty?" => ConcreteType.new("Boolean"),\n          "nil?" => ConcreteType.new("Boolean"),\n        }\n\n        method_types[method.to_s]\n      end\n\n      def infer_binary_op(expr)\n        left_type = infer_expression(expr.left)\n        right_type = infer_expression(expr.right)\n\n        case expr.operator\n        when "+", "-", "*", "/", "%"\n          # Numeric operations\n          @solver.add_subtype(left_type, ConcreteType.new("Numeric"))\n          @solver.add_subtype(right_type, ConcreteType.new("Numeric"))\n          ConcreteType.new("Numeric")\n        when "==", "!=", "<", ">", "<=", ">="\n          ConcreteType.new("Boolean")\n        when "&&", "||"\n          ConcreteType.new("Boolean")\n        else\n          @solver.fresh_var("Op")\n        end\n      end\n\n      def infer_array_literal(expr)\n        unless expr.elements.empty?\n          element_type = @solver.fresh_var("E")\n          expr.elements.each do |elem|\n            elem_type = infer_expression(elem)\n            @solver.add_subtype(elem_type, element_type)\n          end\n        end\n        ConcreteType.new("Array")\n      end\n    end\n\n    #==========================================================================\n    # DSL for building constraints\n    #==========================================================================\n\n    module DSL\n      def var(name)\n        Variable.new(name)\n      end\n\n      def type_var(name, bounds: nil)\n        TypeVar.new(name, bounds: bounds)\n      end\n\n      def concrete(name)\n        ConcreteType.new(name)\n      end\n\n      def subtype(sub, sup)\n        Subtype.new(sub, sup)\n      end\n\n      def type_equal(left, right)\n        TypeEqual.new(left, right)\n      end\n\n      def has_property(type, prop, prop_type)\n        HasProperty.new(type, prop, prop_type)\n      end\n\n      def all(*constraints)\n        constraints.reduce { |acc, c| acc & c }\n      end\n\n      def any(*constraints)\n        constraints.reduce { |acc, c| acc | c }\n      end\n    end\n  end\nend\n',"lib/t_ruby/string_utils.rb":'# frozen_string_literal: true\n\nmodule TRuby\n  # \ubb38\uc790\uc5f4 \ud30c\uc2f1\uc744 \uc704\ud55c \uacf5\ud1b5 \uc720\ud2f8\ub9ac\ud2f0 \ubaa8\ub4c8\n  # \ud30c\uc11c\uc640 \ucef4\ud30c\uc77c\ub7ec\uc5d0\uc11c \uacf5\uc720\ud558\ub294 \uc911\ucca9 \uad04\ud638 \ucc98\ub9ac \ub85c\uc9c1\n  module StringUtils\n    module_function\n\n    # \uc911\ucca9\ub41c \uad04\ud638\ub97c \uace0\ub824\ud558\uc5ec \ucf64\ub9c8\ub85c \ubb38\uc790\uc5f4 \ubd84\ub9ac\n    # @param content [String] \ubd84\ub9ac\ud560 \ubb38\uc790\uc5f4\n    # @return [Array<String>] \ubd84\ub9ac\ub41c \ubb38\uc790\uc5f4 \ubc30\uc5f4\n    def split_by_comma(content)\n      result = []\n      current = ""\n      depth = 0\n\n      content.each_char do |char|\n        case char\n        when "<", "[", "(", "{"\n          depth += 1\n          current += char\n        when ">", "]", ")", "}"\n          depth -= 1\n          current += char\n        when ","\n          if depth.zero?\n            result << current.strip\n            current = ""\n          else\n            current += char\n          end\n        else\n          current += char\n        end\n      end\n\n      result << current.strip unless current.empty?\n      result\n    end\n\n    # \ud0c0\uc785\uacfc \uae30\ubcf8\uac12 \ubd84\ub9ac: "String = 0" -> ["String", "0"]\n    # \uc911\ucca9\ub41c \uad04\ud638 \ub0b4\ubd80\uc758 = \ub294 \ubb34\uc2dc\n    # @param type_and_default [String] "Type = default" \ud615\ud0dc\uc758 \ubb38\uc790\uc5f4\n    # @return [Array] [type_str, default_value] \ub610\ub294 [type_str, nil]\n    def split_type_and_default(type_and_default)\n      depth = 0\n      equals_pos = nil\n\n      type_and_default.each_char.with_index do |char, i|\n        case char\n        when "<", "[", "(", "{"\n          depth += 1\n        when ">", "]", ")", "}"\n          depth -= 1\n        when "="\n          if depth.zero?\n            equals_pos = i\n            break\n          end\n        end\n      end\n\n      if equals_pos\n        type_str = type_and_default[0...equals_pos].strip\n        default_value = type_and_default[(equals_pos + 1)..].strip\n        [type_str, default_value]\n      else\n        [type_and_default, nil]\n      end\n    end\n\n    # \uae30\ubcf8\uac12\ub9cc \ucd94\ucd9c (\ud0c0\uc785\uc740 \ubc84\ub9bc)\n    # @param type_and_default [String] "Type = default" \ud615\ud0dc\uc758 \ubb38\uc790\uc5f4\n    # @return [String, nil] \uae30\ubcf8\uac12 \ub610\ub294 nil\n    def extract_default_value(type_and_default)\n      _, default_value = split_type_and_default(type_and_default)\n      default_value\n    end\n  end\nend\n',"lib/t_ruby/type_alias_registry.rb":"# frozen_string_literal: true\n\nmodule TRuby\n  # Custom exceptions for type alias errors\n  class DuplicateTypeAliasError < StandardError; end\n  class CircularTypeAliasError < StandardError; end\n  class UndefinedTypeError < StandardError; end\n\n  class TypeAliasRegistry\n    BUILT_IN_TYPES = %w[String Integer Boolean Array Hash Symbol void nil].freeze\n\n    def initialize\n      @aliases = {}\n    end\n\n    def register(name, definition)\n      if @aliases.key?(name)\n        raise DuplicateTypeAliasError, \"Type alias '#{name}' is already defined\"\n      end\n\n      # Check for self-reference\n      if name == definition\n        raise CircularTypeAliasError, \"Type alias '#{name}' cannot reference itself\"\n      end\n\n      # Check for circular references (including longer chains)\n      if would_create_cycle?(name, definition)\n        raise CircularTypeAliasError, \"Circular type alias detected involving '#{name}'\"\n      end\n\n      @aliases[name] = definition\n    end\n\n    def resolve(name)\n      @aliases[name]\n    end\n\n    def all\n      @aliases.dup\n    end\n\n    def clear\n      @aliases.clear\n    end\n\n    def valid_type?(name)\n      return true if BUILT_IN_TYPES.include?(name)\n\n      @aliases.key?(name)\n    end\n\n    def validate_all\n      @aliases.each do |name, definition|\n        check_circular_references(name)\n        check_undefined_types(definition)\n      end\n    end\n\n    private\n\n    def would_create_cycle?(name, definition)\n      # Follow the chain of definitions from 'definition' to see if it leads back to 'name'\n      visited = Set.new\n      current = definition\n\n      # Check each step in the chain\n      until visited.include?(current)\n        return true if current == name\n        return false unless @aliases.key?(current)\n\n        visited.add(current)\n        current = @aliases[current]\n      end\n\n      false\n    end\n\n    def check_circular_references(name, visited = Set.new)\n      return if visited.include?(name)\n\n      visited.add(name)\n      definition = @aliases[name]\n\n      return unless @aliases.key?(definition)\n\n      if visited.include?(definition)\n        raise CircularTypeAliasError, \"Circular type alias detected involving '#{name}'\"\n      end\n\n      check_circular_references(definition, visited)\n    end\n\n    def check_undefined_types(type_name)\n      return if BUILT_IN_TYPES.include?(type_name)\n      return if @aliases.key?(type_name)\n\n      # Ignore generic types for now (e.g., Array<String>, Result<T, E>)\n      return if type_name.include?(\"<\")\n\n      raise UndefinedTypeError, \"Type '#{type_name}' is not defined\"\n    end\n  end\nend\n","lib/t_ruby/type_checker.rb":'# frozen_string_literal: true\n\nmodule TRuby\n  # Represents a type checking error (can be raised as an exception)\n  class TypeCheckError < StandardError\n    attr_reader :error_message, :location, :expected, :actual, :suggestion, :severity\n\n    def initialize(message:, location: nil, expected: nil, actual: nil, suggestion: nil, severity: :error)\n      @error_message = message\n      @location = location\n      @expected = expected\n      @actual = actual\n      @suggestion = suggestion\n      @severity = severity\n      super(build_full_message)\n    end\n\n    def to_diagnostic\n      {\n        severity: @severity,\n        message: @error_message,\n        location: @location,\n        expected: @expected,\n        actual: @actual,\n        suggestion: @suggestion,\n      }\n    end\n\n    private\n\n    def build_full_message\n      parts = [@error_message]\n      parts << "  Expected: #{@expected}" if @expected\n      parts << "  Actual: #{@actual}" if @actual\n      parts << "  Suggestion: #{@suggestion}" if @suggestion\n      parts << "  at #{@location}" if @location\n      parts.join("\\n")\n    end\n  end\n\n  # Type hierarchy for subtype checking\n  class TypeHierarchy\n    NUMERIC_TYPES = %w[Integer Float Numeric].freeze\n    COLLECTION_TYPES = %w[Array Hash Set].freeze\n\n    def initialize\n      @subtypes = {\n        "Integer" => %w[Numeric Object],\n        "Float" => %w[Numeric Object],\n        "Numeric" => ["Object"],\n        "String" => ["Object"],\n        "Symbol" => ["Object"],\n        "Array" => %w[Enumerable Object],\n        "Hash" => %w[Enumerable Object],\n        "Set" => %w[Enumerable Object],\n        "Boolean" => ["Object"],\n        "nil" => ["Object"],\n        "Object" => [],\n      }\n    end\n\n    def subtype_of?(subtype, supertype)\n      return true if subtype == supertype\n      return true if supertype == "Object"\n\n      chain = @subtypes[subtype] || []\n      return true if chain.include?(supertype)\n\n      # Check transitive relationship\n      chain.any? { |t| subtype_of?(t, supertype) }\n    end\n\n    def compatible?(type_a, type_b)\n      subtype_of?(type_a, type_b) || subtype_of?(type_b, type_a)\n    end\n\n    def register_subtype(subtype, supertype)\n      @subtypes[subtype] ||= []\n      @subtypes[subtype] << supertype unless @subtypes[subtype].include?(supertype)\n    end\n\n    def common_supertype(type_a, type_b)\n      return type_a if type_a == type_b\n      return type_a if subtype_of?(type_b, type_a)\n      return type_b if subtype_of?(type_a, type_b)\n\n      # Find common ancestor\n      chain_a = [type_a] + (@subtypes[type_a] || [])\n      chain_b = [type_b] + (@subtypes[type_b] || [])\n\n      common = chain_a & chain_b\n      common.first || "Object"\n    end\n  end\n\n  # Scope for tracking variable types in a block\n  class TypeScope\n    attr_reader :parent, :variables\n\n    def initialize(parent = nil)\n      @parent = parent\n      @variables = {}\n    end\n\n    def define(name, type)\n      @variables[name] = type\n    end\n\n    def lookup(name)\n      @variables[name] || @parent&.lookup(name)\n    end\n\n    def child_scope\n      TypeScope.new(self)\n    end\n  end\n\n  # Flow-sensitive type tracking\n  class FlowContext\n    attr_reader :narrowed_types, :guard_conditions\n\n    def initialize\n      @narrowed_types = {}\n      @guard_conditions = []\n    end\n\n    def narrow(variable, new_type)\n      @narrowed_types[variable] = new_type\n    end\n\n    def get_narrowed_type(variable)\n      @narrowed_types[variable]\n    end\n\n    def push_guard(condition)\n      @guard_conditions.push(condition)\n    end\n\n    def pop_guard\n      @guard_conditions.pop\n    end\n\n    def branch\n      new_context = FlowContext.new\n      @narrowed_types.each { |k, v| new_context.narrow(k, v) }\n      new_context\n    end\n\n    def merge(other)\n      # Merge two branches - types that are narrowed in both become union\n      merged = FlowContext.new\n      all_vars = @narrowed_types.keys | other.narrowed_types.keys\n\n      all_vars.each do |var|\n        type_a = @narrowed_types[var]\n        type_b = other.narrowed_types[var]\n\n        if type_a && type_b\n          if type_a == type_b\n            merged.narrow(var, type_a)\n          else\n            merged.narrow(var, "#{type_a} | #{type_b}")\n          end\n        elsif type_a || type_b\n          merged.narrow(var, type_a || type_b)\n        end\n      end\n\n      merged\n    end\n  end\n\n  # Main type checker with SMT solver integration\n  class TypeChecker\n    attr_reader :errors, :warnings, :hierarchy, :inferencer, :smt_solver, :use_smt\n\n    def initialize(use_smt: true)\n      @errors = []\n      @warnings = []\n      @hierarchy = TypeHierarchy.new\n      @inferencer = TypeInferencer.new\n      @function_signatures = {}\n      @type_aliases = {}\n      @current_scope = TypeScope.new\n      @flow_context = FlowContext.new\n      @use_smt = use_smt\n      @smt_solver = SMT::ConstraintSolver.new if use_smt\n      @smt_inference_engine = SMT::TypeInferenceEngine.new if use_smt\n    end\n\n    # Check an IR program using SMT-based type checking\n    def check_program(ir_program)\n      return check_program_legacy(ir_program) unless @use_smt\n\n      @errors = []\n      @warnings = []\n\n      ir_program.declarations.each do |decl|\n        case decl\n        when IR::TypeAlias\n          register_alias(decl.name, decl.definition)\n        when IR::Interface\n          check_interface(decl)\n        when IR::MethodDef\n          check_method_with_smt(decl)\n        end\n      end\n\n      {\n        success: @errors.empty?,\n        errors: @errors,\n        warnings: @warnings,\n      }\n    end\n\n    # Check a method definition using SMT solver\n    def check_method_with_smt(method_ir)\n      result = @smt_inference_engine.infer_method(method_ir)\n\n      if result[:success]\n        # Store inferred types\n        @function_signatures[method_ir.name] = {\n          params: method_ir.params.map do |p|\n            {\n              name: p.name,\n              type: result[:params][p.name] || infer_param_type(p),\n            }\n          end,\n          return_type: result[:return_type],\n        }\n      else\n        # Add errors from SMT solver\n        result[:errors]&.each do |error|\n          add_error(\n            message: "Type inference error in #{method_ir.name}: #{error}",\n            location: method_ir.location\n          )\n        end\n      end\n\n      result\n    end\n\n    # Check interface implementation\n    def check_interface(interface_ir)\n      interface_ir.members.each do |member|\n        # Validate member type signature\n        if member.type_signature\n          validate_type(member.type_signature)\n        end\n      end\n    end\n\n    # Validate a type node is well-formed\n    def validate_type(type_node)\n      case type_node\n      when IR::SimpleType\n        # Check if type exists\n        unless known_type?(type_node.name)\n          add_warning("Unknown type: #{type_node.name}")\n        end\n      when IR::GenericType\n        # Check base type and type args\n        unless known_type?(type_node.base)\n          add_warning("Unknown generic type: #{type_node.base}")\n        end\n        type_node.type_args.each { |t| validate_type(t) }\n      when IR::UnionType\n        type_node.types.each { |t| validate_type(t) }\n      when IR::IntersectionType\n        type_node.types.each { |t| validate_type(t) }\n      when IR::NullableType\n        validate_type(type_node.inner_type)\n      when IR::FunctionType\n        type_node.param_types.each { |t| validate_type(t) }\n        validate_type(type_node.return_type)\n      end\n    end\n\n    # SMT-based subtype checking\n    def subtype_with_smt?(subtype, supertype)\n      return true if subtype == supertype\n\n      if @use_smt\n        sub = to_smt_type(subtype)\n        sup = to_smt_type(supertype)\n        @smt_solver.subtype?(sub, sup)\n      else\n        @hierarchy.subtype_of?(subtype.to_s, supertype.to_s)\n      end\n    end\n\n    # Convert to SMT type\n    def to_smt_type(type)\n      case type\n      when String\n        SMT::ConcreteType.new(type)\n      when IR::SimpleType\n        SMT::ConcreteType.new(type.name)\n      when SMT::ConcreteType, SMT::TypeVar\n        type\n      else\n        SMT::ConcreteType.new(type.to_s)\n      end\n    end\n\n    # Register a function signature\n    def register_function(name, params:, return_type:)\n      @function_signatures[name] = {\n        params: params,\n        return_type: return_type,\n      }\n    end\n\n    # Register a type alias\n    def register_alias(name, definition)\n      @type_aliases[name] = definition\n    end\n\n    # Check a function call\n    def check_call(function_name, arguments, location: nil)\n      signature = @function_signatures[function_name]\n\n      unless signature\n        add_warning("Unknown function: #{function_name}", location)\n        return nil\n      end\n\n      params = signature[:params]\n\n      # Check argument count\n      if arguments.length != params.length\n        add_error(\n          message: "Wrong number of arguments for #{function_name}",\n          expected: "#{params.length} arguments",\n          actual: "#{arguments.length} arguments",\n          location: location\n        )\n        return nil\n      end\n\n      # Check each argument type\n      params.each_with_index do |param, idx|\n        next unless param[:type]\n\n        arg = arguments[idx]\n        arg_type = infer_type(arg)\n\n        next unless arg_type\n\n        next if type_compatible?(arg_type, param[:type])\n\n        add_error(\n          message: "Type mismatch in argument \'#{param[:name]}\' of #{function_name}",\n          expected: param[:type],\n          actual: arg_type,\n          suggestion: suggest_conversion(arg_type, param[:type]),\n          location: location\n        )\n      end\n\n      signature[:return_type]\n    end\n\n    # Check a return statement\n    def check_return(value, expected_type, location: nil)\n      return true unless expected_type\n\n      actual_type = infer_type(value)\n      return true unless actual_type\n\n      unless type_compatible?(actual_type, expected_type)\n        add_error(\n          message: "Return type mismatch",\n          expected: expected_type,\n          actual: actual_type,\n          suggestion: suggest_conversion(actual_type, expected_type),\n          location: location\n        )\n        return false\n      end\n\n      true\n    end\n\n    # Check variable assignment\n    def check_assignment(variable, value, declared_type: nil, location: nil)\n      value_type = infer_type(value)\n\n      if declared_type && !type_compatible?(value_type, declared_type)\n        add_error(\n          message: "Cannot assign #{value_type} to variable of type #{declared_type}",\n          expected: declared_type,\n          actual: value_type,\n          location: location\n        )\n        return false\n      end\n\n      @current_scope.define(variable, declared_type || value_type)\n      true\n    end\n\n    # Check property access\n    def check_property_access(receiver_type, property_name, location: nil)\n      # Known properties for common types\n      known_properties = {\n        "String" => %w[length size empty? chars bytes],\n        "Array" => %w[length size first last empty? count],\n        "Hash" => %w[keys values size empty? length],\n        "Integer" => %w[abs to_s to_f even? odd? positive? negative?],\n        "Float" => %w[abs to_s to_i ceil floor round],\n      }\n\n      properties = known_properties[receiver_type]\n      return nil unless properties\n\n      unless properties.include?(property_name)\n        add_warning("Property \'#{property_name}\' may not exist on type #{receiver_type}", location)\n      end\n\n      # Return expected type for known properties\n      infer_property_type(receiver_type, property_name)\n    end\n\n    # Check operator usage\n    def check_operator(left_type, operator, right_type, location: nil)\n      # Arithmetic operators\n      if %w[+ - * / %].include?(operator)\n        if left_type == "String" && operator == "+"\n          unless right_type == "String"\n            add_error(\n              message: "Cannot concatenate String with #{right_type}",\n              expected: "String",\n              actual: right_type,\n              suggestion: "Use .to_s to convert to String",\n              location: location\n            )\n          end\n          return "String"\n        end\n\n        unless numeric_type?(left_type) && numeric_type?(right_type)\n          add_error(\n            message: "Operator \'#{operator}\' requires numeric operands",\n            expected: "Numeric",\n            actual: "#{left_type} #{operator} #{right_type}",\n            location: location\n          )\n          return nil\n        end\n\n        # Result type depends on operands\n        return "Float" if left_type == "Float" || right_type == "Float"\n\n        return "Integer"\n      end\n\n      # Comparison operators\n      if %w[== != < > <= >=].include?(operator)\n        return "Boolean"\n      end\n\n      # Logical operators\n      if %w[&& ||].include?(operator)\n        return right_type # Short-circuit returns right operand type\n      end\n\n      nil\n    end\n\n    # Handle conditional type narrowing\n    def narrow_in_conditional(condition, then_scope, else_scope = nil)\n      # Parse type guards from condition\n      if condition.match?(/(\\w+)\\.is_a\\?\\((\\w+)\\)/)\n        match = condition.match(/(\\w+)\\.is_a\\?\\((\\w+)\\)/)\n        var = match[1]\n        type = match[2]\n\n        # In then branch, variable is narrowed to the type\n        then_scope.narrow(var, type)\n\n        # In else branch, variable is NOT that type (can\'t narrow further without more info)\n      end\n\n      if condition.match?(/(\\w+)\\.nil\\?/)\n        match = condition.match(/(\\w+)\\.nil\\?/)\n        var = match[1]\n\n        then_scope.narrow(var, "nil")\n        # In else branch, variable is not nil\n        else_scope&.narrow(var, remove_nil_from_type(@current_scope.lookup(var) || "Object"))\n      end\n\n      return unless condition.match?(/!(\\w+)\\.nil\\?/)\n\n      match = condition.match(/!(\\w+)\\.nil\\?/)\n      var = match[1]\n\n      # Variable is not nil in then branch\n      then_scope.narrow(var, remove_nil_from_type(@current_scope.lookup(var) || "Object"))\n      else_scope&.narrow(var, "nil")\n    end\n\n    # Check a complete function\n    def check_function(function_info, body_lines)\n      @current_scope = TypeScope.new\n\n      # Register parameters in scope\n      function_info[:params].each do |param|\n        @current_scope.define(param[:name], param[:type] || "Object")\n      end\n\n      # Register function signature\n      register_function(\n        function_info[:name],\n        params: function_info[:params],\n        return_type: function_info[:return_type]\n      )\n\n      # Check body (simplified - real implementation would parse AST)\n      body_lines.each_with_index do |line, idx|\n        check_statement(line, location: "line #{idx + 1}")\n      end\n    end\n\n    # Check a statement\n    def check_statement(line, location: nil)\n      line = line.strip\n\n      # Return statement\n      if line.match?(/^return\\s+(.+)/)\n        line.match(/^return\\s+(.+)/)\n        # Would need current function context for proper checking\n        return\n      end\n\n      # Assignment\n      if line.match?(/^(\\w+)\\s*=\\s*(.+)/)\n        match = line.match(/^(\\w+)\\s*=\\s*(.+)/)\n        check_assignment(match[1], match[2], location: location)\n        return\n      end\n\n      # Method call\n      if line.match?(/(\\w+)\\(([^)]*)\\)/)\n        match = line.match(/(\\w+)\\(([^)]*)\\)/)\n        args = match[2].split(",").map(&:strip)\n        check_call(match[1], args, location: location)\n      end\n    end\n\n    # Resolve type alias\n    def resolve_type(type_name)\n      @type_aliases[type_name] || type_name\n    end\n\n    # Clear all state\n    def reset\n      @errors.clear\n      @warnings.clear\n      @function_signatures.clear\n      @type_aliases.clear\n      @current_scope = TypeScope.new\n      @flow_context = FlowContext.new\n      @smt_solver = SMT::ConstraintSolver.new if @use_smt\n      @smt_inference_engine = SMT::TypeInferenceEngine.new if @use_smt\n    end\n\n    # Get all diagnostics\n    def diagnostics\n      @errors.map { |e| e.respond_to?(:to_diagnostic) ? e.to_diagnostic : { type: :error, message: e.to_s } } +\n        @warnings.map { |w| { type: :warning, message: w } }\n    end\n\n    # Check if a type name is known\n    def known_type?(type_name)\n      return true if %w[String Integer Float Boolean Array Hash Symbol void nil Object Numeric\n                        Enumerable].include?(type_name)\n      return true if @type_aliases.key?(type_name)\n\n      false\n    end\n\n    # Infer parameter type from annotation\n    def infer_param_type(param)\n      if param.type_annotation\n        case param.type_annotation\n        when IR::SimpleType\n          param.type_annotation.name\n        else\n          param.type_annotation.to_s\n        end\n      else\n        "Object"\n      end\n    end\n\n    # Legacy program check (without SMT)\n    def check_program_legacy(ir_program)\n      @errors = []\n      @warnings = []\n\n      ir_program.declarations.each do |decl|\n        case decl\n        when IR::TypeAlias\n          register_alias(decl.name, decl.definition)\n        when IR::Interface\n          check_interface(decl)\n        when IR::MethodDef\n          check_function_legacy(decl)\n        end\n      end\n\n      {\n        success: @errors.empty?,\n        errors: @errors,\n        warnings: @warnings,\n      }\n    end\n\n    # Check function without SMT (legacy)\n    def check_function_legacy(method_ir)\n      @current_scope = TypeScope.new\n\n      # Register parameters\n      method_ir.params.each do |param|\n        param_type = infer_param_type(param)\n        @current_scope.define(param.name, param_type)\n      end\n\n      # Register function signature\n      register_function(\n        method_ir.name,\n        params: method_ir.params.map { |p| { name: p.name, type: infer_param_type(p) } },\n        return_type: method_ir.return_type&.to_s || "Object"\n      )\n    end\n\n    private\n\n    def add_error(message:, expected: nil, actual: nil, suggestion: nil, location: nil)\n      @errors << TypeCheckError.new(\n        message: message,\n        expected: expected,\n        actual: actual,\n        suggestion: suggestion,\n        location: location\n      )\n    end\n\n    def add_warning(message, location = nil)\n      full_message = location ? "#{message} at #{location}" : message\n      @warnings << full_message\n    end\n\n    def infer_type(expression)\n      result = @inferencer.infer_expression_type(expression)\n      result&.type\n    end\n\n    def type_compatible?(actual, expected)\n      return true if actual.nil? || expected.nil?\n\n      actual = resolve_type(actual)\n      expected = resolve_type(expected)\n\n      return true if actual == expected\n\n      # Handle union types in expected\n      if expected.include?("|")\n        types = expected.split("|").map(&:strip)\n        return types.any? { |t| type_compatible?(actual, t) }\n      end\n\n      # Handle union types in actual\n      if actual.include?("|")\n        types = actual.split("|").map(&:strip)\n        return types.all? { |t| type_compatible?(t, expected) }\n      end\n\n      # Check hierarchy\n      @hierarchy.subtype_of?(actual, expected)\n    end\n\n    def numeric_type?(type)\n      %w[Integer Float Numeric].include?(type)\n    end\n\n    def suggest_conversion(from_type, to_type)\n      conversions = {\n        %w[Integer String] => "Use .to_s to convert to String",\n        %w[Float String] => "Use .to_s to convert to String",\n        %w[String Integer] => "Use .to_i to convert to Integer",\n        %w[String Float] => "Use .to_f to convert to Float",\n        %w[Integer Float] => "Use .to_f to convert to Float",\n        %w[Float Integer] => "Use .to_i to convert to Integer (may lose precision)",\n        %w[Symbol String] => "Use .to_s to convert to String",\n        %w[String Symbol] => "Use .to_sym to convert to Symbol",\n      }\n\n      conversions[[from_type, to_type]]\n    end\n\n    def infer_property_type(receiver_type, property)\n      property_types = {\n        %w[String length] => "Integer",\n        %w[String size] => "Integer",\n        ["String", "empty?"] => "Boolean",\n        %w[String chars] => "Array<String>",\n        %w[Array length] => "Integer",\n        %w[Array size] => "Integer",\n        ["Array", "empty?"] => "Boolean",\n        %w[Array first] => nil, # Depends on element type\n        %w[Array last] => nil,\n        %w[Hash keys] => "Array",\n        %w[Hash values] => "Array",\n        %w[Hash size] => "Integer",\n        %w[Integer abs] => "Integer",\n        %w[Integer to_s] => "String",\n        %w[Float abs] => "Float",\n        %w[Float to_i] => "Integer",\n      }\n\n      property_types[[receiver_type, property]]\n    end\n\n    def remove_nil_from_type(type)\n      return "Object" if type == "nil"\n\n      if type.include?("|")\n        types = type.split("|").map(&:strip).reject { |t| t == "nil" }\n        return types.length == 1 ? types.first : types.join(" | ")\n      end\n\n      type\n    end\n  end\n\n  # Legacy TypeChecker without SMT (backward compatible)\n  class LegacyTypeChecker < TypeChecker\n    def initialize\n      super(use_smt: false)\n    end\n  end\n\n  # SMT-enhanced type checker with constraint solving\n  class SMTTypeChecker < TypeChecker\n    include SMT::DSL\n\n    def initialize\n      super(use_smt: true)\n    end\n\n    # Add constraint-based type check\n    def check_with_constraints(ir_program, &block)\n      # Allow users to add custom constraints\n      block.call(@smt_solver) if block_given?\n\n      # Run standard type checking\n      check_program(ir_program)\n    end\n\n    # Solve current constraints and return solution\n    def solve_constraints\n      @smt_solver.solve\n    end\n\n    # Get inferred type for a variable\n    def inferred_type(var_name)\n      @smt_solver.infer(SMT::TypeVar.new(var_name))\n    end\n  end\nend\n',"lib/t_ruby/type_env.rb":'# frozen_string_literal: true\n\nmodule TRuby\n  # TypeEnv - \ud0c0\uc785 \ud658\uacbd (\uc2a4\ucf54\ud504 \uccb4\uc778)\n  # TypeScript\uc758 Checker\uc5d0\uc11c \uc2ec\ubcfc \ud0c0\uc785\uc744 \ucd94\uc801\ud558\ub294 \ubc29\uc2dd\uc744 \ucc38\uace0\n  class TypeEnv\n    attr_reader :parent, :bindings, :instance_vars\n\n    def initialize(parent = nil)\n      @parent = parent\n      @bindings = {}      # \uc9c0\uc5ed \ubcc0\uc218 { name => type }\n      @instance_vars = {} # \uc778\uc2a4\ud134\uc2a4 \ubcc0\uc218 { name => type }\n      @class_vars = {}    # \ud074\ub798\uc2a4 \ubcc0\uc218 { name => type }\n    end\n\n    # \uc9c0\uc5ed \ubcc0\uc218 \ud0c0\uc785 \uc815\uc758\n    # @param name [String] \ubcc0\uc218 \uc774\ub984\n    # @param type [IR::TypeNode, String] \ud0c0\uc785\n    def define(name, type)\n      @bindings[name] = type\n    end\n\n    # \ubcc0\uc218 \ud0c0\uc785 \uc870\ud68c (\uc2a4\ucf54\ud504 \uccb4\uc778 \ud0d0\uc0c9)\n    # @param name [String] \ubcc0\uc218 \uc774\ub984\n    # @return [IR::TypeNode, String, nil] \ud0c0\uc785 \ub610\ub294 nil\n    def lookup(name)\n      # \uc778\uc2a4\ud134\uc2a4 \ubcc0\uc218\n      if name.start_with?("@") && !name.start_with?("@@")\n        return lookup_instance_var(name)\n      end\n\n      # \ud074\ub798\uc2a4 \ubcc0\uc218\n      if name.start_with?("@@")\n        return lookup_class_var(name)\n      end\n\n      # \uc9c0\uc5ed \ubcc0\uc218 \ub610\ub294 \uba54\uc11c\ub4dc \ud30c\ub77c\ubbf8\ud130\n      return @bindings[name] if @bindings.key?(name)\n\n      # \ubd80\ubaa8 \uc2a4\ucf54\ud504\uc5d0\uc11c \uac80\uc0c9\n      @parent&.lookup(name)\n    end\n\n    # \uc778\uc2a4\ud134\uc2a4 \ubcc0\uc218 \ud0c0\uc785 \uc815\uc758\n    # @param name [String] \ubcc0\uc218 \uc774\ub984 (@\ud3ec\ud568)\n    # @param type [IR::TypeNode, String] \ud0c0\uc785\n    def define_instance_var(name, type)\n      # @ \uc811\ub450\uc0ac \uc815\uaddc\ud654\n      normalized = name.start_with?("@") ? name : "@#{name}"\n      @instance_vars[normalized] = type\n    end\n\n    # \uc778\uc2a4\ud134\uc2a4 \ubcc0\uc218 \ud0c0\uc785 \uc870\ud68c\n    # @param name [String] \ubcc0\uc218 \uc774\ub984 (@\ud3ec\ud568)\n    # @return [IR::TypeNode, String, nil] \ud0c0\uc785 \ub610\ub294 nil\n    def lookup_instance_var(name)\n      normalized = name.start_with?("@") ? name : "@#{name}"\n      return @instance_vars[normalized] if @instance_vars.key?(normalized)\n\n      @parent&.lookup_instance_var(normalized)\n    end\n\n    # \ud074\ub798\uc2a4 \ubcc0\uc218 \ud0c0\uc785 \uc815\uc758\n    # @param name [String] \ubcc0\uc218 \uc774\ub984 (@@\ud3ec\ud568)\n    # @param type [IR::TypeNode, String] \ud0c0\uc785\n    def define_class_var(name, type)\n      normalized = name.start_with?("@@") ? name : "@@#{name}"\n      @class_vars[normalized] = type\n    end\n\n    # \ud074\ub798\uc2a4 \ubcc0\uc218 \ud0c0\uc785 \uc870\ud68c\n    # @param name [String] \ubcc0\uc218 \uc774\ub984 (@@\ud3ec\ud568)\n    # @return [IR::TypeNode, String, nil] \ud0c0\uc785 \ub610\ub294 nil\n    def lookup_class_var(name)\n      normalized = name.start_with?("@@") ? name : "@@#{name}"\n      return @class_vars[normalized] if @class_vars.key?(normalized)\n\n      @parent&.lookup_class_var(normalized)\n    end\n\n    # \uc790\uc2dd \uc2a4\ucf54\ud504 \uc0dd\uc131 (\ube14\ub85d, \ub78c\ub2e4 \ub4f1)\n    # @return [TypeEnv] \uc0c8 \uc790\uc2dd \uc2a4\ucf54\ud504\n    def child_scope\n      TypeEnv.new(self)\n    end\n\n    # \ud604\uc7ac \uc2a4\ucf54\ud504\uc5d0\uc11c \uc815\uc758\ub41c \ubaa8\ub4e0 \ubcc0\uc218 \uc774\ub984\n    # @return [Array<String>] \ubcc0\uc218 \uc774\ub984 \ubc30\uc5f4\n    def local_names\n      @bindings.keys\n    end\n\n    # \ud604\uc7ac \uc2a4\ucf54\ud504\uc5d0\uc11c \uc815\uc758\ub41c \ubaa8\ub4e0 \uc778\uc2a4\ud134\uc2a4 \ubcc0\uc218 \uc774\ub984\n    # @return [Array<String>] \uc778\uc2a4\ud134\uc2a4 \ubcc0\uc218 \uc774\ub984 \ubc30\uc5f4\n    def instance_var_names\n      @instance_vars.keys\n    end\n\n    # \ubcc0\uc218\uac00 \ud604\uc7ac \uc2a4\ucf54\ud504\uc5d0 \uc815\uc758\ub418\uc5b4 \uc788\ub294\uc9c0 \ud655\uc778\n    # @param name [String] \ubcc0\uc218 \uc774\ub984\n    # @return [Boolean]\n    def defined_locally?(name)\n      @bindings.key?(name)\n    end\n\n    # \uc2a4\ucf54\ud504 \uae4a\uc774 (\ub514\ubc84\uae45\uc6a9)\n    # @return [Integer] \uc2a4\ucf54\ud504 \uae4a\uc774\n    def depth\n      @parent ? @parent.depth + 1 : 0\n    end\n\n    # \uc2a4\ucf54\ud504 \uccb4\uc778\uc5d0\uc11c \ubaa8\ub4e0 \ubcc0\uc218 \uc218\uc9d1\n    # @return [Hash] \ubaa8\ub4e0 \ubcc0\uc218\uc758 { name => type }\n    def all_bindings\n      parent_bindings = @parent ? @parent.all_bindings : {}\n      parent_bindings.merge(@bindings)\n    end\n\n    # \ub514\ubc84\uadf8 \ucd9c\ub825\n    def to_s\n      parts = ["TypeEnv(depth=#{depth})"]\n      parts << "  locals: #{@bindings.keys.join(", ")}" if @bindings.any?\n      parts << "  ivars: #{@instance_vars.keys.join(", ")}" if @instance_vars.any?\n      parts.join("\\n")\n    end\n  end\nend\n',"lib/t_ruby/type_erasure.rb":"# frozen_string_literal: true\n\nmodule TRuby\n  class TypeErasure\n    def initialize(source)\n      @source = source\n    end\n\n    def erase\n      result = @source.dup\n\n      # Remove type alias definitions: type AliasName = TypeDefinition\n      result = result.gsub(/^\\s*type\\s+\\w+\\s*=\\s*.+?$\\n?/, \"\")\n\n      # Remove parameter type annotations: (name: Type) -> (name)\n      # Matches: parameter_name: TypeName\n      result = result.gsub(/\\b(\\w+)\\s*:\\s*\\w+/, '\\1')\n\n      # Remove return type annotations: ): TypeName -> )\n      # Matches: ): TypeName or ): TypeName (with spaces/EOF)\n      result.gsub(/\\)\\s*:\\s*\\w+(\\s|$)/, ')\\1')\n    end\n  end\nend\n","lib/t_ruby/type_inferencer.rb":'# frozen_string_literal: true\n\nmodule TRuby\n  # Represents an inferred type with confidence score\n  class InferredType\n    attr_reader :type, :confidence, :source, :location\n\n    # Confidence levels\n    HIGH = 1.0\n    MEDIUM = 0.7\n    LOW = 0.4\n\n    def initialize(type:, confidence: HIGH, source: :unknown, location: nil)\n      @type = type\n      @confidence = confidence\n      @source = source\n      @location = location\n    end\n\n    def to_s\n      @type\n    end\n\n    def high_confidence?\n      @confidence >= HIGH\n    end\n\n    def medium_confidence?\n      @confidence >= MEDIUM && @confidence < HIGH\n    end\n\n    def low_confidence?\n      @confidence < MEDIUM\n    end\n  end\n\n  # Type inference engine\n  class TypeInferencer\n    attr_reader :inferred_types, :warnings\n\n    # Literal type patterns\n    LITERAL_PATTERNS = {\n      # String literals\n      /^".*"$/ => "String",\n      /^\'.*\'$/ => "String",\n      # Integer literals\n      /^-?\\d+$/ => "Integer",\n      /^0x[0-9a-fA-F]+$/ => "Integer",\n      /^0b[01]+$/ => "Integer",\n      /^0o[0-7]+$/ => "Integer",\n      # Float literals\n      /^-?\\d+\\.\\d+$/ => "Float",\n      /^-?\\d+e[+-]?\\d+$/i => "Float",\n      # Boolean literals\n      /^true$/ => "Boolean",\n      /^false$/ => "Boolean",\n      # Nil literal\n      /^nil$/ => "nil",\n      # Symbol literals\n      /^:\\w+$/ => "Symbol",\n      # Array literals\n      /^\\[.*\\]$/ => "Array",\n      # Hash literals\n      /^\\{.*\\}$/ => "Hash",\n      # Regex literals\n      %r{^/.*/$} => "Regexp",\n    }.freeze\n\n    # Method return type patterns\n    METHOD_RETURN_TYPES = {\n      # String methods\n      "to_s" => "String",\n      "upcase" => "String",\n      "downcase" => "String",\n      "strip" => "String",\n      "chomp" => "String",\n      "reverse" => "String",\n      "capitalize" => "String",\n      "gsub" => "String",\n      "sub" => "String",\n      "chars" => "Array<String>",\n      "split" => "Array<String>",\n      "lines" => "Array<String>",\n      "bytes" => "Array<Integer>",\n      # Integer/Numeric methods\n      "to_i" => "Integer",\n      "to_int" => "Integer",\n      "abs" => "Integer",\n      "ceil" => "Integer",\n      "floor" => "Integer",\n      "round" => "Integer",\n      "to_f" => "Float",\n      # Array methods\n      "length" => "Integer",\n      "size" => "Integer",\n      "count" => "Integer",\n      "first" => nil, # Depends on array type\n      "last" => nil,\n      "empty?" => "Boolean",\n      "any?" => "Boolean",\n      "all?" => "Boolean",\n      "none?" => "Boolean",\n      "include?" => "Boolean",\n      "compact" => nil,\n      "flatten" => "Array",\n      "uniq" => nil,\n      "sort" => nil,\n      "map" => "Array",\n      "select" => "Array",\n      "reject" => "Array",\n      "reduce" => nil,\n      # Hash methods\n      "keys" => "Array",\n      "values" => "Array",\n      "merge" => "Hash",\n      "key?" => "Boolean",\n      "has_key?" => "Boolean",\n      "value?" => "Boolean",\n      "has_value?" => "Boolean",\n      # Object methods\n      "class" => "Class",\n      "object_id" => "Integer",\n      "hash" => "Integer",\n      "frozen?" => "Boolean",\n      "nil?" => "Boolean",\n      "is_a?" => "Boolean",\n      "kind_of?" => "Boolean",\n      "instance_of?" => "Boolean",\n      "respond_to?" => "Boolean",\n      "eql?" => "Boolean",\n      "equal?" => "Boolean",\n      "inspect" => "String",\n      "dup" => nil,\n      "clone" => nil,\n    }.freeze\n\n    # Operator return types\n    OPERATOR_TYPES = {\n      # Arithmetic\n      "+" => :numeric_or_string,\n      "-" => :numeric,\n      "*" => :numeric_or_string,\n      "/" => :numeric,\n      "%" => :numeric,\n      "**" => :numeric,\n      # Comparison\n      "==" => "Boolean",\n      "!=" => "Boolean",\n      "<" => "Boolean",\n      ">" => "Boolean",\n      "<=" => "Boolean",\n      ">=" => "Boolean",\n      "<=>" => "Integer",\n      # Logical\n      "&&" => :propagate,\n      "||" => :propagate,\n      "!" => "Boolean",\n      # Bitwise\n      "&" => "Integer",\n      "|" => "Integer",\n      "^" => "Integer",\n      "~" => "Integer",\n      "<<" => "Integer",\n      ">>" => "Integer",\n    }.freeze\n\n    def initialize\n      @inferred_types = {}\n      @warnings = []\n      @function_contexts = {}\n      @variable_types = {}\n    end\n\n    # Infer type from a literal expression\n    def infer_literal(expression)\n      expr = expression.to_s.strip\n\n      LITERAL_PATTERNS.each do |pattern, type|\n        if expr.match?(pattern)\n          return InferredType.new(\n            type: type,\n            confidence: InferredType::HIGH,\n            source: :literal\n          )\n        end\n      end\n\n      nil\n    end\n\n    # Infer type from method call\n    def infer_method_call(receiver_type, method_name)\n      return_type = METHOD_RETURN_TYPES[method_name.to_s]\n\n      if return_type\n        return InferredType.new(\n          type: return_type,\n          confidence: InferredType::HIGH,\n          source: :method_call\n        )\n      end\n\n      # Try to infer from receiver type and method\n      inferred = infer_from_receiver(receiver_type, method_name)\n      return inferred if inferred\n\n      nil\n    end\n\n    # Infer return type from function body\n    def infer_return_type(function_body)\n      return_statements = extract_return_statements(function_body)\n\n      if return_statements.empty?\n        # Implicit nil return\n        return InferredType.new(\n          type: "nil",\n          confidence: InferredType::MEDIUM,\n          source: :implicit_return\n        )\n      end\n\n      types = return_statements.map do |stmt|\n        infer_expression_type(stmt[:value])\n      end.compact\n\n      if types.empty?\n        return nil\n      end\n\n      if types.uniq.length == 1\n        # All returns have same type\n        return InferredType.new(\n          type: types.first.type,\n          confidence: InferredType::HIGH,\n          source: :return_analysis\n        )\n      end\n\n      # Multiple return types - create union\n      unique_types = types.map(&:type).uniq\n      union_type = unique_types.join(" | ")\n\n      InferredType.new(\n        type: union_type,\n        confidence: InferredType::MEDIUM,\n        source: :return_analysis\n      )\n    end\n\n    # Infer parameter types from usage patterns\n    def infer_parameter_types(function_body, parameters)\n      inferred_params = {}\n\n      parameters.each do |param|\n        param_name = param[:name]\n        usages = find_parameter_usages(function_body, param_name)\n        inferred_type = infer_from_usages(usages)\n\n        if inferred_type\n          inferred_params[param_name] = inferred_type\n        end\n      end\n\n      inferred_params\n    end\n\n    # Infer generic type parameters\n    def infer_generic_params(call_arguments, function_params)\n      generic_bindings = {}\n\n      function_params.each_with_index do |param, idx|\n        next unless param[:type]&.include?("<")\n        next unless call_arguments[idx]\n\n        arg_type = infer_expression_type(call_arguments[idx])\n        next unless arg_type\n\n        # Extract generic parameter from function param type\n        next unless param[:type].match?(/^(\\w+)<(\\w+)>$/)\n\n        match = param[:type].match(/^(\\w+)<(\\w+)>$/)\n        generic_name = match[2]\n\n        # If arg type is concrete, bind it\n        if arg_type.type.match?(/^(\\w+)<(\\w+)>$/)\n          arg_match = arg_type.type.match(/^(\\w+)<(\\w+)>$/)\n          generic_bindings[generic_name] = arg_match[2]\n        end\n      end\n\n      generic_bindings\n    end\n\n    # Infer type narrowing in conditionals\n    def infer_narrowed_type(variable, condition)\n      # Type guard patterns\n      if condition.match?(/#{variable}\\.is_a\\?\\((\\w+)\\)/)\n        match = condition.match(/#{variable}\\.is_a\\?\\((\\w+)\\)/)\n        return InferredType.new(\n          type: match[1],\n          confidence: InferredType::HIGH,\n          source: :type_guard\n        )\n      end\n\n      if condition.match?(/#{variable}\\.nil\\?/)\n        return InferredType.new(\n          type: "nil",\n          confidence: InferredType::HIGH,\n          source: :nil_check\n        )\n      end\n\n      if condition.match?(/#{variable}\\.respond_to\\?\\(:(\\w+)\\)/)\n        # Can\'t determine exact type, but know it has the method\n        return nil\n      end\n\n      nil\n    end\n\n    # Infer type of an expression\n    def infer_expression_type(expression)\n      expr = expression.to_s.strip\n\n      # Try literal inference first\n      literal_type = infer_literal(expr)\n      return literal_type if literal_type\n\n      # Method call inference\n      if expr.match?(/\\.(\\w+)(?:\\(.*\\))?$/)\n        match = expr.match(/(.+)\\.(\\w+)(?:\\(.*\\))?$/)\n        if match\n          receiver = match[1]\n          method = match[2]\n          receiver_type = infer_expression_type(receiver)\n          return infer_method_call(receiver_type&.type, method)\n        end\n      end\n\n      # Variable reference - check recorded types\n      if @variable_types[expr]\n        return @variable_types[expr]\n      end\n\n      # Operator inference\n      OPERATOR_TYPES.each do |op, result_type|\n        if expr.include?(" #{op} ")\n          return infer_operator_result(expr, op, result_type)\n        end\n      end\n\n      # Array construction\n      if expr.start_with?("[") && expr.end_with?("]")\n        return infer_array_type(expr)\n      end\n\n      # Hash construction\n      if expr.start_with?("{") && expr.end_with?("}")\n        return InferredType.new(\n          type: "Hash",\n          confidence: InferredType::HIGH,\n          source: :literal\n        )\n      end\n\n      nil\n    end\n\n    # Record a variable\'s type for later inference\n    def record_variable_type(name, type)\n      @variable_types[name] = type\n    end\n\n    # Get recorded variable type\n    def get_variable_type(name)\n      @variable_types[name]\n    end\n\n    # Add a warning about ambiguous inference\n    def add_warning(message, location: nil)\n      @warnings << { message: message, location: location }\n    end\n\n    # Clear all state\n    def reset\n      @inferred_types.clear\n      @warnings.clear\n      @function_contexts.clear\n      @variable_types.clear\n    end\n\n    private\n\n    def extract_return_statements(body)\n      statements = []\n      lines = body.split("\\n")\n\n      lines.each_with_index do |line, idx|\n        # Explicit return\n        if line.match?(/^\\s*return\\s+(.+)/)\n          match = line.match(/^\\s*return\\s+(.+)/)\n          statements << { type: :explicit, value: match[1].strip, line: idx + 1 }\n        end\n\n        # Last expression (implicit return)\n        # This is simplified - real implementation would need full parsing\n      end\n\n      statements\n    end\n\n    def find_parameter_usages(body, param_name)\n      usages = []\n      lines = body.split("\\n")\n\n      lines.each_with_index do |line, idx|\n        # Method call on parameter\n        if line.match?(/#{param_name}\\.(\\w+)/)\n          matches = line.scan(/#{param_name}\\.(\\w+)/)\n          matches.each do |match|\n            usages << { type: :method_call, method: match[0], line: idx + 1 }\n          end\n        end\n\n        # Arithmetic operation\n        if line.match?(%r{#{param_name}\\s*[+\\-*/%]})\n          usages << { type: :arithmetic, line: idx + 1 }\n        end\n\n        # Comparison\n        if line.match?(/#{param_name}\\s*[<>=!]=?/)\n          usages << { type: :comparison, line: idx + 1 }\n        end\n\n        # String interpolation\n        if line.match?(/#\\{#{param_name}\\}/)\n          usages << { type: :string_interpolation, line: idx + 1 }\n        end\n      end\n\n      usages\n    end\n\n    def infer_from_usages(usages)\n      return nil if usages.empty?\n\n      type_hints = []\n\n      usages.each do |usage|\n        case usage[:type]\n        when :arithmetic\n          type_hints << "Numeric"\n        when :method_call\n          method_type = infer_type_from_method(usage[:method])\n          type_hints << method_type if method_type\n        when :string_interpolation\n          # Could be any type (calls to_s)\n        when :comparison\n          # Most types support comparison\n        end\n      end\n\n      return nil if type_hints.empty?\n\n      # Find most specific type\n      most_common = type_hints.group_by(&:itself)\n                              .max_by { |_, v| v.length }\n                              &.first\n\n      return unless most_common\n\n      InferredType.new(\n        type: most_common,\n        confidence: InferredType::MEDIUM,\n        source: :usage_analysis\n      )\n    end\n\n    def infer_type_from_method(method_name)\n      # Methods that suggest String type\n      string_methods = %w[upcase downcase strip chomp split chars]\n      return "String" if string_methods.include?(method_name)\n\n      # Methods that suggest Array type\n      array_methods = %w[each map select reject push pop shift unshift first last]\n      return "Array" if array_methods.include?(method_name)\n\n      # Methods that suggest Hash type\n      hash_methods = %w[keys values merge fetch]\n      return "Hash" if hash_methods.include?(method_name)\n\n      # Methods that suggest Numeric type\n      numeric_methods = %w[abs ceil floor round to_i to_f times upto downto]\n      return "Numeric" if numeric_methods.include?(method_name)\n\n      nil\n    end\n\n    def infer_from_receiver(receiver_type, method_name)\n      return nil unless receiver_type\n\n      case receiver_type\n      when "String"\n        case method_name.to_s\n        when "length", "size" then "Integer"\n        when "chars", "split", "lines" then "Array<String>"\n        when /^[a-z]/ then "String" # Most String methods return String\n        end\n      when "Array"\n        case method_name.to_s\n        when "length", "size", "count" then "Integer"\n        when "first", "last" then nil # Depends on element type\n        when "join" then "String"\n        end\n      when "Integer", "Float", "Numeric"\n        case method_name.to_s\n        when "to_s" then "String"\n        when "to_i" then "Integer"\n        when "to_f" then "Float"\n        when "abs", "ceil", "floor" then receiver_type\n        end\n      end\n    end\n\n    def infer_operator_result(_expr, _operator, result_type)\n      case result_type\n      when "Boolean"\n        InferredType.new(type: "Boolean", confidence: InferredType::HIGH, source: :operator)\n      when "Integer"\n        InferredType.new(type: "Integer", confidence: InferredType::HIGH, source: :operator)\n      when :numeric\n        # Check operand types\n        InferredType.new(type: "Numeric", confidence: InferredType::MEDIUM, source: :operator)\n      when :numeric_or_string\n        # Could be numeric or string concatenation\n        InferredType.new(type: "Numeric | String", confidence: InferredType::LOW, source: :operator)\n      when :propagate\n        # Type propagates from operands\n        nil\n      end\n    end\n\n    def infer_array_type(expr)\n      # Remove brackets\n      content = expr[1..-2].strip\n      return InferredType.new(type: "Array", confidence: InferredType::HIGH, source: :literal) if content.empty?\n\n      # Try to infer element types\n      elements = split_array_elements(content)\n      element_types = elements.map { |e| infer_expression_type(e)&.type }.compact.uniq\n\n      if element_types.length == 1\n        InferredType.new(\n          type: "Array<#{element_types.first}>",\n          confidence: InferredType::HIGH,\n          source: :literal\n        )\n      elsif element_types.length > 1\n        InferredType.new(\n          type: "Array<#{element_types.join(" | ")}>",\n          confidence: InferredType::MEDIUM,\n          source: :literal\n        )\n      else\n        InferredType.new(type: "Array", confidence: InferredType::HIGH, source: :literal)\n      end\n    end\n\n    def split_array_elements(content)\n      # Simple split by comma (doesn\'t handle nested structures well)\n      content.split(",").map(&:strip)\n    end\n  end\nend\n',"lib/t_ruby/union_type_parser.rb":'# frozen_string_literal: true\n\nmodule TRuby\n  class UnionTypeParser\n    def initialize(type_string)\n      @type_string = type_string.strip\n    end\n\n    def parse\n      # Check if it contains pipes (union indicator)\n      if @type_string.include?("|")\n        parse_union\n      else\n        parse_simple\n      end\n    end\n\n    private\n\n    def parse_union\n      members = @type_string.split("|").map(&:strip).compact\n\n      {\n        type: :union,\n        members: members,\n        has_duplicates: members.length != members.uniq.length,\n        unique_members: members.uniq,\n      }\n    end\n\n    def parse_simple\n      {\n        type: :simple,\n        value: @type_string,\n      }\n    end\n  end\nend\n',"lib/t_ruby/version.rb":'# frozen_string_literal: true\n\nmodule TRuby\n  VERSION = "0.0.46"\nend\n',"lib/t_ruby/version_checker.rb":'# frozen_string_literal: true\n\nrequire "net/http"\nrequire "json"\nrequire "uri"\nrequire "openssl"\n\nmodule TRuby\n  class VersionChecker\n    GEM_NAME = "t-ruby"\n    RUBYGEMS_API = "https://rubygems.org/api/v1/gems/#{GEM_NAME}.json".freeze\n\n    def self.check\n      new.check\n    end\n\n    def self.update\n      new.update\n    end\n\n    def check\n      latest = fetch_latest_version\n      return nil unless latest\n\n      current = Gem::Version.new(VERSION)\n      latest_version = Gem::Version.new(latest)\n\n      return nil if current >= latest_version\n\n      { current: VERSION, latest: latest }\n    end\n\n    def update\n      system("gem install #{GEM_NAME}")\n    end\n\n    private\n\n    def fetch_latest_version\n      uri = URI(RUBYGEMS_API)\n\n      http = Net::HTTP.new(uri.host, uri.port)\n      http.use_ssl = true\n      http.verify_mode = OpenSSL::SSL::VERIFY_PEER\n      http.verify_callback = ->(_preverify_ok, _store_ctx) { true } # Skip CRL check\n      http.open_timeout = 3\n      http.read_timeout = 3\n\n      request = Net::HTTP::Get.new(uri)\n      response = http.request(request)\n\n      return nil unless response.is_a?(Net::HTTPSuccess)\n\n      data = JSON.parse(response.body)\n      data["version"]\n    rescue StandardError\n      nil\n    end\n  end\nend\n',"lib/t_ruby/watcher.rb":'# frozen_string_literal: true\n\n# listen gem is optional - only required for watch mode\n# This allows T-Ruby core functionality to work on Ruby 4.0+ where listen/ffi may not be available\nbegin\n  require "listen"\n  LISTEN_AVAILABLE = true\nrescue LoadError\n  LISTEN_AVAILABLE = false\nend\n\nmodule TRuby\n  class Watcher\n    # ANSI color codes (similar to tsc output style)\n    COLORS = {\n      reset: "\\e[0m",\n      bold: "\\e[1m",\n      dim: "\\e[2m",\n      red: "\\e[31m",\n      green: "\\e[32m",\n      yellow: "\\e[33m",\n      blue: "\\e[34m",\n      cyan: "\\e[36m",\n      gray: "\\e[90m",\n    }.freeze\n\n    attr_reader :incremental_compiler, :stats\n\n    def initialize(paths: ["."], config: nil, incremental: true, cross_file_check: true, parallel: true)\n      @paths = paths.map { |p| File.expand_path(p) }\n      @config = config || Config.new\n      @compiler = Compiler.new(@config)\n      @error_count = 0\n      @file_count = 0\n      @use_colors = $stdout.tty?\n      @file_diagnostics = {} # Cache diagnostics per file for incremental updates\n\n      # Enhanced features\n      @incremental = incremental\n      @cross_file_check = cross_file_check\n      @parallel = parallel\n\n      # Initialize incremental compiler\n      if @incremental\n        @incremental_compiler = EnhancedIncrementalCompiler.new(\n          @compiler,\n          enable_cross_file: @cross_file_check\n        )\n      end\n\n      # Parallel processor\n      @parallel_processor = ParallelProcessor.new if @parallel\n\n      # Statistics\n      @stats = {\n        total_compilations: 0,\n        incremental_hits: 0,\n        total_time: 0.0,\n      }\n    end\n\n    def watch\n      unless LISTEN_AVAILABLE\n        puts colorize(:red, "Error: Watch mode requires the \'listen\' gem.")\n        puts colorize(:yellow, "The \'listen\' gem is not available (possibly due to Ruby 4.0+ ffi compatibility).")\n        puts colorize(:dim, "Install with: gem install listen")\n        puts colorize(:dim, "Or run without watch mode: trc")\n        exit 1\n      end\n\n      print_start_message\n\n      # Initial compilation\n      start_time = Time.now\n      compile_all\n      @stats[:total_time] += Time.now - start_time\n\n      # Start watching (.trb and .rb files)\n      listener = Listen.to(*watch_directories, only: /\\.(trb|rb)$/) do |modified, added, removed|\n        handle_changes(modified, added, removed)\n      end\n\n      listener.start\n\n      print_watching_message\n\n      # Keep the process running\n      begin\n        sleep\n      rescue Interrupt\n        puts "\\n#{colorize(:dim, timestamp)} #{colorize(:cyan, "Stopping watch mode...")}"\n        print_stats if @incremental\n        listener.stop\n      end\n    end\n\n    private\n\n    def watch_directory(path)\n      File.directory?(path) ? path : File.dirname(path)\n    end\n\n    def watch_directories\n      if @paths == [File.expand_path(".")]\n        # Default case: only watch source_include directories from config\n        @config.source_include.map { |dir| File.expand_path(dir) }.select { |dir| Dir.exist?(dir) }\n      else\n        # Specific paths provided: watch those paths\n        @paths.map { |path| watch_directory(path) }.uniq\n      end\n    end\n\n    def handle_changes(modified, added, removed)\n      changed_files = (modified + added)\n                      .select { |f| f.end_with?(".trb") || f.end_with?(".rb") }\n                      .reject { |f| @config.excluded?(f) }\n      return if changed_files.empty? && removed.empty?\n\n      puts\n      print_file_change_message\n\n      if removed.any?\n        removed.each do |file|\n          puts "#{colorize(:gray, timestamp)} #{colorize(:yellow, "File removed:")} #{relative_path(file)}"\n          # Clear from incremental compiler cache\n          @incremental_compiler&.file_hashes&.delete(file)\n        end\n      end\n\n      if changed_files.any?\n        start_time = Time.now\n        compile_files_incremental(changed_files)\n        @stats[:total_time] += Time.now - start_time\n      else\n        print_watching_message\n      end\n    end\n\n    def compile_all\n      @error_count = 0\n      @file_count = 0\n      @file_diagnostics = {} # Reset diagnostics cache on full compile\n\n      trb_files = find_trb_files\n      rb_files = find_rb_files\n      all_files = trb_files + rb_files\n      @file_count = all_files.size\n\n      # Use unified compile_with_diagnostics for all files\n      # Note: compile_file increments @stats[:total_compilations] internally\n      all_files.each do |file|\n        result = compile_file(file)\n        # Cache diagnostics per file\n        @file_diagnostics[file] = result[:diagnostics] || []\n      end\n\n      all_diagnostics = @file_diagnostics.values.flatten\n      print_errors(all_diagnostics)\n      print_summary\n    end\n\n    def compile_files_incremental(files)\n      compiled_count = 0\n\n      if @incremental\n        files.each do |file|\n          if @incremental_compiler.needs_compile?(file)\n            @stats[:total_compilations] += 1\n            result = compile_file_with_ir(file)\n            # Update cached diagnostics for this file\n            @file_diagnostics[file] = result[:diagnostics] || []\n            compiled_count += 1\n          else\n            @stats[:incremental_hits] += 1\n            puts "#{colorize(:gray, timestamp)} #{colorize(:dim, "Skipping unchanged:")} #{relative_path(file)}"\n          end\n        end\n\n        # Run cross-file check if enabled\n        if @cross_file_check && @incremental_compiler.cross_file_checker\n          check_result = @incremental_compiler.cross_file_checker.check_all\n          check_result[:errors].each do |e|\n            # Add cross-file errors (these are not file-specific)\n            @file_diagnostics[:cross_file] ||= []\n            @file_diagnostics[:cross_file] << create_diagnostic_from_cross_file_error(e)\n          end\n        end\n      else\n        files.each do |file|\n          result = compile_file(file)\n          # Update cached diagnostics for this file\n          @file_diagnostics[file] = result[:diagnostics] || []\n          compiled_count += 1\n        end\n      end\n\n      # Collect all diagnostics from cache (includes unchanged files\' errors)\n      all_diagnostics = @file_diagnostics.values.flatten\n\n      # Update error count from all cached diagnostics\n      @error_count = all_diagnostics.size\n\n      @file_count = compiled_count\n      print_errors(all_diagnostics)\n      print_summary\n      print_watching_message\n    end\n\n    def compile_file_with_ir(file)\n      # Use unified compile_with_diagnostics from Compiler (same as compile_file)\n      # This ensures incremental compile returns the same diagnostics as full compile\n      compile_result = @compiler.compile_with_diagnostics(file)\n\n      # Update incremental compiler\'s file hash to track changes\n      @incremental_compiler&.update_file_hash(file)\n\n      {\n        file: file,\n        diagnostics: compile_result[:diagnostics],\n        success: compile_result[:success],\n      }\n    end\n\n    def compile_file(file)\n      # Use unified compile_with_diagnostics from Compiler\n      compile_result = @compiler.compile_with_diagnostics(file)\n\n      @error_count += compile_result[:diagnostics].size\n      @stats[:total_compilations] += 1\n\n      {\n        file: file,\n        diagnostics: compile_result[:diagnostics],\n        success: compile_result[:success],\n      }\n    end\n\n    def find_trb_files\n      find_source_files_by_extension(".trb")\n    end\n\n    def find_rb_files\n      find_source_files_by_extension(".rb")\n    end\n\n    def find_source_files_by_extension(ext)\n      files = []\n\n      # Always search in source_include directories only\n      source_paths = if @paths == [File.expand_path(".")]\n                       @config.source_include.map { |dir| File.expand_path(dir) }\n                     else\n                       @paths.map { |path| File.expand_path(path) }\n                     end\n\n      source_paths.each do |path|\n        if File.file?(path)\n          # Handle single file path\n          files << path if path.end_with?(ext) && !@config.excluded?(path)\n        elsif Dir.exist?(path)\n          # Handle directory path\n          Dir.glob(File.join(path, "**", "*#{ext}")).each do |file|\n            files << file unless @config.excluded?(file)\n          end\n        end\n      end\n\n      files.uniq\n    end\n\n    # Create a Diagnostic for cross-file check errors\n    def create_diagnostic_from_cross_file_error(error)\n      file = error[:file]\n      source = File.exist?(file) ? File.read(file) : nil\n      create_generic_diagnostic(file, error[:message], source)\n    end\n\n    # Create a generic Diagnostic for standard errors\n    def create_generic_diagnostic(file, message, source = nil)\n      line = 1\n      col = 1\n\n      # Try to extract line info from error message\n      if message =~ /line (\\d+)/i\n        line = ::Regexp.last_match(1).to_i\n      end\n\n      source_line = source&.split("\\n")&.at(line - 1)\n\n      Diagnostic.new(\n        code: "TR0001",\n        message: message,\n        file: relative_path(file),\n        line: line,\n        column: col,\n        source_line: source_line\n      )\n    end\n\n    def print_errors(diagnostics)\n      return if diagnostics.empty?\n\n      formatter = DiagnosticFormatter.new(use_colors: @use_colors)\n      diagnostics.each do |diagnostic|\n        puts\n        puts formatter.format(diagnostic)\n      end\n    end\n\n    def print_start_message\n      puts "#{colorize(:gray, timestamp)} #{colorize(:bold, "Starting compilation in watch mode...")}"\n      puts\n    end\n\n    def print_file_change_message\n      puts "#{colorize(:gray,\n                       timestamp)} #{colorize(:bold, "File change detected. Starting incremental compilation...")}"\n      puts\n    end\n\n    def print_summary\n      puts\n      if @error_count.zero?\n        msg = "Found #{colorize(:green, "0 errors")}. Watching for file changes."\n      else\n        error_word = @error_count == 1 ? "error" : "errors"\n        msg = "Found #{colorize(:red, "#{@error_count} #{error_word}")}. Watching for file changes."\n      end\n      puts "#{colorize(:gray, timestamp)} #{msg}"\n    end\n\n    def print_watching_message\n      # Just print a blank line for readability\n    end\n\n    def print_stats\n      puts\n      puts "#{colorize(:gray, timestamp)} #{colorize(:bold, "Watch Mode Statistics:")}"\n      puts "  Total compilations: #{@stats[:total_compilations]}"\n      puts "  Incremental cache hits: #{@stats[:incremental_hits]}"\n      total = @stats[:total_compilations] + @stats[:incremental_hits]\n      hit_rate = if total.positive?\n                   (@stats[:incremental_hits].to_f / total * 100).round(1)\n                 else\n                   0\n                 end\n      puts "  Cache hit rate: #{hit_rate}%"\n      puts "  Total compile time: #{@stats[:total_time].round(2)}s"\n    end\n\n    def timestamp\n      Time.now.strftime("[%I:%M:%S %p]")\n    end\n\n    def relative_path(file)\n      file.sub("#{Dir.pwd}/", "")\n    end\n\n    def colorize(color, text)\n      return text unless @use_colors\n      return text unless COLORS[color]\n\n      "#{COLORS[color]}#{text}#{COLORS[:reset]}"\n    end\n  end\nend\n',"lib/t_ruby.rb":'# frozen_string_literal: true\n\nrequire_relative "t_ruby/version"\nrequire_relative "t_ruby/version_checker"\nrequire_relative "t_ruby/ruby_version"\nrequire_relative "t_ruby/code_emitter"\nrequire_relative "t_ruby/config"\n\n# Core infrastructure (must be loaded first)\nrequire_relative "t_ruby/string_utils"\nrequire_relative "t_ruby/ir"\nrequire_relative "t_ruby/parser_combinator"\nrequire_relative "t_ruby/scanner"\nrequire_relative "t_ruby/smt_solver"\n\n# Basic components\nrequire_relative "t_ruby/type_alias_registry"\nrequire_relative "t_ruby/heredoc_detector"\nrequire_relative "t_ruby/parser"\nrequire_relative "t_ruby/union_type_parser"\nrequire_relative "t_ruby/generic_type_parser"\nrequire_relative "t_ruby/intersection_type_parser"\nrequire_relative "t_ruby/type_erasure"\nrequire_relative "t_ruby/error_handler"\nrequire_relative "t_ruby/diagnostic"\nrequire_relative "t_ruby/diagnostic_formatter"\nrequire_relative "t_ruby/error_reporter"\nrequire_relative "t_ruby/declaration_generator"\nrequire_relative "t_ruby/compiler"\nrequire_relative "t_ruby/lsp_server"\nrequire_relative "t_ruby/watcher"\nrequire_relative "t_ruby/runner"\nrequire_relative "t_ruby/cli"\n\n# Milestone 4: Advanced Features\nrequire_relative "t_ruby/constraint_checker"\nrequire_relative "t_ruby/type_inferencer"\nrequire_relative "t_ruby/runtime_validator"\nrequire_relative "t_ruby/type_checker"\nrequire_relative "t_ruby/type_env"\nrequire_relative "t_ruby/ast_type_inferrer"\nrequire_relative "t_ruby/cache"\nrequire_relative "t_ruby/package_manager"\n\n# Milestone 5: Bundler Integration\nrequire_relative "t_ruby/bundler_integration"\n\n# Milestone 6: Quality & Documentation\nrequire_relative "t_ruby/benchmark"\nrequire_relative "t_ruby/doc_generator"\n\n# Milestone -7: Documentation Verification\nrequire_relative "t_ruby/docs_example_extractor"\nrequire_relative "t_ruby/docs_example_verifier"\nrequire_relative "t_ruby/docs_badge_generator"\n\nmodule TRuby\n  # Parse error for T-Ruby source code\n  class ParseError < StandardError\n    attr_reader :line, :column, :source\n\n    def initialize(message, line: nil, column: nil, source: nil)\n      @line = line\n      @column = column\n      @source = source\n      super(message)\n    end\n  end\nend\n'};var a=function(){{const n=["lib/t_ruby/version.rb","lib/t_ruby/ruby_version.rb","lib/t_ruby/code_emitter.rb","lib/t_ruby/config.rb","lib/t_ruby/string_utils.rb","lib/t_ruby/ir.rb","lib/t_ruby/parser_combinator/parse_result.rb","lib/t_ruby/parser_combinator/parser.rb","lib/t_ruby/parser_combinator/primitives/literal.rb","lib/t_ruby/parser_combinator/primitives/satisfy.rb","lib/t_ruby/parser_combinator/primitives/regex.rb","lib/t_ruby/parser_combinator/primitives/end_of_input.rb","lib/t_ruby/parser_combinator/primitives/pure.rb","lib/t_ruby/parser_combinator/primitives/fail.rb","lib/t_ruby/parser_combinator/primitives/lazy.rb","lib/t_ruby/parser_combinator/combinators/sequence.rb","lib/t_ruby/parser_combinator/combinators/alternative.rb","lib/t_ruby/parser_combinator/combinators/map.rb","lib/t_ruby/parser_combinator/combinators/flat_map.rb","lib/t_ruby/parser_combinator/combinators/many.rb","lib/t_ruby/parser_combinator/combinators/many1.rb","lib/t_ruby/parser_combinator/combinators/optional.rb","lib/t_ruby/parser_combinator/combinators/sep_by.rb","lib/t_ruby/parser_combinator/combinators/sep_by1.rb","lib/t_ruby/parser_combinator/combinators/skip_right.rb","lib/t_ruby/parser_combinator/combinators/label.rb","lib/t_ruby/parser_combinator/combinators/lookahead.rb","lib/t_ruby/parser_combinator/combinators/not_followed_by.rb","lib/t_ruby/parser_combinator/combinators/choice.rb","lib/t_ruby/parser_combinator/combinators/chain_left.rb","lib/t_ruby/parser_combinator/dsl.rb","lib/t_ruby/parser_combinator/token/token_parse_result.rb","lib/t_ruby/parser_combinator/token/token_parser.rb","lib/t_ruby/parser_combinator/token/token_matcher.rb","lib/t_ruby/parser_combinator/token/token_sequence.rb","lib/t_ruby/parser_combinator/token/token_alternative.rb","lib/t_ruby/parser_combinator/token/token_map.rb","lib/t_ruby/parser_combinator/token/token_many.rb","lib/t_ruby/parser_combinator/token/token_many1.rb","lib/t_ruby/parser_combinator/token/token_optional.rb","lib/t_ruby/parser_combinator/token/token_sep_by.rb","lib/t_ruby/parser_combinator/token/token_sep_by1.rb","lib/t_ruby/parser_combinator/token/token_skip_right.rb","lib/t_ruby/parser_combinator/token/token_label.rb","lib/t_ruby/parser_combinator/token/token_dsl.rb","lib/t_ruby/parser_combinator/token/expression_parser.rb","lib/t_ruby/parser_combinator/token/token_body_parser.rb","lib/t_ruby/parser_combinator/token/statement_parser.rb","lib/t_ruby/parser_combinator/token/token_declaration_parser.rb","lib/t_ruby/parser_combinator/type_parser.rb","lib/t_ruby/parser_combinator/declaration_parser.rb","lib/t_ruby/parser_combinator/parse_error.rb","lib/t_ruby/parser_combinator.rb","lib/t_ruby/scanner.rb","lib/t_ruby/smt_solver.rb","lib/t_ruby/type_alias_registry.rb","lib/t_ruby/heredoc_detector.rb","lib/t_ruby/parser.rb","lib/t_ruby/union_type_parser.rb","lib/t_ruby/generic_type_parser.rb","lib/t_ruby/intersection_type_parser.rb","lib/t_ruby/type_erasure.rb","lib/t_ruby/error_handler.rb","lib/t_ruby/diagnostic.rb","lib/t_ruby/diagnostic_formatter.rb","lib/t_ruby/error_reporter.rb","lib/t_ruby/declaration_generator.rb","lib/t_ruby/compiler.rb","lib/t_ruby/constraint_checker.rb","lib/t_ruby/type_inferencer.rb","lib/t_ruby/runtime_validator.rb","lib/t_ruby/type_checker.rb","lib/t_ruby/type_env.rb","lib/t_ruby/ast_type_inferrer.rb","lib/t_ruby/cache.rb"];let e="\n# T-Ruby WASM Bundle Loader\n# Directly eval bundled files instead of writing to file system\n\n# WASM \ud658\uacbd \ud45c\uc2dc\nmodule TRuby\n  WASM_ENV = true\nend unless defined?(TRuby)\n\n# Net::HTTP \uc2a4\ud141 (WASM\uc5d0\uc11c socket \uc0ac\uc6a9 \ubd88\uac00)\nmodule Net\n  class HTTP\n    class << self\n      def new(*); self; end\n      def start(*); yield self if block_given?; end\n      def get_response(*); nil; end\n    end\n\n    attr_accessor :use_ssl, :verify_mode, :open_timeout, :read_timeout\n\n    def request(*); nil; end\n\n    class Get\n      def initialize(*); end\n    end\n\n    class Post\n      def initialize(*); end\n      attr_accessor :body\n      def []=(*); end\n    end\n\n    class Delete\n      def initialize(*); end\n      def set_form_data(*); end\n    end\n  end\n\n  HTTPSuccess = Class.new\n  HTTPNotFound = Class.new\nend unless defined?(Net::HTTP)\n\n# OpenSSL \uc2a4\ud141\nmodule OpenSSL\n  module SSL\n    VERIFY_PEER = 0\n    VERIFY_NONE = 1\n  end\nend unless defined?(OpenSSL::SSL::VERIFY_PEER)\n\n# FileUtils \uc2a4\ud141\nmodule FileUtils\n  def self.mkdir_p(*); true; end\n  def self.rm_rf(*); true; end\n  def self.cp(*); true; end\n  def self.mv(*); true; end\nend unless defined?(FileUtils) && FileUtils.respond_to?(:mkdir_p)\n";e+=`\nputs "[T-Ruby WASM] Starting file loading..."\nputs "[T-Ruby WASM] Bundle has #{${Object.keys(s).length}} files"\n`;for(let t=0;t<n.length;t++){const r=n[t],i=s[r];if(!i){e+=`puts "[T-Ruby WASM] SKIP: ${r} (not in bundle)"\n`;continue}e+=`puts "[T-Ruby WASM] Loading: ${r}"\n`;const a=`__T_RUBY_CODE_${t}__`;e+=`\neval(<<~'${a}', binding, '${r}')\n${i.replace(/# frozen_string_literal: true\n?/g,"").replace(/require_relative\s+["'][^"']+["']\n?/g,"").replace(/require\s+["']fileutils["']\n?/g,"")}\n${a}\n`}return e+="\nrequire 'json'\n",e}}(),o="2.8.1",l=class{vm=null;initialized=!1;vfs=new r;constructor(n={}){}async initialize(){this.initialized||(this.vm=await this.loadWasm(),await this.vm.evalAsync(a),this.initialized=!0)}async compile(n,e="input.trb"){this.ensureInit();try{const e=await this.vm.evalAsync("defined?(TRuby::Compiler)");if(!e||"nil"===String(e))return{success:!1,errors:[{message:"TRuby::Compiler is not defined. Initialization may have failed."}]};const t=await this.evalJson(`TRuby::Compiler.new.compile_string(${i(n)}).to_json`);return{...t,success:!t.errors?.length}}catch(t){return{success:!1,errors:[{message:String(t)}]}}}async typeCheck(n,e="input.trb"){this.ensureInit();try{return await this.evalJson(`TRuby::TypeChecker.check(${i(n)}, filename: ${i(e)}).to_json`)}catch(t){return{valid:!1,errors:[{message:String(t)}]}}}addFile(n,e){this.vfs.addFile(n,e)}addFiles(n){this.vfs.addFiles(n)}removeFile(n){this.vfs.removeFile(n)}clearFiles(){this.vfs.clear()}getFiles(){return this.vfs.getAllFiles()}async getVersion(){this.ensureInit();const[n,e]=await Promise.all([this.vm.evalAsync("TRuby::VERSION"),this.vm.evalAsync("RUBY_VERSION")]);return{tRuby:"string"==typeof n?n:String(n),ruby:"string"==typeof e?e:String(e),rubyWasm:o}}async eval(n){return this.ensureInit(),this.vm.evalAsync(n)}isInitialized(){return this.initialized}async loadWasm(){const{DefaultRubyVM:n}=await t.e(2385).then(t.bind(t,2385)),e=`https://cdn.jsdelivr.net/npm/@ruby/3.4-wasm-wasi@${o}/dist/ruby+stdlib.wasm`,r=await fetch(e);if(!r.ok)throw new Error(`Failed to fetch WASM: ${r.status} ${r.statusText}`);const i=await WebAssembly.compileStreaming(r);return(await n(i)).vm}async evalJson(n){return JSON.parse(await this.vm.evalAsync(`require 'json'; ${n}`))}ensureInit(){if(!this.initialized)throw new Error("T-Ruby WASM not initialized. Call initialize() first.")}}}}]);